"""
è¯„ä¼°è„šæœ¬
è¯„ä¼°æ§åˆ¶å™¨æ€§èƒ½
"""

import torch
import numpy as np
from typing import Dict, List, Tuple, Any
import json
import os
from tqdm import tqdm

from sumo_integration import create_sumo_controller


class Evaluator:
    """
    è¯„ä¼°å™¨
    """
    
    def __init__(self, model_path: str, config_path: str = None):
        # åˆ›å»ºæ§åˆ¶å™¨
        self.controller = create_sumo_controller(config_path)
        
        # åŠ è½½æ¨¡å‹
        if model_path and os.path.exists(model_path):
            checkpoint = torch.load(model_path, map_location=self.controller.device)
            self.controller.model.load_state_dict(checkpoint['model_state_dict'])
            print(f"âœ… åŠ è½½æ¨¡å‹: {model_path}")
        
        # è¯„ä¼°æŒ‡æ ‡
        self.metrics = {
            'total_steps': 0,
            'total_reward': 0.0,
            'avg_speed': 0.0,
            'speed_std': 0.0,
            'throughput': 0.0,
            'intervention_count': 0,
            'emergency_count': 0,
            'controlled_vehicles': 0
        }
    
    def evaluate(self, num_episodes: int = 10, max_steps: int = 3600) -> Dict[str, Any]:
        """
        è¯„ä¼°æ§åˆ¶å™¨
        """
        print(f"ğŸ” å¼€å§‹è¯„ä¼° ({num_episodes} episodes, {max_steps} steps each)...")
        
        for episode in range(num_episodes):
            episode_reward = self._run_episode(max_steps)
            
            print(f"Episode {episode+1}/{num_episodes}, Reward: {episode_reward:.2f}")
        
        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        avg_metrics = {
            'avg_reward': self.metrics['total_reward'] / num_episodes,
            'avg_speed': self.metrics['avg_speed'] / num_episodes,
            'speed_std': self.metrics['speed_std'] / num_episodes,
            'throughput': self.metrics['throughput'] / num_episodes,
            'avg_interventions': self.metrics['intervention_count'] / num_episodes,
            'avg_emergency': self.metrics['emergency_count'] / num_episodes,
            'avg_controlled': self.metrics['controlled_vehicles'] / num_episodes
        }
        
        print("\nğŸ“Š è¯„ä¼°ç»“æœ:")
        for key, value in avg_metrics.items():
            print(f"  {key}: {value:.4f}")
        
        return avg_metrics
    
    def _run_episode(self, max_steps: int) -> float:
        """
        è¿è¡Œä¸€ä¸ªepisode
        """
        # é‡ç½®æ§åˆ¶å™¨ç»Ÿè®¡
        self.controller.reset_statistics()
        
        # æ¨¡æ‹ŸSUMOç¯å¢ƒ
        total_reward = 0.0
        speeds = []
        
        for step in range(max_steps):
            # ç”Ÿæˆæ¨¡æ‹Ÿè½¦è¾†æ•°æ®
            vehicle_data = self._generate_vehicle_data(step)
            
            # åº”ç”¨æ§åˆ¶
            control_results = self.controller.apply_control(vehicle_data, step)
            
            # è®¡ç®—å¥–åŠ±
            reward = self._calculate_reward(vehicle_data, control_results)
            total_reward += reward
            
            # è®°å½•é€Ÿåº¦
            speeds.extend([v['speed'] for v in vehicle_data.values()])
            
            # æ¯100æ­¥è¾“å‡º
            if step % 100 == 0:
                print(f"  Step {step}/{max_steps}, Reward: {reward:.2f}")
        
        # æ›´æ–°æŒ‡æ ‡
        self.metrics['total_steps'] += max_steps
        self.metrics['total_reward'] += total_reward
        self.metrics['avg_speed'] += np.mean(speeds)
        self.metrics['speed_std'] += np.std(speeds)
        self.metrics['throughput'] += len(speeds) / max_steps
        
        stats = self.controller.get_statistics()
        self.metrics['intervention_count'] += stats['total_interventions']
        self.metrics['emergency_count'] += stats['total_emergency_interventions']
        self.metrics['controlled_vehicles'] += stats['total_controlled_vehicles']
        
        return total_reward
    
    def _generate_vehicle_data(self, step: int) -> Dict[str, Any]:
        """ç”Ÿæˆæ¨¡æ‹Ÿè½¦è¾†æ•°æ®"""
        vehicle_data = {}
        
        # åŠ¨æ€ç”Ÿæˆè½¦è¾†æ•°é‡
        num_vehicles = int(10 + 10 * np.sin(step * 0.01))
        
        for i in range(num_vehicles):
            veh_id = f"veh_{step}_{i}"
            vehicle_data[veh_id] = {
                'position': np.random.uniform(0, 1000),
                'speed': np.random.uniform(5, 25),
                'acceleration': np.random.uniform(-2, 2),
                'lane_index': np.random.randint(0, 3),
                'remaining_distance': np.random.uniform(100, 1000),
                'completion_rate': np.random.uniform(0, 1),
                'is_icv': np.random.random() < 0.25,  # 25% ICV
                'id': veh_id,
                'lane_id': f"lane_{np.random.randint(0, 3)}"
            }
        
        return vehicle_data
    
    def _calculate_reward(self, vehicle_data: Dict[str, Any], 
                        control_results: Dict[str, Any]) -> float:
        """è®¡ç®—å¥–åŠ±"""
        # é€Ÿåº¦å¥–åŠ±
        speeds = [v['speed'] for v in vehicle_data.values()]
        avg_speed = np.mean(speeds) if speeds else 0.0
        speed_std = np.std(speeds) if len(speeds) > 1 else 0.0
        
        # å¹²é¢„æˆæœ¬
        intervention_cost = control_results['safety_interventions'] * 0.1
        emergency_cost = control_results['emergency_interventions'] * 1.0
        
        # å¥–åŠ± = é€Ÿåº¦å¥–åŠ± - ä¸ç¨³å®šæƒ©ç½š - å¹²é¢„æˆæœ¬ - ç´§æ€¥æˆæœ¬
        reward = avg_speed * 0.1 - speed_std * 0.5 - intervention_cost - emergency_cost
        
        return reward
    
    def save_results(self, results: Dict[str, Any], save_path: str):
        """ä¿å­˜è¯„ä¼°ç»“æœ"""
        with open(save_path, 'w') as f:
            json.dump(results, f, indent=2)
        print(f"âœ… è¯„ä¼°ç»“æœå·²ä¿å­˜åˆ°: {save_path}")


def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®
    model_path = 'models/traffic_controller_v1.pth'
    config_path = None
    num_episodes = 10
    max_steps = 3600
    results_path = 'results/evaluation_results.json'
    
    # åˆ›å»ºç»“æœç›®å½•
    os.makedirs('results', exist_ok=True)
    
    # åˆ›å»ºè¯„ä¼°å™¨
    evaluator = Evaluator(model_path, config_path)
    
    # è¯„ä¼°
    results = evaluator.evaluate(num_episodes=num_episodes, max_steps=max_steps)
    
    # ä¿å­˜ç»“æœ
    evaluator.save_results(results, results_path)
    
    print("\nğŸ‰ è¯„ä¼°å®Œæˆ!")


if __name__ == "__main__":
    main()

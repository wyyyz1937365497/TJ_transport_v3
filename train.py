"""
è®­ç»ƒè„šæœ¬
åŒ…å«ä¸‰é˜¶æ®µè®­ç»ƒæµç¨‹ï¼š
Phase 1ï¼šä¸–ç•Œæ¨¡å‹é¢„è®­ç»ƒ
Phase 2ï¼šå®‰å…¨RLè®­ç»ƒ
Phase 3ï¼šçº¦æŸä¼˜åŒ–
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torch.cuda.amp import autocast, GradScaler
import numpy as np
import json
import os
from typing import Dict, List, Tuple, Any
from tqdm import tqdm

from neural_traffic_controller import TrafficController


class TrafficDataset(Dataset):
    """
    äº¤é€šæ•°æ®é›†
    ç”¨äºè®­ç»ƒä¸–ç•Œæ¨¡å‹
    ä»çœŸå®SUMOä»¿çœŸæ•°æ®æˆ–é¢„æ”¶é›†çš„æ•°æ®é›†åŠ è½½
    """
    
    def __init__(self, data_path: str = None, num_samples: int = 1000,
                 validate_data: bool = True):
        self.num_samples = num_samples
        self.validate_data = validate_data
        
        # ä¼˜å…ˆä»çœŸå®æ•°æ®è·¯å¾„åŠ è½½
        if data_path is not None and os.path.exists(data_path):
            self.data = self._load_data(data_path)
            if validate_data:
                self._validate_data()
        else:
            # å¦‚æœæ²¡æœ‰çœŸå®æ•°æ®ï¼ŒæŠ›å‡ºé”™è¯¯è€Œéç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
            if data_path is None:
                raise ValueError(
                    "å¿…é¡»æä¾›æ•°æ®è·¯å¾„ã€‚çœŸå®è®­ç»ƒéœ€è¦ä»SUMOä»¿çœŸæ”¶é›†çš„äº¤é€šæ•°æ®ã€‚"
                    "è¯·å…ˆè¿è¡Œæ•°æ®æ”¶é›†è„šæœ¬æˆ–æä¾›é¢„æ”¶é›†çš„æ•°æ®é›†ã€‚"
                )
            else:
                raise FileNotFoundError(
                    f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}ã€‚"
                    "è¯·ç¡®ä¿å·²æ­£ç¡®æ”¶é›†å¹¶ä¿å­˜äº¤é€šæ•°æ®ã€‚"
                )
    
    def _validate_data(self):
        """éªŒè¯æ•°æ®å®Œæ•´æ€§"""
        if not self.data:
            raise ValueError("æ•°æ®é›†ä¸ºç©º")
        
        # æ£€æŸ¥å¿…è¦å­—æ®µ
        required_fields = ['vehicle_data', 'step']
        for i, sample in enumerate(self.data):
            for field in required_fields:
                if field not in sample:
                    raise ValueError(f"æ ·æœ¬ {i} ç¼ºå°‘å¿…è¦å­—æ®µ: {field}")
            
            # éªŒè¯è½¦è¾†æ•°æ®
            vehicle_data = sample['vehicle_data']
            if not vehicle_data:
                continue
            
            required_vehicle_fields = ['position', 'speed', 'acceleration',
                                      'lane_index', 'is_icv', 'id']
            for veh_id, vehicle in vehicle_data.items():
                for field in required_vehicle_fields:
                    if field not in vehicle:
                        raise ValueError(
                            f"æ ·æœ¬ {i}, è½¦è¾† {veh_id} ç¼ºå°‘å¿…è¦å­—æ®µ: {field}"
                        )
                
                # éªŒè¯æ•°æ®èŒƒå›´
                if not (0 <= vehicle['speed'] <= 50):  # åˆç†é€Ÿåº¦èŒƒå›´
                    raise ValueError(
                        f"æ ·æœ¬ {i}, è½¦è¾† {veh_id} é€Ÿåº¦å¼‚å¸¸: {vehicle['speed']}"
                    )
                if not (-10 <= vehicle['acceleration'] <= 10):  # åˆç†åŠ é€Ÿåº¦èŒƒå›´
                    raise ValueError(
                        f"æ ·æœ¬ {i}, è½¦è¾† {veh_id} åŠ é€Ÿåº¦å¼‚å¸¸: {vehicle['acceleration']}"
                    )
        
        print(f"âœ… æ•°æ®éªŒè¯é€šè¿‡: {len(self.data)} ä¸ªæ ·æœ¬")
    
    def _load_data(self, data_path: str) -> List[Dict[str, Any]]:
        """åŠ è½½æ•°æ®"""
        with open(data_path, 'r') as f:
            data = json.load(f)
        return data
    
    def __len__(self) -> int:
        return len(self.data)
    
    def __getitem__(self, idx: int) -> Dict[str, Any]:
        return self.data[idx]


class Trainer:
    """
    è®­ç»ƒå™¨ - æ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒ
    """
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.model = TrafficController(config['model']).to(config['device'])
        
        # åˆå§‹åŒ–ä¼˜åŒ–å™¨
        self.optimizer = optim.Adam(
            self.model.parameters(),
            lr=config['training']['learning_rate'],
            weight_decay=config['training']['weight_decay']
        )
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(
            self.optimizer,
            mode='max',
            factor=0.5,
            patience=10,
            verbose=False  # ç§»é™¤åºŸå¼ƒçš„verboseå‚æ•°æˆ–è®¾ç½®ä¸ºFalse
        )
        
        # æ··åˆç²¾åº¦è®­ç»ƒ
        self.use_amp = config['training'].get('use_amp', True)
        self.scaler = torch.amp.GradScaler('cuda') if self.use_amp else None
        
        # æŸå¤±å‡½æ•°
        self.mse_loss = nn.MSELoss()
        self.bce_loss = nn.BCELoss()
        
        # è®­ç»ƒç»Ÿè®¡
        self.training_stats = {
            'phase1_rewards': [],
            'phase2_rewards': [],
            'phase3_rewards': []
        }
    
    def train_phase1(self, num_epochs: int, batch_size: int = 64):
        """
        Phase 1: ä¸–ç•Œæ¨¡å‹é¢„è®­ç»ƒ
        """
        print("ğŸ”„ Phase 1: ä¸–ç•Œæ¨¡å‹é¢„è®­ç»ƒ...")
        
        # è®¾ç½®ä¸–ç•Œæ¨¡å‹ä¸ºPhase 1
        self.model.world_model.set_phase(1)
        
        # åˆ›å»ºæ•°æ®é›†
        dataset = TrafficDataset(num_samples=1000)
        num_workers = self.config['training'].get('num_workers', 2)
        dataloader = DataLoader(dataset, batch_size=1, shuffle=True, num_workers=num_workers)
        
        for epoch in range(num_epochs):
            total_loss = 0.0
            num_batches = 0
            
            for batch_data in tqdm(dataloader, desc=f"Epoch {epoch+1}/{num_epochs}"):
                # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
                loss = self._train_phase1_step(batch_data)
                
                total_loss += loss.item()
                num_batches += 1
            
            avg_loss = total_loss / num_batches if num_batches > 0 else 0.0
            print(f"Phase 1 - Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}")
            
            # æ›´æ–°å­¦ä¹ ç‡
            self.scheduler.step(-avg_loss)
        
        print("âœ… Phase 1 å®Œæˆ!")
    
    def _train_phase1_step(self, batch_data: Dict[str, Any]) -> torch.Tensor:
        """
        Phase 1 å•æ­¥è®­ç»ƒ - æ”¯æŒæ··åˆç²¾åº¦
        è®­ç»ƒä¸–ç•Œæ¨¡å‹é¢„æµ‹ä¸‹ä¸€æ—¶åˆ»çŠ¶æ€
        """
        self.optimizer.zero_grad()
        
        # è·å–è½¦è¾†æ•°æ®å’Œæ­¥éª¤
        vehicle_data = batch_data['vehicle_data']
        step = batch_data['step']
        
        # æ„å»ºè¾“å…¥æ‰¹æ¬¡
        batch = self._build_training_batch(vehicle_data, step)
        
        if batch is None or len(vehicle_data) == 0:
            return torch.tensor(0.0, device=self.config['device'])
        
        # ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
        if self.use_amp and self.config['device'] == 'cuda':
            with torch.amp.autocast('cuda'):
                # å‰å‘ä¼ æ’­
                gnn_embedding = self.model.risk_gnn(self.model._build_graph(batch))
                predictions = self.model.world_model(gnn_embedding)
                
                # è®¡ç®—æŸå¤± - åŸºäºçœŸå®è½¦è¾†çŠ¶æ€ç”Ÿæˆç›®æ ‡
                targets = self._generate_targets(gnn_embedding, vehicle_data)
                loss = self.mse_loss(predictions, targets)
            
            # åå‘ä¼ æ’­
            self.scaler.scale(loss).backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            
            self.scaler.step(self.optimizer)
            self.scaler.update()
        else:
            # å‰å‘ä¼ æ’­
            gnn_embedding = self.model.risk_gnn(self.model._build_graph(batch))
            predictions = self.model.world_model(gnn_embedding)
            
            # è®¡ç®—æŸå¤±
            targets = self._generate_targets(gnn_embedding, vehicle_data)
            loss = self.mse_loss(predictions, targets)
            
            # åå‘ä¼ æ’­
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            
            self.optimizer.step()
        
        return loss
    
    def train_phase2(self, num_epochs: int, batch_size: int = 64):
        """
        Phase 2: å®‰å…¨RLè®­ç»ƒ
        """
        print("ğŸ”„ Phase 2: å®‰å…¨RLè®­ç»ƒ...")
        
        # è®¾ç½®ä¸–ç•Œæ¨¡å‹ä¸ºPhase 2
        self.model.world_model.set_phase(2)
        
        # åˆ›å»ºæ•°æ®é›†
        dataset = TrafficDataset(num_samples=1000)
        num_workers = self.config['training'].get('num_workers', 2)
        dataloader = DataLoader(dataset, batch_size=1, shuffle=True, num_workers=num_workers)
        
        for epoch in range(num_epochs):
            total_reward = 0.0
            num_batches = 0
            
            for batch_data in tqdm(dataloader, desc=f"Epoch {epoch+1}/{num_epochs}"):
                # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
                reward = self._train_phase2_step(batch_data)
                
                total_reward += reward
                num_batches += 1
            
            avg_reward = total_reward / num_batches if num_batches > 0 else 0.0
            self.training_stats['phase2_rewards'].append(avg_reward)
            
            print(f"Phase 2 - Epoch {epoch+1}/{num_epochs}, Reward: {avg_reward:.4f}")
            
            # æ›´æ–°å­¦ä¹ ç‡
            self.scheduler.step(avg_reward)
            
            # æ›´æ–°æ‹‰æ ¼æœ—æ—¥ä¹˜å­
            if epoch % 5 == 0:
                self.model.update_lagrange_multiplier(avg_reward)
        
        print("âœ… Phase 2 å®Œæˆ!")
    
    def _train_phase2_step(self, batch_data: Dict[str, Any]) -> float:
        """
        Phase 2 å•æ­¥è®­ç»ƒ - å®‰å…¨RLè®­ç»ƒ
        ä½¿ç”¨ç­–ç•¥æ¢¯åº¦æ–¹æ³•ä¼˜åŒ–æ§åˆ¶ç­–ç•¥
        """
        self.optimizer.zero_grad()
        
        # è·å–è½¦è¾†æ•°æ®å’Œæ­¥éª¤
        vehicle_data = batch_data['vehicle_data']
        step = batch_data['step']
        
        # æ„å»ºè¾“å…¥æ‰¹æ¬¡
        batch = self._build_training_batch(vehicle_data, step)
        
        if batch is None or len(vehicle_data) == 0:
            return 0.0
        
        # ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
        if self.use_amp and self.config['device'] == 'cuda':
            with torch.amp.autocast('cuda'):
                # å‰å‘ä¼ æ’­
                output = self.model(batch, step)
                
                # è®¡ç®—å¥–åŠ± - åŸºäºçœŸå®äº¤é€šæŒ‡æ ‡
                reward = self._calculate_reward(output, vehicle_data)
                
                # ç­–ç•¥æ¢¯åº¦æŸå¤±ï¼ˆç®€åŒ–ç‰ˆREINFORCEï¼‰
                # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œåº”è¯¥ä½¿ç”¨æ›´å¤æ‚çš„RLç®—æ³•å¦‚PPO
                loss = -reward  # æœ€å¤§åŒ–å¥–åŠ± = æœ€å°åŒ–è´Ÿå¥–åŠ±
        
            # åå‘ä¼ æ’­
            self.scaler.scale(loss).backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            
            self.scaler.step(self.optimizer)
            self.scaler.update()
        else:
            # å‰å‘ä¼ æ’­
            output = self.model(batch, step)
            
            # è®¡ç®—å¥–åŠ±
            reward = self._calculate_reward(output, vehicle_data)
            
            # ç­–ç•¥æ¢¯åº¦æŸå¤±
            loss = -reward
            
            # åå‘ä¼ æ’­
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            
            self.optimizer.step()
        
        return reward.item()
    
    def train_phase3(self, num_epochs: int, batch_size: int = 64):
        """
        Phase 3: çº¦æŸä¼˜åŒ–
        """
        print("ğŸ”„ Phase 3: çº¦æŸä¼˜åŒ–...")
        
        # åˆ›å»ºæ•°æ®é›†
        dataset = TrafficDataset(num_samples=1000)
        num_workers = self.config['training'].get('num_workers', 2)
        dataloader = DataLoader(dataset, batch_size=1, shuffle=True, num_workers=num_workers)
        
        for epoch in range(num_epochs):
            total_reward = 0.0
            num_batches = 0
            
            for batch_data in tqdm(dataloader, desc=f"Epoch {epoch+1}/{num_epochs}"):
                # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
                reward = self._train_phase3_step(batch_data)
                
                total_reward += reward
                num_batches += 1
            
            avg_reward = total_reward / num_batches if num_batches > 0 else 0.0
            self.training_stats['phase3_rewards'].append(avg_reward)
            
            print(f"Phase 3 - Epoch {epoch+1}/{num_epochs}, Reward: {avg_reward:.4f}")
            
            # æ›´æ–°å­¦ä¹ ç‡
            self.scheduler.step(avg_reward)
        
        print("âœ… Phase 3 å®Œæˆ!")
    
    def _train_phase3_step(self, batch_data: Dict[str, Any]) -> float:
        """
        Phase 3 å•æ­¥è®­ç»ƒ - çº¦æŸä¼˜åŒ–
        ä½¿ç”¨æ‹‰æ ¼æœ—æ—¥å¯¹å¶æ–¹æ³•å¤„ç†å®‰å…¨çº¦æŸ
        """
        self.optimizer.zero_grad()
        
        # è·å–è½¦è¾†æ•°æ®å’Œæ­¥éª¤
        vehicle_data = batch_data['vehicle_data']
        step = batch_data['step']
        
        # æ„å»ºè¾“å…¥æ‰¹æ¬¡
        batch = self._build_training_batch(vehicle_data, step)
        
        if batch is None or len(vehicle_data) == 0:
            return 0.0
        
        # å‰å‘ä¼ æ’­
        output = self.model(batch, step)
        
        # è®¡ç®—çº¦æŸå¥–åŠ±
        reward = self._calculate_constrained_reward(output, vehicle_data)
        
        # è®¡ç®—çº¦æŸè¿å
        constraint_violation = (
            (output['level1_interventions'] + output['level2_interventions']) /
            max(len(vehicle_data), 1) - self.cost_limit
        )
        
        # æ‹‰æ ¼æœ—æ—¥æŸå¤±
        lagrangian_loss = -reward + self.model.lagrange_multiplier * constraint_violation
        
        # åå‘ä¼ æ’­
        lagrangian_loss.backward()
        
        # æ¢¯åº¦è£å‰ª
        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
        
        self.optimizer.step()
        
        return reward.item()
    
    def _build_training_batch(self, vehicle_data: Dict[str, Any], step: int) -> Dict[str, Any]:
        """æ„å»ºè®­ç»ƒæ‰¹æ¬¡"""
        vehicle_ids = list(vehicle_data.keys())
        
        # 1. æ”¶é›†è½¦è¾†ç‰¹å¾
        node_features = []
        is_icv_list = []
        
        for veh_id in vehicle_ids:
            vehicle = vehicle_data[veh_id]
            
            # èŠ‚ç‚¹ç‰¹å¾: [ä½ç½®, é€Ÿåº¦, åŠ é€Ÿåº¦, è½¦é“, å‰©ä½™è·ç¦», å®Œæˆç‡, ç±»å‹, æ—¶é—´, æ­¥é•¿]
            features = [
                vehicle.get('position', 0.0),
                vehicle.get('speed', 0.0),
                vehicle.get('acceleration', 0.0),
                vehicle.get('lane_index', 0),
                vehicle.get('remaining_distance', 1000.0),
                vehicle.get('completion_rate', 0.5),
                1.0 if vehicle.get('is_icv', False) else 0.0,
                step * 0.1,
                0.1
            ]
            
            node_features.append(features)
            is_icv_list.append(vehicle.get('is_icv', False))
        
        # 2. æ„å»ºäº¤äº’å›¾
        edge_indices = []
        edge_features = []
        
        # ç®€åŒ–ç‰ˆï¼šè¿æ¥ç›¸è¿‘è½¦è¾†
        for i, veh_id_i in enumerate(vehicle_ids):
            for j, veh_id_j in enumerate(vehicle_ids):
                if i == j:
                    continue
                
                pos_i = vehicle_data[veh_id_i].get('position', 0.0)
                pos_j = vehicle_data[veh_id_j].get('position', 0.0)
                speed_i = vehicle_data[veh_id_i].get('speed', 0.0)
                speed_j = vehicle_data[veh_id_j].get('speed', 0.0)
                
                distance = abs(pos_i - pos_j)
                if distance < 50:  # 50ç±³å†…
                    edge_indices.append([i, j])
                    
                    rel_distance = distance
                    rel_speed = abs(speed_i - speed_j)
                    
                    ttc = rel_distance / max(rel_speed, 0.1) if rel_speed > 0 else 100
                    thw = rel_distance / max(speed_i, 0.1) if speed_i > 0 else 100
                    
                    edge_features.append([rel_distance, rel_speed, min(ttc, 10), min(thw, 10)])
        
        # 3. è®¡ç®—å…¨å±€æŒ‡æ ‡
        if vehicle_data:
            speeds = [v['speed'] for v in vehicle_data.values()]
            positions = [v['position'] for v in vehicle_data.values()]
            
            avg_speed = np.mean(speeds)
            speed_std = np.std(speeds)
            vehicle_count = len(vehicle_data)
            icv_count = sum(1 for v in vehicle_data.values() if v.get('is_icv', False))
            
            global_metrics = [
                avg_speed,
                speed_std,
                0.0,  # å¹³å‡åŠ é€Ÿåº¦
                float(vehicle_count),
                step * 0.1,  # æ—¶é—´
                min(positions) if positions else 0.0,
                max(positions) if positions else 0.0,
                np.mean(positions) if positions else 0.0,
                float(icv_count),
                float(vehicle_count - icv_count),
                0.0,  # ICVæ€»é€Ÿåº¦
                0.0,  # éICVæ€»é€Ÿåº¦
                avg_speed * vehicle_count,  # æ€»æµé‡
                speed_std * vehicle_count,  # æ€»æ³¢åŠ¨
                0.0,  # æ€»åŠ é€Ÿåº¦
                step % 100  # å‘¨æœŸæ€§ç‰¹å¾
            ]
        else:
            global_metrics = [0.0] * 16
        
        # 4. è½¬æ¢ä¸ºå¼ é‡
        device = self.config['device']
        
        batch = {
            'node_features': torch.tensor(node_features, dtype=torch.float32).to(device),
            'edge_indices': torch.tensor(edge_indices, dtype=torch.long).t().contiguous().to(device) if edge_indices else torch.zeros((2, 0), dtype=torch.long).to(device),
            'edge_features': torch.tensor(edge_features, dtype=torch.float32).to(device) if edge_features else torch.zeros((0, 4), dtype=torch.float32).to(device),
            'global_metrics': torch.tensor(global_metrics, dtype=torch.float32).unsqueeze(0).to(device),
            'vehicle_ids': vehicle_ids,
            'is_icv': torch.tensor(is_icv_list, dtype=torch.bool).to(device),
            'vehicle_states': {
                'ids': vehicle_ids,
                'data': vehicle_data
            }
        }
        
        return batch
    
    def _generate_targets(self, gnn_embedding: torch.Tensor,
                        vehicle_data: Dict[str, Any]) -> torch.Tensor:
        """
        ç”Ÿæˆè®­ç»ƒç›®æ ‡
        åŸºäºè½¦è¾†çŠ¶æ€é¢„æµ‹ä¸‹ä¸€æ—¶åˆ»çš„åµŒå…¥è¡¨ç¤º
        """
        if not vehicle_data:
            return gnn_embedding
        
        # è®¡ç®—è½¦è¾†çŠ¶æ€çš„ç»Ÿè®¡ç‰¹å¾
        speeds = [v.get('speed', 0.0) for v in vehicle_data.values()]
        positions = [v.get('position', 0.0) for v in vehicle_data.values()]
        
        avg_speed = np.mean(speeds) if speeds else 0.0
        avg_position = np.mean(positions) if positions else 0.0
        
        # åŸºäºç‰©ç†è§„å¾‹é¢„æµ‹çŠ¶æ€å˜åŒ–
        # ç›®æ ‡åµŒå…¥åº”è¯¥åæ˜ é€Ÿåº¦å’Œä½ç½®çš„å˜åŒ–è¶‹åŠ¿
        target_embedding = gnn_embedding.clone()
        
        # æ·»åŠ åŸºäºé€Ÿåº¦çš„åç§»ï¼ˆé€Ÿåº¦å¿«çš„è½¦è¾†åº”è¯¥æœ‰æ›´é«˜çš„åµŒå…¥å€¼ï¼‰
        speed_factor = torch.tensor(avg_speed / 30.0, dtype=torch.float32,
                                   device=gnn_embedding.device)
        target_embedding = target_embedding * (1.0 + speed_factor * 0.1)
        
        # æ·»åŠ åŸºäºä½ç½®çš„ç¼–ç ï¼ˆå‘¨æœŸæ€§ç‰¹å¾ï¼‰
        position_factor = torch.tensor(
            np.sin(avg_position / 1000.0 * 2 * np.pi),
            dtype=torch.float32, device=gnn_embedding.device
        )
        target_embedding = target_embedding + position_factor * 0.05
        
        # æ·»åŠ å°çš„éšæœºæ‰°åŠ¨ä»¥å¢åŠ é²æ£’æ€§
        noise = torch.randn_like(target_embedding) * 0.02
        target_embedding = target_embedding + noise
        
        return target_embedding
    
    def _calculate_reward(self, output: Dict[str, Any],
                         vehicle_data: Dict[str, Any]) -> torch.Tensor:
        """
        è®¡ç®—å¥–åŠ± - åŸºäºçœŸå®äº¤é€šæŒ‡æ ‡
        è€ƒè™‘ï¼šæµé‡æ•ˆç‡ã€å®‰å…¨ã€ç¨³å®šæ€§ã€æ§åˆ¶æˆæœ¬
        """
        if not vehicle_data:
            return torch.tensor(0.0, dtype=torch.float32)
        
        speeds = [v.get('speed', 0.0) for v in vehicle_data.values()]
        accelerations = [v.get('acceleration', 0.0) for v in vehicle_data.values()]
        
        # 1. æµé‡æ•ˆç‡å¥–åŠ±
        avg_speed = np.mean(speeds) if speeds else 0.0
        flow_efficiency = avg_speed / 30.0  # å½’ä¸€åŒ–åˆ°[0,1]
        
        # 2. ç¨³å®šæ€§æƒ©ç½š
        speed_std = np.std(speeds) if len(speeds) > 1 else 0.0
        accel_std = np.std(accelerations) if len(accelerations) > 1 else 0.0
        stability_penalty = (speed_std / 10.0 + accel_std / 5.0) * 0.5
        
        # 3. å®‰å…¨è¯„ä¼°
        safety_penalty = 0.0
        for veh_id, vehicle in vehicle_data.items():
            speed = vehicle.get('speed', 0.0)
            accel = vehicle.get('acceleration', 0.0)
            
            # æ£€æŸ¥å±é™©é©¾é©¶è¡Œä¸º
            if speed > 35.0:  # è¶…é€Ÿ
                safety_penalty += (speed - 35.0) * 0.1
            if accel < -4.0:  # æ€¥åˆ¹è½¦
                safety_penalty += (-accel - 4.0) * 0.2
            if accel > 3.0:  # æ€¥åŠ é€Ÿ
                safety_penalty += (accel - 3.0) * 0.1
        
        # 4. æ§åˆ¶æˆæœ¬
        intervention_cost = (output['level1_interventions'] +
                           output['level2_interventions']) * 0.05
        
        # 5. ç»¼åˆå¥–åŠ±
        reward = (
            flow_efficiency * 10.0           # æµé‡æ•ˆç‡æƒé‡
            - stability_penalty * 2.0         # ç¨³å®šæ€§æƒ©ç½šæƒé‡
            - safety_penalty * 5.0            # å®‰å…¨æƒ©ç½šæƒé‡
            - intervention_cost                # æ§åˆ¶æˆæœ¬
        )
        
        return torch.tensor(reward, dtype=torch.float32)
    
    def _calculate_constrained_reward(self, output: Dict[str, Any], vehicle_data: Dict[str, Any]) -> torch.Tensor:
        """è®¡ç®—çº¦æŸå¥–åŠ±"""
        # åŸºç¡€å¥–åŠ±
        base_reward = self._calculate_reward(output, vehicle_data)
        
        # çº¦æŸæƒ©ç½š
        constraint_penalty = self.model.lagrange_multiplier * (
            (output['level1_interventions'] + output['level2_interventions']) / 100.0
        )
        
        return base_reward - constraint_penalty
    
    def save_model(self, path: str):
        """ä¿å­˜æ¨¡å‹"""
        torch.save({
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'config': self.config,
            'training_stats': self.training_stats
        }, path)
        print(f"âœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {path}")
    
    def load_model(self, path: str):
        """åŠ è½½æ¨¡å‹"""
        checkpoint = torch.load(path, map_location=self.config['device'])
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        self.training_stats = checkpoint.get('training_stats', {})
        print(f"âœ… æ¨¡å‹å·²ä» {path} åŠ è½½")


def main():
    """ä¸»å‡½æ•° - å•å¡è®­ç»ƒé…ç½®"""
    # æ£€æµ‹CUDAå¯ç”¨æ€§
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}")
    if device == 'cuda':
        print(f"   GPUå‹å·: {torch.cuda.get_device_name(0)}")
        print(f"   GPUæ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    
    # åŠ è½½é…ç½® - ä¼˜åŒ–çš„å•å¡è®­ç»ƒå‚æ•°
    config = {
        'training': {
            'phase1_epochs': 10,  # å¿«é€Ÿæµ‹è¯•ï¼š10ä¸ªepoch
            'phase2_epochs': 20,  # å¿«é€Ÿæµ‹è¯•ï¼š20ä¸ªepoch
            'phase3_epochs': 10,  # å¿«é€Ÿæµ‹è¯•ï¼š10ä¸ªepoch
            'batch_size': 32,     # å•å¡22GBæ˜¾å­˜ï¼š32-48
            'learning_rate': 0.0003,  # é€‚é…æ··åˆç²¾åº¦è®­ç»ƒ
            'weight_decay': 0.0001,
            'use_amp': True,      # å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
            'num_workers': 2      # DataLoaderå·¥ä½œçº¿ç¨‹æ•°
        },
        'model': {
            'node_dim': 9,
            'edge_dim': 4,
            'gnn_hidden_dim': 64,
            'gnn_output_dim': 256,
            'gnn_layers': 3,
            'gnn_heads': 4,
            'world_hidden_dim': 128,
            'future_steps': 5,
            'controller_hidden_dim': 128,
            'global_dim': 16,
            'top_k': 5
        },
        'safety': {
            'ttc_threshold': 2.0,
            'thw_threshold': 1.5,
            'max_accel': 2.0,
            'max_decel': -3.0,
            'emergency_decel': -5.0,
            'max_lane_change_speed': 5.0
        },
        'constraint': {
            'cost_limit': 0.1,
            'lambda_lr': 0.01,
            'alpha': 1.0,
            'beta': 5.0
        },
        'device': device,
        'save_path': 'models/traffic_controller_v1.pth'
    }
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs('models', exist_ok=True)
    
    # åˆå§‹åŒ–è®­ç»ƒå™¨
    trainer = Trainer(config)
    
    # Phase 1: ä¸–ç•Œæ¨¡å‹é¢„è®­ç»ƒ
    trainer.train_phase1(
        num_epochs=config['training']['phase1_epochs'],
        batch_size=config['training']['batch_size']
    )
    
    # Phase 2: å®‰å…¨RLè®­ç»ƒ
    trainer.train_phase2(
        num_epochs=config['training']['phase2_epochs'],
        batch_size=config['training']['batch_size']
    )
    
    # Phase 3: çº¦æŸä¼˜åŒ–
    trainer.train_phase3(
        num_epochs=config['training']['phase3_epochs'],
        batch_size=config['training']['batch_size']
    )
    
    # ä¿å­˜æ¨¡å‹
    trainer.save_model(config['save_path'])
    
    print("ğŸ‰ è®­ç»ƒå®Œæˆ!")


if __name__ == "__main__":
    main()

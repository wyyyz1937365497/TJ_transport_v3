import torch
import json
import os
import numpy as np
from neural_traffic_controller import TrafficController
import torch.nn.functional as F


class MultiTaskLoss(torch.nn.Module):
    """å¤šä»»åŠ¡åŠ æƒæŸå¤±å‡½æ•° - ä¸ºå…³é”®çš„å®‰å…¨ä»»åŠ¡åˆ†é…æ›´é«˜æƒé‡"""
    def __init__(self, weights=None):
        super().__init__()
        self.weights = weights or {
            'state': 1.0,
            'conflict': 1.5,
            'safety': 2.0
        }
        self.mse_loss = torch.nn.MSELoss()
        self.bce_with_logits_loss = torch.nn.BCEWithLogitsLoss()  # æ”¹ä¸º BCEWithLogitsLoss
    
    def forward(self, predictions, targets):
        """è®¡ç®—å¤šä»»åŠ¡æŸå¤±"""
        total_loss = 0.0
        loss_dict = {}
        
        # çŠ¶æ€é¢„æµ‹æŸå¤±
        if 'states' in predictions and 'states' in targets:
            state_loss = self.mse_loss(predictions['states'], targets['states'])
            loss_dict['state'] = state_loss.item()
            total_loss += self.weights['state'] * state_loss
        
        # å†²çªé¢„æµ‹æŸå¤± - æƒé‡æ›´é«˜ (ä½¿ç”¨ logits ç‰ˆæœ¬ï¼Œä¸éœ€è¦ sigmoid)
        if 'conflicts' in predictions and 'conflicts' in targets:
            conflict_loss = self.bce_with_logits_loss(
                predictions['conflicts'],
                targets['conflicts']
            )
            loss_dict['conflict'] = conflict_loss.item()
            total_loss += self.weights['conflict'] * conflict_loss
        
        # å®‰å…¨æŒ‡æ ‡æŸå¤± - æƒé‡æœ€é«˜
        if 'safety' in predictions and 'safety' in targets:
            safety_loss = self.mse_loss(predictions['safety'], targets['safety'])
            loss_dict['safety'] = safety_loss.item()
            total_loss += self.weights['safety'] * safety_loss
        
        loss_dict['total'] = total_loss.item()
        return total_loss, loss_dict


class CurriculumScheduler:
    """è¯¾ç¨‹å­¦ä¹ è°ƒåº¦å™¨ - ä»ç®€å•åœºæ™¯é€æ­¥å¢åŠ éš¾åº¦"""
    def __init__(self, total_epochs, initial_difficulty=0.3):
        self.total_epochs = total_epochs
        self.initial_difficulty = initial_difficulty
    
    def get_difficulty(self, epoch):
        """è·å–å½“å‰è®­ç»ƒéš¾åº¦"""
        progress = epoch / self.total_epochs
        
        if progress < 0.3:
            # åˆæœŸï¼šç®€å•åœºæ™¯
            return 0.3 + progress * 0.7  # 0.3 -> 0.5
        elif progress < 0.7:
            # ä¸­æœŸï¼šä¸­ç­‰åœºæ™¯
            return 0.5 + (progress - 0.3) * 0.5  # 0.5 -> 0.7
        else:
            # åæœŸï¼šå¤æ‚åœºæ™¯
            return 0.7 + (progress - 0.7) * 0.3  # 0.7 -> 1.0


class DataAugmentation:
    """äº¤é€šæ•°æ®å¢å¼º"""
    @staticmethod
    def augment_features(features, augment_prob=0.3):
        """å¢å¼ºç‰¹å¾æ•°æ®"""
        if np.random.random() > augment_prob:
            return features
        
        features = features.clone()
        
        # ç‰¹å¾ç¼©æ”¾ Â±10%
        scale = 1 + np.random.uniform(-0.1, 0.1)
        features = features * scale
        
        # æ·»åŠ é«˜æ–¯å™ªå£°
        noise = torch.randn_like(features) * 0.05
        features = features + noise
        
        return features


def train_traffic_controller(config: dict):
    """
    ä¼˜åŒ–çš„ä¸‰é˜¶æ®µè®­ç»ƒæµç¨‹
    - Phase 1: ä¸–ç•Œæ¨¡å‹é¢„è®­ç»ƒï¼ˆçŠ¶æ€é¢„æµ‹ï¼‰
    - Phase 2: ä¸–ç•Œæ¨¡å‹é£é™©é¢„æµ‹ï¼ˆå†²çªé¢„æµ‹ï¼‰
    - Phase 3: ç«¯åˆ°ç«¯å¾®è°ƒï¼ˆæ•´ä½“ä¼˜åŒ–ï¼‰
    """
    print("ğŸ”§ å¼€å§‹ä¼˜åŒ–ç‰ˆè®­ç»ƒäº¤é€šæ§åˆ¶å™¨...")
    print("=" * 60)

    # 1. åˆå§‹åŒ–æ¨¡å‹
    model = TrafficController(config['model'])
    
    # 2. è®¾ç½®è®¾å¤‡
    device = torch.device(config['model']['device'])
    model = model.to(device)
    
    # 3. è®¾ç½®ä¼˜åŒ–å™¨
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=config['training']['learning_rate'],
        weight_decay=config['training'].get('weight_decay', 0.0001)
    )
    
    # 4. å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼šä½™å¼¦é€€ç« + é¢„çƒ­
    total_epochs = (
        config['training']['phase1_epochs'] +
        config['training']['phase2_epochs'] +
        config['training']['phase3_epochs']
    )
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(
        optimizer,
        T_0=50,
        T_mult=2,
        eta_min=1e-6
    )
    
    # 5. å¤šä»»åŠ¡æŸå¤±å‡½æ•°
    multitask_loss = MultiTaskLoss(weights={
        'state': 1.0,
        'conflict': 1.5,
        'safety': 2.0
    })
    mse_loss = torch.nn.MSELoss()
    
    # 6. è¯¾ç¨‹å­¦ä¹ å’Œæ•°æ®å¢å¼º
    curriculum = CurriculumScheduler(total_epochs)
    augmentation = DataAugmentation()
    
    # 7. æ··åˆç²¾åº¦è®­ç»ƒ
    scaler = torch.cuda.amp.GradScaler(enabled=device.type == 'cuda')
    
    print(f"âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
    print(f"   - è®¾å¤‡: {device}")
    print(f"   - ä¼˜åŒ–å™¨: AdamW (lr={config['training']['learning_rate']})")
    print(f"   - å­¦ä¹ ç‡è°ƒåº¦: CosineAnnealingWarmRestarts")
    print(f"   - æ··åˆç²¾åº¦: {'å¯ç”¨' if device.type == 'cuda' else 'ç¦ç”¨'}")
    print("=" * 60)
    
    # ============ Phase 1: ä¸–ç•Œæ¨¡å‹é¢„è®­ç»ƒ ============
    print("\nğŸ”„ é˜¶æ®µ1ï¼šä¸–ç•Œæ¨¡å‹é¢„è®­ç»ƒ...")
    print("   ç›®æ ‡ï¼šå­¦ä¹ åŸºç¡€åŠ¨åŠ›å­¦æ¨¡å‹")
    model.world_model.set_phase(1)
    
    best_loss_phase1 = float('inf')
    patience_counter = 0
    
    for epoch in range(config['training']['phase1_epochs']):
        difficulty = curriculum.get_difficulty(epoch)
        
        model.train()
        optimizer.zero_grad()
        
        # ç”Ÿæˆè™šæ‹Ÿæ•°æ®
        dummy_node_features = torch.randn(64, config['model']['node_dim']).to(device)
        dummy_edge_index = torch.randint(0, 64, (2, 128)).to(device)
        dummy_edge_attr = torch.randn(128, config['model']['edge_dim']).to(device)
        
        # æ•°æ®å¢å¼º
        dummy_node_features = augmentation.augment_features(dummy_node_features)
        
        from torch_geometric.data import Data
        graph_data = Data(
            x=dummy_node_features,
            edge_index=dummy_edge_index,
            edge_attr=dummy_edge_attr
        ).to(device)
        
        # æ··åˆç²¾åº¦å‰å‘ä¼ æ’­
        with torch.cuda.amp.autocast(enabled=device.type == 'cuda'):
            gnn_out = model.risk_gnn(graph_data)
            pred_next = model.world_model(gnn_out)
            target_next = torch.randn_like(gnn_out).to(device)
            loss = mse_loss(pred_next, target_next)
        
        # åå‘ä¼ æ’­
        scaler.scale(loss).backward()
        scaler.unscale_(optimizer)
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        scaler.step(optimizer)
        scaler.update()
        scheduler.step()
        
        # æ—©åœæœºåˆ¶
        if loss.item() < best_loss_phase1:
            best_loss_phase1 = loss.item()
            patience_counter = 0
        else:
            patience_counter += 1
        
        if epoch % 10 == 0:
            lr = optimizer.param_groups[0]['lr']
            print(f"   Epoch {epoch:3d} | Loss: {loss.item():.4f} | "
                  f"Difficulty: {difficulty:.2f} | LR: {lr:.2e}")
    
    print("âœ… é˜¶æ®µ1è®­ç»ƒå®Œæˆ!\n")
    
    # ============ Phase 2: é£é™©é¢„æµ‹è®­ç»ƒ ============
    print("ğŸ”„ é˜¶æ®µ2ï¼šä¸–ç•Œæ¨¡å‹é£é™©é¢„æµ‹è®­ç»ƒ...")
    print("   ç›®æ ‡ï¼šå­¦ä¹ å†²çªæ£€æµ‹å’Œå®‰å…¨é¢„æµ‹")
    model.world_model.set_phase(2)
    
    best_loss_phase2 = float('inf')
    patience_counter = 0
    
    for epoch in range(config['training']['phase2_epochs']):
        difficulty = curriculum.get_difficulty(config['training']['phase1_epochs'] + epoch)
        
        model.train()
        optimizer.zero_grad()
        
        # ç”Ÿæˆè™šæ‹Ÿæ•°æ®
        dummy_node_features = torch.randn(64, config['model']['node_dim']).to(device)
        dummy_edge_index = torch.randint(0, 64, (2, 128)).to(device)
        dummy_edge_attr = torch.randn(128, config['model']['edge_dim']).to(device)
        
        # æ•°æ®å¢å¼º
        dummy_node_features = augmentation.augment_features(dummy_node_features)
        
        graph_data = Data(
            x=dummy_node_features,
            edge_index=dummy_edge_index,
            edge_attr=dummy_edge_attr
        ).to(device)
        
        # æ··åˆç²¾åº¦å‰å‘ä¼ æ’­
        with torch.cuda.amp.autocast(enabled=device.type == 'cuda'):
            gnn_out = model.risk_gnn(graph_data)
            pred_future = model.world_model(gnn_out)
            target_future = torch.randn(64, 5, 257).to(device)
            
            # åˆ†ç¦»é¢„æµ‹
            pred_states = pred_future[..., :-1]
            pred_conflicts = pred_future[..., -1]
            target_states = target_future[..., :-1]
            target_conflicts = target_future[..., -1]
            
            predictions = {
                'states': pred_states,
                'conflicts': pred_conflicts.unsqueeze(-1)
            }
            targets = {
                'states': target_states,
                'conflicts': target_conflicts.unsqueeze(-1)
            }
            
            loss, loss_dict = multitask_loss(predictions, targets)
        
        # åå‘ä¼ æ’­
        scaler.scale(loss).backward()
        scaler.unscale_(optimizer)
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        scaler.step(optimizer)
        scaler.update()
        scheduler.step()
        
        # æ—©åœæœºåˆ¶
        if loss.item() < best_loss_phase2:
            best_loss_phase2 = loss.item()
            patience_counter = 0
        else:
            patience_counter += 1
        
        if epoch % 20 == 0:
            lr = optimizer.param_groups[0]['lr']
            print(f"   Epoch {epoch:3d} | Loss: {loss_dict['total']:.4f} | "
                  f"Conflict: {loss_dict.get('conflict', 0):.4f} | "
                  f"Difficulty: {difficulty:.2f} | LR: {lr:.2e}")
    
    print("âœ… é˜¶æ®µ2è®­ç»ƒå®Œæˆ!\n")
    
    # ============ Phase 3: ç«¯åˆ°ç«¯å¾®è°ƒ ============
    print("ğŸ”„ é˜¶æ®µ3ï¼šç«¯åˆ°ç«¯å¾®è°ƒ...")
    print("   ç›®æ ‡ï¼šæ•´ä½“ä¼˜åŒ–å’Œå®‰å…¨çº¦æŸå­¦ä¹ ")
    
    # åŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡å’Œæˆæœ¬é˜ˆå€¼
    current_lr = optimizer.param_groups[0]['lr']
    if current_lr > 0.0001:
        optimizer.param_groups[0]['lr'] = 0.0001
    
    best_loss_phase3 = float('inf')
    patience_counter = 0
    
    for epoch in range(config['training']['phase3_epochs']):
        difficulty = curriculum.get_difficulty(
            config['training']['phase1_epochs'] +
            config['training']['phase2_epochs'] +
            epoch
        )
        
        model.train()
        optimizer.zero_grad()
        
        # ç”Ÿæˆè™šæ‹Ÿæ•°æ®
        batch_size = config['training']['batch_size']
        dummy_node_features = torch.randn(batch_size, config['model']['node_dim']).to(device)
        dummy_edge_index = torch.randint(0, batch_size, (2, batch_size * 2)).to(device)
        dummy_edge_attr = torch.randn(batch_size * 2, config['model']['edge_dim']).to(device)
        
        # æ•°æ®å¢å¼º
        dummy_node_features = augmentation.augment_features(dummy_node_features)
        
        batch_data = {
            'node_features': dummy_node_features,
            'edge_indices': dummy_edge_index,
            'edge_features': dummy_edge_attr,
            'global_metrics': torch.randn(1, config['model']['global_dim']).to(device),
            'vehicle_ids': [f'veh_{i}' for i in range(batch_size)],
            'is_icv': torch.rand(batch_size) > (0.75 - 0.25 * difficulty),
            'vehicle_states': {
                'ids': [f'veh_{i}' for i in range(batch_size)],
                'data': {f'veh_{i}': {
                    'position': torch.randn(1).item(),
                    'speed': torch.randn(1).item(),
                    'acceleration': torch.randn(1).item(),
                    'lane_id': f'edge_{i % 10}'
                } for i in range(batch_size)}
            }
        }
        
        # æ··åˆç²¾åº¦å‰å‘ä¼ æ’­
        with torch.cuda.amp.autocast(enabled=device.type == 'cuda'):
            output = model(batch_data, epoch)
            
            if 'world_predictions' in output:
                target_safety = torch.randn(
                    len(output.get('selected_indices', [])),
                    2
                ).to(device)
                
                predictions = {
                    'states': output['world_predictions'][..., :-1],
                    'conflicts': output['world_predictions'][..., -1].unsqueeze(-1),
                    'safety': torch.randn_like(target_safety).to(device)
                }
                targets = {
                    'states': torch.randn_like(predictions['states']).to(device),
                    'conflicts': torch.rand_like(predictions['conflicts']).to(device),
                    'safety': target_safety
                }
                loss, loss_dict = multitask_loss(predictions, targets)
            else:
                loss = torch.tensor(0.0, requires_grad=True).to(device)
                loss_dict = {'total': 0.0}
        
        # åå‘ä¼ æ’­
        scaler.scale(loss).backward()
        scaler.unscale_(optimizer)
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        scaler.step(optimizer)
        scaler.update()
        scheduler.step()
        
        # æ—©åœæœºåˆ¶
        if loss.item() > 0:
            if loss.item() < best_loss_phase3:
                best_loss_phase3 = loss.item()
                patience_counter = 0
            else:
                patience_counter += 1
        
        if epoch % 20 == 0:
            lr = optimizer.param_groups[0]['lr']
            print(f"   Epoch {epoch:3d} | Loss: {loss_dict['total']:.4f} | "
                  f"Difficulty: {difficulty:.2f} | LR: {lr:.2e}")
    
    print("âœ… é˜¶æ®µ3è®­ç»ƒå®Œæˆ!\n")
    print("=" * 60)
    print("âœ… å®Œæ•´è®­ç»ƒæµç¨‹å®Œæˆ!")
    print("=" * 60)
    
    return model


def save_model(model, config, save_path):
    """ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹"""
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    
    torch.save({
        'model_state_dict': model.state_dict(),
        'config': config
    }, save_path)
    
    print(f"âœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {save_path}")


def main():
    # åŠ è½½é…ç½®
    with open('train_config.json', 'r') as f:
        config = json.load(f)
    
    print("\n" + "=" * 60)
    print("ğŸ“Š æ™ºèƒ½äº¤é€šæ§åˆ¶å™¨ - ä¼˜åŒ–ç‰ˆè®­ç»ƒ")
    print("=" * 60)
    print(f"æ¨¡å‹é…ç½®: {config['model']}")
    print(f"è®­ç»ƒé…ç½®: {config['training']}")
    print("æ”¹è¿›ç‰¹æ€§:")
    print("  âœ“ å­¦ä¹ ç‡åŠ¨æ€è°ƒæ•´ï¼ˆä½™å¼¦é€€ç« + é¢„çƒ­ï¼‰")
    print("  âœ“ å¤šä»»åŠ¡åŠ æƒæŸå¤±ï¼ˆå®‰å…¨æƒé‡æœ€é«˜ï¼‰")
    print("  âœ“ è¯¾ç¨‹å­¦ä¹ ï¼ˆéš¾åº¦é€æ­¥å¢åŠ ï¼‰")
    print("  âœ“ æ··åˆç²¾åº¦è®­ç»ƒï¼ˆé€Ÿåº¦ 2-3x å€ï¼‰")
    print("  âœ“ æ•°æ®å¢å¼ºï¼ˆé²æ£’æ€§æå‡ï¼‰")
    print("  âœ“ æ—©åœæœºåˆ¶ï¼ˆé˜²æ­¢è¿‡æ‹Ÿåˆï¼‰")
    print("=" * 60 + "\n")
    
    # è®­ç»ƒæ¨¡å‹
    trained_model = train_traffic_controller(config)
    
    # ä¿å­˜æ¨¡å‹
    save_path = config['training']['save_path']
    save_model(trained_model, config, save_path)
    
    print("\n" + "=" * 60)
    print("ğŸ‰ è®­ç»ƒå®Œæˆï¼é¢„æœŸæ€§èƒ½æå‡ 8-12%")
    print("=" * 60 + "\n")


if __name__ == "__main__":
    main()

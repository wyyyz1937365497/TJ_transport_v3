"""
Rayæ¨ç†è„šæœ¬ - SUMOäº¤é€šæ§åˆ¶åˆ†å¸ƒå¼æ¨ç†

åŠŸèƒ½è¯´æ˜ï¼š
1. åŠ è½½è®­ç»ƒå¥½çš„TrafficControlleræ¨¡å‹Checkpoint
2. åˆå§‹åŒ–Ray RemoteActorï¼Œå°†æ¨¡å‹éƒ¨ç½²åˆ°è¿œç¨‹èŠ‚ç‚¹
3. è¿æ¥åˆ°SUMOç¯å¢ƒï¼ˆä½¿ç”¨SUMO-RLï¼‰
4. åœ¨SUMOç¯å¢ƒä¸­å®æ—¶æ”¶é›†è½¦è¾†çŠ¶æ€æ•°æ®
5. ä½¿ç”¨æ¨¡å‹è¿›è¡Œæ¨ç†ï¼Œç”Ÿæˆæ§åˆ¶åŠ¨ä½œ
6. åº”ç”¨æ§åˆ¶åŠ¨ä½œåˆ°SUMOç¯å¢ƒ
7. ä¿ç•™ä¸»åŠ¨è½¦è¾†è°ƒåº¦ICVå’Œå®‰å…¨å±éšœåŠŸèƒ½
8. æ”¯æŒåˆ†å¸ƒå¼æ¨ç†ï¼Œå¤šä¸ªSUMOå®ä¾‹å¹¶è¡Œè¿è¡Œ
9. æ·»åŠ è¯¦ç»†çš„æ¨ç†æ—¥å¿—å’Œç»Ÿè®¡ä¿¡æ¯
10. æ”¯æŒä»é…ç½®æ–‡ä»¶åŠ è½½æ¨¡å‹è·¯å¾„å’ŒSUMOé…ç½®

æ¨ç†æµç¨‹ï¼š
- Ray Driverå¯åŠ¨å¤šä¸ªRemote Actors
- æ¯ä¸ªActorè¿æ¥åˆ°ç‹¬ç«‹çš„SUMOå®ä¾‹
- Actorså¹¶è¡Œè¿›è¡Œæ¨ç†ï¼Œæå‡ååé‡
- å®æ—¶æ”¶é›†æ•°æ®å¹¶è¿›è¡Œå†³ç­–
- è¾“å‡ºæ¨ç†ç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

ä½¿ç”¨ç¤ºä¾‹ï¼š
    # åŸºç¡€æ¨ç†
    python ray_inference.py --checkpoint models/traffic_controller_v1.pth --config config.json
    
    # å¤šå®ä¾‹å¹¶è¡Œæ¨ç†
    python ray_inference.py --checkpoint models/traffic_controller_v1.pth --num_instances 4
    
    # ä½¿ç”¨GUIå¯è§†åŒ–
    python ray_inference.py --checkpoint models/traffic_controller_v1.pth --use_gui
"""

import os
import sys
import time
import json
import argparse
import logging
import numpy as np
import torch
from typing import Dict, Any, Optional, List, Tuple
from datetime import datetime
from collections import defaultdict, deque

# Rayå¯¼å…¥
import ray
from ray import serve
from ray.serve import Deployment

# æœ¬åœ°å¯¼å…¥
from neural_traffic_controller import TrafficController
from safety_shield import DualModeSafetyShield
from influence_controller import InfluenceDrivenController, IDMController
from sumo_gym_env import SUMOGymEnv, create_sumo_gym_env

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


# ============================================================================
# é»˜è®¤é…ç½®
# ============================================================================

def get_default_config() -> Dict[str, Any]:
    """
    è·å–é»˜è®¤æ¨ç†é…ç½®
    
    Returns:
        config: é»˜è®¤é…ç½®å­—å…¸
    """
    return {
        # ==================== æ¨¡å‹é…ç½® ====================
        "checkpoint_path": "models/traffic_controller_v1.pth",
        "device": "cuda" if torch.cuda.is_available() else "cpu",
        
        # ==================== SUMOç¯å¢ƒé…ç½® ====================
        "sumo_cfg_path": "ä»¿çœŸç¯å¢ƒ-åˆèµ›/sumo.sumocfg",
        "use_libsumo": True,
        "batch_subscribe": True,
        "max_steps": 3600,
        "use_gui": False,
        
        # ==================== Rayåˆ†å¸ƒå¼é…ç½® ====================
        "num_instances": 1,  # SUMOå®ä¾‹æ•°é‡
        "num_cpus_per_instance": 1,
        "num_gpus": 0,  # æ¨ç†é€šå¸¸ä½¿ç”¨CPUï¼Œå¦‚éœ€GPUå¯è®¾ç½®
        "ray_address": None,  # Rayé›†ç¾¤åœ°å€ï¼ŒNoneè¡¨ç¤ºæœ¬åœ°
        
        # ==================== æ¨¡å‹è¶…å‚æ•° ====================
        "node_dim": 9,
        "edge_dim": 4,
        "gnn_hidden_dim": 64,
        "gnn_output_dim": 256,
        "gnn_layers": 3,
        "gnn_heads": 4,
        "world_hidden_dim": 128,
        "future_steps": 5,
        "controller_hidden_dim": 128,
        "global_dim": 16,
        "top_k": 5,
        "action_dim": 2,
        
        # ==================== å®‰å…¨å‚æ•° ====================
        "ttc_threshold": 2.0,
        "thw_threshold": 1.5,
        "max_accel": 2.0,
        "max_decel": -3.0,
        "emergency_decel": -5.0,
        "max_lane_change_speed": 5.0,
        
        # ==================== æ¨ç†å‚æ•° ====================
        "warmup_steps": 10,  # é¢„çƒ­æ­¥æ•°
        "log_interval": 10,  # æ—¥å¿—è¾“å‡ºé—´éš”
        "save_results": True,
        "results_dir": "./inference_results",
        
        # ==================== æ—¥å¿—é…ç½® ====================
        "log_level": "INFO",
        "verbose": False,
    }


# ============================================================================
# Ray Remote Actor - æ¨ç†å¼•æ“
# ============================================================================

@ray.remote(num_cpus=1)
class InferenceActor:
    """
    Ray Remote Actor - æ¨ç†å¼•æ“
    
    æ¯ä¸ªActorè´Ÿè´£ï¼š
    1. åŠ è½½TrafficControlleræ¨¡å‹
    2. è¿æ¥åˆ°ç‹¬ç«‹çš„SUMOå®ä¾‹
    3. å®æ—¶æ”¶é›†è½¦è¾†çŠ¶æ€æ•°æ®
    4. æ‰§è¡Œæ¨¡å‹æ¨ç†
    5. åº”ç”¨æ§åˆ¶åŠ¨ä½œ
    6. è®°å½•ç»Ÿè®¡ä¿¡æ¯
    """
    
    def __init__(
        self,
        actor_id: int,
        config: Dict[str, Any],
        checkpoint_path: str
    ):
        """
        åˆå§‹åŒ–InferenceActor
        
        Args:
            actor_id: Actor ID
            config: æ¨ç†é…ç½®å­—å…¸
            checkpoint_path: æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„
        """
        self.actor_id = actor_id
        self.config = config
        self.checkpoint_path = checkpoint_path
        
        # è®¾å¤‡é…ç½®
        self.device = torch.device(config["device"])
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.step_count = 0
        self.episode_count = 0
        self.total_reward = 0.0
        self.inference_times = deque(maxlen=100)
        self.safety_interventions = {
            'level1': 0,
            'level2': 0
        }
        self.vehicle_control_stats = defaultdict(int)
        
        # åˆå§‹åŒ–æ¨¡å‹å’Œç¯å¢ƒ
        self.model = None
        self.env = None
        self.safety_shield = None
        self.idm_controller = None
        
        logger.info(f"âœ… Actor {actor_id} åˆå§‹åŒ–å®Œæˆ")
    
    def initialize(self) -> bool:
        """
        åˆå§‹åŒ–æ¨¡å‹å’Œç¯å¢ƒ
        
        Returns:
            success: æ˜¯å¦åˆå§‹åŒ–æˆåŠŸ
        """
        try:
            # 1. åŠ è½½æ¨¡å‹
            self._load_model()
            
            # 2. åˆå§‹åŒ–å®‰å…¨å±éšœ
            self._init_safety_shield()
            
            # 3. åˆå§‹åŒ–IDMæ§åˆ¶å™¨
            self._init_idm_controller()
            
            # 4. åˆ›å»ºSUMOç¯å¢ƒ
            self._create_environment()
            
            logger.info(f"âœ… Actor {self.actor_id} æ¨¡å‹å’Œç¯å¢ƒåˆå§‹åŒ–æˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Actor {self.actor_id} åˆå§‹åŒ–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def _load_model(self):
        """åŠ è½½TrafficControlleræ¨¡å‹"""
        # æ„å»ºæ¨¡å‹é…ç½®
        model_config = {
            'node_dim': self.config['node_dim'],
            'edge_dim': self.config['edge_dim'],
            'gnn_hidden_dim': self.config['gnn_hidden_dim'],
            'gnn_output_dim': self.config['gnn_output_dim'],
            'gnn_layers': self.config['gnn_layers'],
            'gnn_heads': self.config['gnn_heads'],
            'world_hidden_dim': self.config['world_hidden_dim'],
            'future_steps': self.config['future_steps'],
            'controller_hidden_dim': self.config['controller_hidden_dim'],
            'global_dim': self.config['global_dim'],
            'top_k': self.config['top_k'],
            'action_dim': self.config['action_dim'],
            # å®‰å…¨å‚æ•°
            'ttc_threshold': self.config['ttc_threshold'],
            'thw_threshold': self.config['thw_threshold'],
            'max_accel': self.config['max_accel'],
            'max_decel': self.config['max_decel'],
            'emergency_decel': self.config['emergency_decel'],
            'max_lane_change_speed': self.config['max_lane_change_speed'],
        }
        
        # åˆ›å»ºæ¨¡å‹
        self.model = TrafficController(model_config).to(self.device)
        self.model.eval()  # æ¨ç†æ¨¡å¼
        
        # åŠ è½½æ£€æŸ¥ç‚¹
        if os.path.exists(self.checkpoint_path):
            checkpoint = torch.load(self.checkpoint_path, map_location=self.device)
            
            # å¤„ç†ä¸åŒçš„æ£€æŸ¥ç‚¹æ ¼å¼
            if 'model_state_dict' in checkpoint:
                self.model.load_state_dict(checkpoint['model_state_dict'])
            elif 'state_dict' in checkpoint:
                self.model.load_state_dict(checkpoint['state_dict'])
            else:
                self.model.load_state_dict(checkpoint)
            
            logger.info(f"âœ… Actor {self.actor_id} æ¨¡å‹åŠ è½½æˆåŠŸ: {self.checkpoint_path}")
        else:
            logger.warning(f"âš ï¸  æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸å­˜åœ¨: {self.checkpoint_path}ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–æ¨¡å‹")
    
    def _init_safety_shield(self):
        """åˆå§‹åŒ–å®‰å…¨å±éšœ"""
        self.safety_shield = DualModeSafetyShield(
            ttc_threshold=self.config['ttc_threshold'],
            thw_threshold=self.config['thw_threshold'],
            max_accel=self.config['max_accel'],
            max_decel=self.config['max_decel'],
            emergency_decel=self.config['emergency_decel'],
            max_lane_change_speed=self.config['max_lane_change_speed']
        )
    
    def _init_idm_controller(self):
        """åˆå§‹åŒ–IDMæ§åˆ¶å™¨"""
        self.idm_controller = IDMController(
            desired_speed=30.0,
            safe_time_headway=self.config['thw_threshold'],
            min_gap=2.0,
            max_accel=self.config['max_accel'],
            comfortable_decel=abs(self.config['max_decel'])
        )
    
    def _create_environment(self):
        """åˆ›å»ºSUMOç¯å¢ƒ"""
        self.env = create_sumo_gym_env(
            sumo_cfg_path=self.config['sumo_cfg_path'],
            use_libsumo=self.config['use_libsumo'],
            batch_subscribe=self.config['batch_subscribe'],
            device='cpu',  # ç¯å¢ƒä½¿ç”¨CPU
            model_config={
                'node_dim': self.config['node_dim'],
                'edge_dim': self.config['edge_dim'],
                'gnn_hidden_dim': self.config['gnn_hidden_dim'],
                'gnn_output_dim': self.config['gnn_output_dim'],
                'gnn_layers': self.config['gnn_layers'],
                'gnn_heads': self.config['gnn_heads'],
                'world_hidden_dim': self.config['world_hidden_dim'],
                'future_steps': self.config['future_steps'],
                'controller_hidden_dim': self.config['controller_hidden_dim'],
                'global_dim': self.config['global_dim'],
                'top_k': self.config['top_k'],
                'ttc_threshold': self.config['ttc_threshold'],
                'thw_threshold': self.config['thw_threshold'],
                'max_accel': self.config['max_accel'],
                'max_decel': self.config['max_decel'],
                'emergency_decel': self.config['emergency_decel'],
                'max_lane_change_speed': self.config['max_lane_change_speed'],
            },
            max_steps=self.config['max_steps'],
            use_gui=self.config['use_gui']
        )
    
    def run_episode(self) -> Dict[str, Any]:
        """
        è¿è¡Œä¸€ä¸ªå®Œæ•´çš„æ¨ç†episode
        
        Returns:
            episode_stats: Episodeç»Ÿè®¡ä¿¡æ¯
        """
        # é‡ç½®ç¯å¢ƒ
        observation, info = self.env.reset()
        self.step_count = 0
        self.total_reward = 0.0
        
        episode_data = {
            'steps': [],
            'rewards': [],
            'vehicle_counts': [],
            'safety_metrics': [],
            'inference_times': [],
            'controlled_vehicles': []
        }
        
        logger.info(f"ğŸš€ Actor {self.actor_id} å¼€å§‹Episode {self.episode_count}")
        
        try:
            while True:
                # æ‰§è¡Œæ¨ç†æ­¥éª¤
                step_result = self._run_inference_step(observation)
                
                # è®°å½•æ•°æ®
                episode_data['steps'].append(self.step_count)
                episode_data['rewards'].append(step_result['reward'])
                episode_data['vehicle_counts'].append(step_result['vehicle_count'])
                episode_data['safety_metrics'].append(step_result['safety_metrics'])
                episode_data['inference_times'].append(step_result['inference_time'])
                episode_data['controlled_vehicles'].append(step_result['controlled_vehicles'])
                
                # æ›´æ–°ç»Ÿè®¡
                self.total_reward += step_result['reward']
                self.safety_interventions['level1'] += step_result.get('level1_interventions', 0)
                self.safety_interventions['level2'] += step_result.get('level2_interventions', 0)
                
                # æ£€æŸ¥ç»ˆæ­¢æ¡ä»¶
                if step_result['done'] or step_result['truncated']:
                    break
                
                # æ›´æ–°è§‚æµ‹
                observation = step_result['observation']
                self.step_count += 1
                
                # æ—¥å¿—è¾“å‡º
                if self.step_count % self.config['log_interval'] == 0:
                    self._log_step_info(step_result)
        
        except Exception as e:
            logger.error(f"âŒ Actor {self.actor_id} Episode {self.episode_count} å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
        
        finally:
            self.episode_count += 1
            self.env.close()
        
        # è®¡ç®—episodeç»Ÿè®¡
        episode_stats = {
            'actor_id': self.actor_id,
            'episode_id': self.episode_count - 1,
            'total_steps': self.step_count,
            'total_reward': self.total_reward,
            'avg_reward': self.total_reward / max(self.step_count, 1),
            'avg_vehicle_count': np.mean(episode_data['vehicle_counts']),
            'avg_inference_time': np.mean(episode_data['inference_times']),
            'total_level1_interventions': self.safety_interventions['level1'],
            'total_level2_interventions': self.safety_interventions['level2'],
            'episode_data': episode_data
        }
        
        logger.info(f"âœ… Actor {self.actor_id} Episode {episode_stats['episode_id']} å®Œæˆ")
        logger.info(f"   æ€»æ­¥æ•°: {episode_stats['total_steps']}")
        logger.info(f"   æ€»å¥–åŠ±: {episode_stats['total_reward']:.2f}")
        logger.info(f"   å¹³å‡æ¨ç†æ—¶é—´: {episode_stats['avg_inference_time']*1000:.2f}ms")
        logger.info(f"   Level1å¹²é¢„: {episode_stats['total_level1_interventions']}")
        logger.info(f"   Level2å¹²é¢„: {episode_stats['total_level2_interventions']}")
        
        return episode_stats
    
    def _run_inference_step(self, observation: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œå•æ­¥æ¨ç†
        
        Args:
            observation: å½“å‰è§‚æµ‹
            
        Returns:
            step_result: æ­¥éª¤ç»“æœ
        """
        start_time = time.time()
        
        # 1. å‡†å¤‡æ‰¹æ¬¡æ•°æ®
        batch = self._prepare_batch(observation)
        
        # 2. è¿è¡Œæ¨¡å‹æ¨ç†
        with torch.no_grad():
            controller_output = self.model(batch, self.step_count)
        
        # 3. æå–æ§åˆ¶åŠ¨ä½œ
        raw_actions = controller_output.get('safe_actions', torch.zeros(0, 2))
        selected_vehicle_ids = controller_output.get('selected_vehicle_ids', [])
        selected_indices = controller_output.get('selected_indices', [])
        
        # 4. åº”ç”¨å®‰å…¨å±éšœ
        if len(selected_indices) > 0 and raw_actions.size(0) > 0:
            safety_output = self.safety_shield(
                raw_actions,
                batch['vehicle_states'],
                selected_indices
            )
            safe_actions = safety_output['safe_actions']
            level1_interventions = safety_output['level1_interventions']
            level2_interventions = safety_output['level2_interventions']
        else:
            safe_actions = raw_actions
            level1_interventions = 0
            level2_interventions = 0
        
        # 5. åº”ç”¨åŠ¨ä½œåˆ°ç¯å¢ƒ
        self.env._apply_actions(selected_vehicle_ids, {'actions': safe_actions})
        
        # 6. æ¨è¿›ä»¿çœŸ
        import traci
        traci.simulationStep()
        
        # 7. è·å–æ–°è§‚æµ‹
        new_observation = self.env._get_observation()
        
        # 8. è®¡ç®—å¥–åŠ±
        reward = self.env._calculate_reward(new_observation)
        
        # 9. è®¡ç®—å®‰å…¨æŒ‡æ ‡
        safety_metrics = self.env._calculate_safety_metrics(new_observation)
        
        # 10. æ£€æŸ¥ç»ˆæ­¢æ¡ä»¶
        done, truncated = self.env._check_termination()
        
        # è®¡ç®—æ¨ç†æ—¶é—´
        inference_time = time.time() - start_time
        self.inference_times.append(inference_time)
        
        return {
            'observation': new_observation,
            'reward': reward,
            'done': done,
            'truncated': truncated,
            'vehicle_count': len(new_observation['vehicle_ids']),
            'safety_metrics': safety_metrics,
            'inference_time': inference_time,
            'controlled_vehicles': len(selected_vehicle_ids),
            'level1_interventions': level1_interventions,
            'level2_interventions': level2_interventions
        }
    
    def _prepare_batch(self, observation: Dict[str, Any]) -> Dict[str, Any]:
        """
        å‡†å¤‡æ¨¡å‹è¾“å…¥æ‰¹æ¬¡
        
        Args:
            observation: è§‚æµ‹æ•°æ®
            
        Returns:
            batch: æ‰¹æ¬¡æ•°æ®
        """
        batch = {
            'node_features': torch.tensor(
                observation['node_features'], dtype=torch.float32
            ).to(self.device),
            'edge_indices': torch.tensor(
                observation['edge_indices'], dtype=torch.long
            ).to(self.device),
            'edge_features': torch.tensor(
                observation['edge_features'], dtype=torch.float32
            ).to(self.device),
            'global_metrics': torch.tensor(
                observation['global_metrics'], dtype=torch.float32
            ).unsqueeze(0).to(self.device),
            'vehicle_ids': observation['vehicle_ids'].tolist(),
            'is_icv': torch.tensor(
                observation['is_icv'], dtype=torch.bool
            ).to(self.device),
            'vehicle_states': {
                'ids': observation['vehicle_ids'].tolist(),
                'data': observation.get('vehicle_data', {})
            }
        }
        return batch
    
    def _log_step_info(self, step_result: Dict[str, Any]):
        """è¾“å‡ºæ­¥éª¤ä¿¡æ¯"""
        logger.info(
            f"Actor {self.actor_id} Step {self.step_count}: "
            f"Reward={step_result['reward']:.4f}, "
            f"Vehicles={step_result['vehicle_count']}, "
            f"Controlled={step_result['controlled_vehicles']}, "
            f"Time={step_result['inference_time']*1000:.2f}ms"
        )
    
    def get_statistics(self) -> Dict[str, Any]:
        """
        è·å–Actorç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            stats: ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        avg_inference_time = np.mean(self.inference_times) if self.inference_times else 0.0
        
        return {
            'actor_id': self.actor_id,
            'episode_count': self.episode_count,
            'total_steps': self.step_count,
            'total_reward': self.total_reward,
            'avg_inference_time': avg_inference_time,
            'level1_interventions': self.safety_interventions['level1'],
            'level2_interventions': self.safety_interventions['level2']
        }


# ============================================================================
# åˆ†å¸ƒå¼æ¨ç†åè°ƒå™¨
# ============================================================================

class DistributedInferenceCoordinator:
    """
    åˆ†å¸ƒå¼æ¨ç†åè°ƒå™¨
    
    è´Ÿè´£ï¼š
    1. åˆå§‹åŒ–Rayé›†ç¾¤
    2. åˆ›å»ºå’Œç®¡ç†å¤šä¸ªInferenceActor
    3. åè°ƒå¹¶è¡Œæ¨ç†ä»»åŠ¡
    4. æ”¶é›†å’Œèšåˆç»Ÿè®¡ä¿¡æ¯
    5. ä¿å­˜æ¨ç†ç»“æœ
    """
    
    def __init__(self, config: Dict[str, Any], checkpoint_path: str):
        """
        åˆå§‹åŒ–åè°ƒå™¨
        
        Args:
            config: æ¨ç†é…ç½®å­—å…¸
            checkpoint_path: æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„
        """
        self.config = config
        self.checkpoint_path = checkpoint_path
        
        # Rayé…ç½®
        self.num_instances = config['num_instances']
        self.num_cpus_per_instance = config['num_cpus_per_instance']
        self.num_gpus = config['num_gpus']
        self.ray_address = config.get('ray_address', None)
        
        # Actors
        self.actors = []
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.start_time = None
        self.episode_stats = []
        
        logger.info("âœ… åˆ†å¸ƒå¼æ¨ç†åè°ƒå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def initialize_ray(self):
        """åˆå§‹åŒ–Rayé›†ç¾¤"""
        if not ray.is_initialized():
            # è®¡ç®—èµ„æºéœ€æ±‚
            num_cpus = self.num_instances * self.num_cpus_per_instance + 2  # +2 for driver
            
            ray.init(
                address=self.ray_address,
                num_gpus=self.num_gpus,
                num_cpus=num_cpus,
                ignore_reinit_error=True,
                log_to_driver=self.config['log_level'] == 'INFO'
            )
            logger.info(f"âœ… Rayé›†ç¾¤åˆå§‹åŒ–æˆåŠŸ")
            logger.info(f"   åœ°å€: {self.ray_address or 'local'}")
            logger.info(f"   CPUs: {num_cpus}")
            logger.info(f"   GPUs: {self.num_gpus}")
        else:
            logger.info("â„¹ï¸  Rayé›†ç¾¤å·²åˆå§‹åŒ–")
    
    def create_actors(self) -> bool:
        """
        åˆ›å»ºInferenceActorå®ä¾‹
        
        Returns:
            success: æ˜¯å¦åˆ›å»ºæˆåŠŸ
        """
        try:
            self.actors = []
            
            for i in range(self.num_instances):
                # åˆ›å»ºActor
                actor = InferenceActor.remote(
                    actor_id=i,
                    config=self.config,
                    checkpoint_path=self.checkpoint_path
                )
                
                # åˆå§‹åŒ–Actor
                success = ray.get(actor.initialize.remote())
                
                if success:
                    self.actors.append(actor)
                    logger.info(f"âœ… Actor {i} åˆ›å»ºå¹¶åˆå§‹åŒ–æˆåŠŸ")
                else:
                    logger.error(f"âŒ Actor {i} åˆå§‹åŒ–å¤±è´¥")
                    return False
            
            logger.info(f"âœ… æ‰€æœ‰ {len(self.actors)} ä¸ªActoråˆ›å»ºæˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºActorå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def run_inference(self, num_episodes: int = 1) -> List[Dict[str, Any]]:
        """
        è¿è¡Œåˆ†å¸ƒå¼æ¨ç†
        
        Args:
            num_episodes: æ¯ä¸ªActorè¿è¡Œçš„episodeæ•°é‡
            
        Returns:
            all_episode_stats: æ‰€æœ‰episodeçš„ç»Ÿè®¡ä¿¡æ¯
        """
        self.start_time = time.time()
        self.episode_stats = []
        
        logger.info("=" * 80)
        logger.info("ğŸš€ å¼€å§‹åˆ†å¸ƒå¼æ¨ç†")
        logger.info("=" * 80)
        logger.info(f"   Actoræ•°é‡: {len(self.actors)}")
        logger.info(f"   æ¯Actor Episodeæ•°: {num_episodes}")
        logger.info(f"   æ€»Episodeæ•°: {len(self.actors) * num_episodes}")
        logger.info("=" * 80)
        
        try:
            # å¹¶è¡Œè¿è¡Œæ¨ç†
            futures = []
            for actor in self.actors:
                for _ in range(num_episodes):
                    futures.append(actor.run_episode.remote())
            
            # æ”¶é›†ç»“æœ
            episode_stats = ray.get(futures)
            self.episode_stats = episode_stats
            
            # æ‰“å°æ±‡æ€»ç»Ÿè®¡
            self._print_summary_stats()
            
            return episode_stats
            
        except Exception as e:
            logger.error(f"âŒ æ¨ç†è¿‡ç¨‹å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def _print_summary_stats(self):
        """æ‰“å°æ±‡æ€»ç»Ÿè®¡ä¿¡æ¯"""
        if not self.episode_stats:
            return
        
        # è®¡ç®—æ±‡æ€»ç»Ÿè®¡
        total_episodes = len(self.episode_stats)
        total_steps = sum(s['total_steps'] for s in self.episode_stats)
        total_reward = sum(s['total_reward'] for s in self.episode_stats)
        avg_reward = total_reward / total_episodes
        avg_inference_time = np.mean([s['avg_inference_time'] for s in self.episode_stats])
        total_level1 = sum(s['total_level1_interventions'] for s in self.episode_stats)
        total_level2 = sum(s['total_level2_interventions'] for s in self.episode_stats)
        
        elapsed_time = time.time() - self.start_time
        throughput = total_steps / elapsed_time if elapsed_time > 0 else 0
        
        print("\n" + "=" * 80)
        print("ğŸ“Š åˆ†å¸ƒå¼æ¨ç†æ±‡æ€»ç»Ÿè®¡")
        print("=" * 80)
        print(f"â±ï¸  æ€»è¿è¡Œæ—¶é—´: {elapsed_time:.2f}ç§’")
        print(f"ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡:")
        print(f"   - æ€»Episodeæ•°: {total_episodes}")
        print(f"   - æ€»æ­¥æ•°: {total_steps}")
        print(f"   - æ€»å¥–åŠ±: {total_reward:.2f}")
        print(f"   - å¹³å‡å¥–åŠ±: {avg_reward:.4f}")
        print(f"   - å¹³å‡æ¨ç†æ—¶é—´: {avg_inference_time*1000:.2f}ms")
        print(f"   - ååé‡: {throughput:.2f} æ­¥/ç§’")
        print(f"ğŸ›¡ï¸  å®‰å…¨æŒ‡æ ‡:")
        print(f"   - Level1å¹²é¢„æ€»æ•°: {total_level1}")
        print(f"   - Level2å¹²é¢„æ€»æ•°: {total_level2}")
        print(f"   - å¹³å‡å¹²é¢„ç‡: {(total_level1 + total_level2) / total_steps * 100:.2f}%")
        print("=" * 80)
    
    def save_results(self, results_dir: Optional[str] = None):
        """
        ä¿å­˜æ¨ç†ç»“æœ
        
        Args:
            results_dir: ç»“æœä¿å­˜ç›®å½•
        """
        if not self.config.get('save_results', True):
            return
        
        results_dir = results_dir or self.config.get('results_dir', './inference_results')
        os.makedirs(results_dir, exist_ok=True)
        
        # ç”Ÿæˆæ—¶é—´æˆ³
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜episodeç»Ÿè®¡
        stats_file = os.path.join(results_dir, f"inference_stats_{timestamp}.json")
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(self.episode_stats, f, indent=2, ensure_ascii=False)
        
        logger.info(f"âœ… æ¨ç†ç»“æœå·²ä¿å­˜: {stats_file}")
        
        # ä¿å­˜æ±‡æ€»ç»Ÿè®¡
        summary_file = os.path.join(results_dir, f"inference_summary_{timestamp}.json")
        summary = {
            'config': self.config,
            'checkpoint_path': self.checkpoint_path,
            'total_episodes': len(self.episode_stats),
            'total_steps': sum(s['total_steps'] for s in self.episode_stats),
            'total_reward': sum(s['total_reward'] for s in self.episode_stats),
            'avg_reward': sum(s['total_reward'] for s in self.episode_stats) / max(len(self.episode_stats), 1),
            'avg_inference_time': np.mean([s['avg_inference_time'] for s in self.episode_stats]),
            'total_level1_interventions': sum(s['total_level1_interventions'] for s in self.episode_stats),
            'total_level2_interventions': sum(s['total_level2_interventions'] for s in self.episode_stats),
            'elapsed_time': time.time() - self.start_time,
        }
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        
        logger.info(f"âœ… æ±‡æ€»ç»Ÿè®¡å·²ä¿å­˜: {summary_file}")
    
    def shutdown(self):
        """å…³é—­åè°ƒå™¨"""
        if ray.is_initialized():
            ray.shutdown()
            logger.info("âœ… Rayé›†ç¾¤å·²å…³é—­")


# ============================================================================
# é…ç½®æ–‡ä»¶åŠ è½½
# ============================================================================

def load_config_from_file(config_path: str) -> Dict[str, Any]:
    """
    ä»JSONæ–‡ä»¶åŠ è½½é…ç½®
    
    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        
    Returns:
        config: é…ç½®å­—å…¸
    """
    with open(config_path, 'r', encoding='utf-8') as f:
        config = json.load(f)
    logger.info(f"âœ… ä» {config_path} åŠ è½½é…ç½®")
    return config


def merge_configs(default_config: Dict[str, Any], 
                  user_config: Dict[str, Any]) -> Dict[str, Any]:
    """
    åˆå¹¶é»˜è®¤é…ç½®å’Œç”¨æˆ·é…ç½®
    
    Args:
        default_config: é»˜è®¤é…ç½®
        user_config: ç”¨æˆ·é…ç½®
        
    Returns:
        merged_config: åˆå¹¶åçš„é…ç½®
    """
    merged = default_config.copy()
    
    # é€’å½’åˆå¹¶åµŒå¥—å­—å…¸
    for key, value in user_config.items():
        if key in merged and isinstance(merged[key], dict) and isinstance(value, dict):
            merged[key] = merge_configs(merged[key], value)
        else:
            merged[key] = value
    
    return merged


# ============================================================================
# å‘½ä»¤è¡Œæ¥å£
# ============================================================================

def parse_args() -> argparse.Namespace:
    """
    è§£æå‘½ä»¤è¡Œå‚æ•°
    
    Returns:
        args: å‘½ä»¤è¡Œå‚æ•°
    """
    parser = argparse.ArgumentParser(
        description="Rayæ¨ç†è„šæœ¬ - SUMOäº¤é€šæ§åˆ¶åˆ†å¸ƒå¼æ¨ç†",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
    # åŸºç¡€æ¨ç†
    python ray_inference.py --checkpoint models/traffic_controller_v1.pth
    
    # ä»é…ç½®æ–‡ä»¶åŠ è½½
    python ray_inference.py --checkpoint models/traffic_controller_v1.pth --config config.json
    
    # å¤šå®ä¾‹å¹¶è¡Œæ¨ç†
    python ray_inference.py --checkpoint models/traffic_controller_v1.pth --num_instances 4
    
    # ä½¿ç”¨GUIå¯è§†åŒ–
    python ray_inference.py --checkpoint models/traffic_controller_v1.pth --use_gui
    
    # è¿æ¥åˆ°Rayé›†ç¾¤
    python ray_inference.py --checkpoint models/traffic_controller_v1.pth --ray-address ray://localhost:10001
        """
    )
    
    parser.add_argument(
        "--checkpoint",
        type=str,
        required=True,
        help="æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„"
    )
    
    parser.add_argument(
        "--config",
        type=str,
        default=None,
        help="é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆJSONæ ¼å¼ï¼‰"
    )
    
    parser.add_argument(
        "--num-instances",
        type=int,
        default=None,
        help="SUMOå®ä¾‹æ•°é‡ï¼ˆå¹¶è¡ŒActoræ•°ï¼‰"
    )
    
    parser.add_argument(
        "--num-episodes",
        type=int,
        default=1,
        help="æ¯ä¸ªActorè¿è¡Œçš„episodeæ•°é‡"
    )
    
    parser.add_argument(
        "--max-steps",
        type=int,
        default=None,
        help="æ¯ä¸ªepisodeçš„æœ€å¤§æ­¥æ•°"
    )
    
    parser.add_argument(
        "--device",
        type=str,
        default=None,
        choices=['cpu', 'cuda'],
        help="è®¡ç®—è®¾å¤‡"
    )
    
    parser.add_argument(
        "--sumo-cfg",
        type=str,
        default=None,
        help="SUMOé…ç½®æ–‡ä»¶è·¯å¾„"
    )
    
    parser.add_argument(
        "--use-gui",
        action="store_true",
        help="å¯ç”¨SUMO GUI"
    )
    
    parser.add_argument(
        "--use-libsumo",
        action="store_true",
        help="å¯ç”¨LIBSUMO_AS_TRACIåŠ é€Ÿ"
    )
    
    parser.add_argument(
        "--ray-address",
        type=str,
        default=None,
        help="Rayé›†ç¾¤åœ°å€ï¼ˆå¦‚ï¼šray://localhost:10001ï¼‰"
    )
    
    parser.add_argument(
        "--log-interval",
        type=int,
        default=None,
        help="æ—¥å¿—è¾“å‡ºé—´éš”"
    )
    
    parser.add_argument(
        "--results-dir",
        type=str,
        default=None,
        help="ç»“æœä¿å­˜ç›®å½•"
    )
    
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="è¯¦ç»†æ—¥å¿—è¾“å‡º"
    )
    
    return parser.parse_args()


# ============================================================================
# ä¸»å‡½æ•°
# ============================================================================

def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_args()
    
    # è·å–é»˜è®¤é…ç½®
    config = get_default_config()
    
    # ä»é…ç½®æ–‡ä»¶åŠ è½½é…ç½®
    if args.config:
        user_config = load_config_from_file(args.config)
        config = merge_configs(config, user_config)
    
    # è¦†ç›–å‘½ä»¤è¡Œå‚æ•°
    config['checkpoint_path'] = args.checkpoint
    
    if args.num_instances is not None:
        config['num_instances'] = args.num_instances
    if args.device is not None:
        config['device'] = args.device
    if args.max_steps is not None:
        config['max_steps'] = args.max_steps
    if args.sumo_cfg is not None:
        config['sumo_cfg_path'] = args.sumo_cfg
    if args.use_gui:
        config['use_gui'] = True
    if args.use_libsumo:
        config['use_libsumo'] = True
    if args.ray_address is not None:
        config['ray_address'] = args.ray_address
    if args.log_interval is not None:
        config['log_interval'] = args.log_interval
    if args.results_dir is not None:
        config['results_dir'] = args.results_dir
    if args.verbose:
        config['verbose'] = True
        config['log_level'] = 'DEBUG'
    
    # æ‰“å°é…ç½®ä¿¡æ¯
    print("\n" + "=" * 80)
    print("ğŸš€ Rayæ¨ç†é…ç½®")
    print("=" * 80)
    print(f"ğŸ“ æ£€æŸ¥ç‚¹è·¯å¾„: {config['checkpoint_path']}")
    print(f"ğŸ–¥ï¸  è®¡ç®—è®¾å¤‡: {config['device']}")
    print(f"ğŸŒ SUMOé…ç½®: {config['sumo_cfg_path']}")
    print(f"ğŸ”§ LIBSUMO: {config['use_libsumo']}")
    print(f"ğŸ“º GUI: {config['use_gui']}")
    print(f"âš™ï¸  å®ä¾‹æ•°é‡: {config['num_instances']}")
    print(f"ğŸ“Š æœ€å¤§æ­¥æ•°: {config['max_steps']}")
    print(f"ğŸ”— Rayåœ°å€: {config['ray_address'] or 'local'}")
    print("=" * 80)
    
    # åˆ›å»ºåè°ƒå™¨
    coordinator = DistributedInferenceCoordinator(
        config=config,
        checkpoint_path=config['checkpoint_path']
    )
    
    try:
        # åˆå§‹åŒ–Ray
        coordinator.initialize_ray()
        
        # åˆ›å»ºActors
        if not coordinator.create_actors():
            logger.error("âŒ Actoråˆ›å»ºå¤±è´¥ï¼Œé€€å‡º")
            return
        
        # è¿è¡Œæ¨ç†
        episode_stats = coordinator.run_inference(num_episodes=args.num_episodes)
        
        # ä¿å­˜ç»“æœ
        coordinator.save_results()
        
    except KeyboardInterrupt:
        print("\nâš ï¸  æ¨ç†è¢«ç”¨æˆ·ä¸­æ–­")
    
    except Exception as e:
        logger.error(f"âŒ æ¨ç†è¿‡ç¨‹å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        # å…³é—­åè°ƒå™¨
        coordinator.shutdown()


# ============================================================================
# è„šæœ¬å…¥å£
# ============================================================================

if __name__ == "__main__":
    main()

import torch
import json
import os
import numpy as np
from neural_traffic_controller import TrafficController, ProgressiveWorldModel
from torch.utils.data import DataLoader, TensorDataset
import torch.nn.functional as F
from torch_geometric.data import Data


class TrainingConfig:
    """è®­ç»ƒé…ç½®ç®¡ç†"""
    def __init__(self, config_path='train_config.json'):
        with open(config_path, 'r') as f:
            self.config = json.load(f)
    
    def get_phase_config(self, phase):
        """è·å–ç‰¹å®šé˜¶æ®µçš„é…ç½®"""
        return self.config['training'][f'phase{phase}']


class MultiTaskLoss(nn.Module):
    """å¤šä»»åŠ¡åŠ æƒæŸå¤±å‡½æ•°"""
    def __init__(self, weights=None):
        super().__init__()
        self.weights = weights or {
            'state': 1.0,
            'conflict': 1.5,
            'safety': 2.0
        }
        self.mse_loss = nn.MSELoss()
        self.bce_loss = nn.BCELoss()
    
    def forward(self, predictions, targets):
        """
        è®¡ç®—å¤šä»»åŠ¡æŸå¤±
        predictions: {'states': ..., 'conflicts': ..., 'safety': ...}
        targets: {'states': ..., 'conflicts': ..., 'safety': ...}
        """
        total_loss = 0.0
        loss_dict = {}
        
        # çŠ¶æ€é¢„æµ‹æŸå¤±
        if 'states' in predictions and 'states' in targets:
            state_loss = self.mse_loss(predictions['states'], targets['states'])
            loss_dict['state'] = state_loss.item()
            total_loss += self.weights['state'] * state_loss
        
        # å†²çªé¢„æµ‹æŸå¤±
        if 'conflicts' in predictions and 'conflicts' in targets:
            conflict_loss = self.bce_loss(
                predictions['conflicts'].sigmoid(),
                targets['conflicts']
            )
            loss_dict['conflict'] = conflict_loss.item()
            total_loss += self.weights['conflict'] * conflict_loss
        
        # å®‰å…¨æŒ‡æ ‡æŸå¤±
        if 'safety' in predictions and 'safety' in targets:
            safety_loss = self.mse_loss(predictions['safety'], targets['safety'])
            loss_dict['safety'] = safety_loss.item()
            total_loss += self.weights['safety'] * safety_loss
        
        loss_dict['total'] = total_loss.item()
        return total_loss, loss_dict


class CurriculumScheduler:
    """è¯¾ç¨‹å­¦ä¹ è°ƒåº¦å™¨"""
    def __init__(self, total_epochs, initial_difficulty=0.3):
        self.total_epochs = total_epochs
        self.initial_difficulty = initial_difficulty
    
    def get_difficulty(self, epoch):
        """è·å–å½“å‰è®­ç»ƒéš¾åº¦"""
        progress = epoch / self.total_epochs
        
        if progress < 0.3:
            # åˆæœŸï¼šç®€å•åœºæ™¯
            return 0.3 + progress * 0.7  # 0.3 -> 0.5
        elif progress < 0.7:
            # ä¸­æœŸï¼šä¸­ç­‰åœºæ™¯
            return 0.5 + (progress - 0.3) * 0.5  # 0.5 -> 0.7
        else:
            # åæœŸï¼šå¤æ‚åœºæ™¯
            return 0.7 + (progress - 0.7) * 0.3  # 0.7 -> 1.0
    
    def get_batch_importance_weights(self, batch_size, difficulty):
        """æ ¹æ®éš¾åº¦è·å–æ‰¹æ¬¡é‡è¦æ€§æƒé‡"""
        # æ¨¡æ‹Ÿï¼šå›°éš¾æ ·æœ¬æƒé‡æ›´é«˜
        weights = np.random.exponential(difficulty, size=batch_size)
        return torch.tensor(weights / weights.sum() * batch_size).float()


class DataAugmentation:
    """äº¤é€šæ•°æ®å¢å¼º"""
    @staticmethod
    def augment_vehicle_state(state, augment_prob=0.5):
        """å¢å¼ºè½¦è¾†çŠ¶æ€æ•°æ®"""
        if np.random.random() > augment_prob:
            return state
        
        state = state.clone()
        
        # é€Ÿåº¦æ‰°åŠ¨ Â±10%
        if 'speed' in state:
            state['speed'] = state['speed'] * (1 + np.random.uniform(-0.1, 0.1))
        
        # ä½ç½®åç§» Â±5ç±³
        if 'position' in state:
            state['position'] = state['position'] + np.random.uniform(-5, 5)
        
        # åŠ é€Ÿåº¦å™ªå£°
        if 'acceleration' in state:
            state['acceleration'] = state['acceleration'] + np.random.normal(0, 0.5)
        
        return state
    
    @staticmethod
    def augment_edge_features(edge_features, dropout_rate=0.1):
        """éšæœºç§»é™¤äº¤äº’è¾¹"""
        if np.random.random() < dropout_rate:
            mask = torch.rand(edge_features.size(0)) > 0.1
            return edge_features[mask]
        return edge_features


class TrainingMonitor:
    """è®­ç»ƒç›‘æ§å’Œæ—©åœæœºåˆ¶"""
    def __init__(self, patience=15, verbose=True):
        self.patience = patience
        self.verbose = verbose
        self.best_loss = float('inf')
        self.wait_count = 0
        self.history = {
            'train_loss': [],
            'val_loss': [],
            'learning_rate': [],
            'phase': []
        }
    
    def update(self, val_loss, learning_rate, phase):
        """æ›´æ–°ç›‘æ§çŠ¶æ€"""
        self.history['train_loss'].append(val_loss)
        self.history['learning_rate'].append(learning_rate)
        self.history['phase'].append(phase)
        
        if val_loss < self.best_loss:
            self.best_loss = val_loss
            self.wait_count = 0
            if self.verbose:
                print(f"âœ… æ–°çš„æœ€ä¼˜æŸå¤±: {self.best_loss:.4f}")
            return True
        else:
            self.wait_count += 1
            if self.verbose and self.wait_count % 5 == 0:
                print(f"âš ï¸ éªŒè¯é›†æ— æ”¹è¿› {self.wait_count}/{self.patience}")
            return False
    
    def should_stop(self):
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥æ—©åœ"""
        return self.wait_count >= self.patience


class OptimizedTrainer:
    """ä¼˜åŒ–çš„è®­ç»ƒå™¨"""
    def __init__(self, model, config, device):
        self.model = model
        self.config = config
        self.device = device
        
        # ä¼˜åŒ–å™¨
        self.optimizer = torch.optim.AdamW(
            model.parameters(),
            lr=config['training']['learning_rate'],
            weight_decay=config['training'].get('weight_decay', 0.0001)
        )
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼šä½™å¼¦é€€ç« + é¢„çƒ­
        total_epochs = (
            config['training']['phase1_epochs'] +
            config['training']['phase2_epochs'] +
            config['training']['phase3_epochs']
        )
        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(
            self.optimizer,
            T_0=50,
            T_mult=2,
            eta_min=1e-6
        )
        
        # å¤šä»»åŠ¡æŸå¤±
        self.loss_fn = MultiTaskLoss(weights={
            'state': 1.0,
            'conflict': 1.5,
            'safety': 2.0
        })
        
        # è¯¾ç¨‹å­¦ä¹ 
        self.curriculum = CurriculumScheduler(total_epochs)
        
        # ç›‘æ§
        self.monitor = TrainingMonitor(patience=15)
        
        # æ•°æ®å¢å¼º
        self.augmentation = DataAugmentation()
        
        # æ··åˆç²¾åº¦è®­ç»ƒ
        self.scaler = torch.cuda.amp.GradScaler(enabled=device.type == 'cuda')
    
    def generate_batch_data(self, batch_size=64, difficulty=1.0):
        """ç”Ÿæˆè®­ç»ƒæ‰¹æ¬¡"""
        dummy_node_features = torch.randn(batch_size, self.config['model']['node_dim']).to(self.device)
        dummy_edge_index = torch.randint(0, batch_size, (2, batch_size * 2)).to(self.device)
        dummy_edge_attr = torch.randn(batch_size * 2, self.config['model']['edge_dim']).to(self.device)
        
        # åº”ç”¨æ•°æ®å¢å¼º
        if np.random.random() < 0.3:
            dummy_edge_attr = self.augmentation.augment_edge_features(dummy_edge_attr)
        
        batch_data = {
            'node_features': dummy_node_features,
            'edge_indices': dummy_edge_index,
            'edge_features': dummy_edge_attr,
            'global_metrics': torch.randn(1, self.config['model']['global_dim']).to(self.device),
            'vehicle_ids': [f'veh_{i}' for i in range(batch_size)],
            'is_icv': torch.rand(batch_size) > (0.75 - 0.25 * difficulty),  # éš¾åº¦è¶Šé«˜ï¼ŒICVè¶Šå¤š
            'vehicle_states': {
                'ids': [f'veh_{i}' for i in range(batch_size)],
                'data': {f'veh_{i}': {
                    'position': torch.randn(1).item(),
                    'speed': torch.randn(1).item(),
                    'acceleration': torch.randn(1).item(),
                    'lane_id': f'edge_{i % 10}'
                } for i in range(batch_size)}
            }
        }
        
        return batch_data
    
    def train_phase(self, phase, num_epochs):
        """è®­ç»ƒå•ä¸ªé˜¶æ®µ"""
        print(f"\n{'='*60}")
        print(f"ğŸ”„ é˜¶æ®µ{phase}è®­ç»ƒå¼€å§‹...")
        print(f"{'='*60}")
        
        self.model.world_model.set_phase(phase)
        
        for epoch in range(num_epochs):
            # è·å–è¯¾ç¨‹å­¦ä¹ éš¾åº¦
            difficulty = self.curriculum.get_difficulty(epoch)
            
            # ç”Ÿæˆæ‰¹æ¬¡
            batch_data = self.generate_batch_data(
                batch_size=self.config['training']['batch_size'],
                difficulty=difficulty
            )
            
            # å‰å‘ä¼ æ’­
            self.model.train()
            self.optimizer.zero_grad()
            
            # æ„å»ºå›¾æ•°æ®
            from torch_geometric.data import Data
            graph_data = Data(
                x=batch_data['node_features'],
                edge_index=batch_data['edge_indices'],
                edge_attr=batch_data['edge_features']
            ).to(self.device)
            
            # æ··åˆç²¾åº¦è®­ç»ƒ
            with torch.cuda.amp.autocast(enabled=self.device.type == 'cuda'):
                # GNNæ¨ç†
                gnn_out = self.model.risk_gnn(graph_data)
                
                # é˜¶æ®µç‰¹å®šçš„è®­ç»ƒ
                if phase == 1:
                    # Phase 1: é¢„æµ‹ä¸‹ä¸€æ—¶åˆ»çŠ¶æ€
                    pred_next = self.model.world_model(gnn_out)
                    target_next = torch.randn_like(gnn_out).to(self.device)
                    
                    loss = F.mse_loss(pred_next, target_next)
                    loss_dict = {'total': loss.item()}
                
                elif phase == 2:
                    # Phase 2: é¢„æµ‹æœªæ¥5æ­¥çŠ¶æ€ + å†²çªæ¦‚ç‡
                    pred_future = self.model.world_model(gnn_out)
                    target_future = torch.randn(batch_data['node_features'].size(0), 5, 257).to(self.device)
                    
                    # åˆ†ç¦»é¢„æµ‹
                    pred_states = pred_future[..., :-1]  # çŠ¶æ€éƒ¨åˆ†
                    pred_conflicts = pred_future[..., -1]  # å†²çªéƒ¨åˆ†
                    
                    target_states = target_future[..., :-1]
                    target_conflicts = target_future[..., -1]
                    
                    predictions = {
                        'states': pred_states,
                        'conflicts': pred_conflicts.unsqueeze(-1)
                    }
                    targets = {
                        'states': target_states,
                        'conflicts': target_conflicts.unsqueeze(-1)
                    }
                    
                    loss, loss_dict = self.loss_fn(predictions, targets)
                
                else:  # phase == 3
                    # Phase 3: ç«¯åˆ°ç«¯ä¼˜åŒ–
                    output = self.model(batch_data, epoch)
                    
                    # è®¡ç®—ç»„åˆæŸå¤±
                    target_safety = torch.randn(len(output.get('selected_indices', [])), 2).to(self.device)
                    
                    if 'world_predictions' in output:
                        predictions = {
                            'states': output['world_predictions'][..., :-1],
                            'conflicts': output['world_predictions'][..., -1].unsqueeze(-1),
                            'safety': torch.randn_like(target_safety).to(self.device)
                        }
                        targets = {
                            'states': torch.randn_like(predictions['states']).to(self.device),
                            'conflicts': torch.rand_like(predictions['conflicts']).to(self.device),
                            'safety': target_safety
                        }
                        loss, loss_dict = self.loss_fn(predictions, targets)
                    else:
                        loss = torch.tensor(0.0).to(self.device)
                        loss_dict = {'total': 0.0}
            
            # åå‘ä¼ æ’­ï¼ˆä½¿ç”¨æ¢¯åº¦ç¼©æ”¾å™¨ï¼‰
            self.scaler.scale(loss).backward()
            self.scaler.unscale_(self.optimizer)
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            self.scaler.step(self.optimizer)
            self.scaler.update()
            self.scheduler.step()
            
            # è®°å½•æ—¥å¿—
            if epoch % max(1, num_epochs // 10) == 0:
                lr = self.optimizer.param_groups[0]['lr']
                print(f"Phase {phase} - Epoch {epoch:3d}/{num_epochs} | "
                      f"Loss: {loss_dict['total']:.4f} | "
                      f"Difficulty: {difficulty:.2f} | "
                      f"LR: {lr:.2e}")
        
        print(f"âœ… é˜¶æ®µ{phase}è®­ç»ƒå®Œæˆ!")
    
    def train(self):
        """æ‰§è¡Œå®Œæ•´è®­ç»ƒæµç¨‹"""
        # Phase 1: ä¸–ç•Œæ¨¡å‹é¢„è®­ç»ƒ
        self.train_phase(1, self.config['training']['phase1_epochs'])
        
        # Phase 2: ä¸–ç•Œæ¨¡å‹é£é™©é¢„æµ‹
        self.train_phase(2, self.config['training']['phase2_epochs'])
        
        # Phase 3: ç«¯åˆ°ç«¯å¾®è°ƒ
        self.train_phase(3, self.config['training']['phase3_epochs'])
        
        print("\nâœ… å…¨éƒ¨è®­ç»ƒå®Œæˆ!")


def train_traffic_controller(config: dict):
    """
    ä¼˜åŒ–çš„è®­ç»ƒæµç¨‹
    """
    print("ğŸ”§ å¼€å§‹ä¼˜åŒ–è®­ç»ƒäº¤é€šæ§åˆ¶å™¨...")
    
    # åˆå§‹åŒ–æ¨¡å‹
    model = TrafficController(config['model'])
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device(config['model']['device'])
    model = model.to(device)
    
    # åˆ›å»ºä¼˜åŒ–çš„è®­ç»ƒå™¨
    trainer = OptimizedTrainer(model, config, device)
    
    # æ‰§è¡Œè®­ç»ƒ
    trainer.train()
    
    return model


def save_model(model, config, save_path):
    """ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹"""
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    
    torch.save({
        'model_state_dict': model.state_dict(),
        'config': config
    }, save_path)
    
    print(f"âœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {save_path}")


def main():
    # åŠ è½½é…ç½®
    with open('train_config.json', 'r') as f:
        config = json.load(f)
    
    print("=" * 60)
    print("ğŸ“Š ä¼˜åŒ–ç‰ˆäº¤é€šæ§åˆ¶å™¨è®­ç»ƒ")
    print("=" * 60)
    print(f"æ¨¡å‹é…ç½®: {config['model']}")
    print(f"è®­ç»ƒé…ç½®: {config['training']}")
    
    # è®­ç»ƒæ¨¡å‹
    trained_model = train_traffic_controller(config)
    
    # ä¿å­˜æ¨¡å‹
    save_path = config['training']['save_path']
    save_model(trained_model, config, save_path)
    
    print("\n" + "=" * 60)
    print("è®­ç»ƒæµç¨‹å®Œæˆ!")
    print("=" * 60)


if __name__ == "__main__":
    import torch.nn as nn
    main()

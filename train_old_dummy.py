import torch
import json
import os
import numpy as np
from neural_traffic_controller import TrafficController
import torch.nn.functional as F


class CurriculumScheduler:
    """è¯¾ç¨‹å­¦ä¹ è°ƒåº¦å™¨"""
    def __init__(self, total_epochs, initial_difficulty=0.3):
        self.total_epochs = total_epochs
        self.initial_difficulty = initial_difficulty
    
    def get_difficulty(self, epoch):
        """è·å–å½“å‰è®­ç»ƒéš¾åº¦"""
        progress = epoch / self.total_epochs
        
        if progress < 0.3:
            return 0.3 + progress * 0.7
        elif progress < 0.7:
            return 0.5 + (progress - 0.3) * 0.5
        else:
            return 0.7 + (progress - 0.7) * 0.3


class DataAugmentation:
    """äº¤é€šæ•°æ®å¢å¼º"""
    @staticmethod
    def augment_features(features, augment_prob=0.3):
        """å¢å¼ºç‰¹å¾æ•°æ®"""
        if np.random.random() > augment_prob:
            return features
        
        features = features.clone()
        scale = 1 + np.random.uniform(-0.1, 0.1)
        features = features * scale
        noise = torch.randn_like(features) * 0.05
        features = features + noise
        
        return features


def safe_backward_step(loss, optimizer, scaler, model, phase, epoch):
    """å®‰å…¨çš„åå‘ä¼ æ’­æ­¥éª¤"""
    # æ£€æŸ¥ loss æœ‰æ•ˆæ€§
    if not torch.isfinite(loss):
        optimizer.zero_grad()
        return False
    
    try:
        scaler.scale(loss).backward()
        scaler.unscale_(optimizer)
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        scaler.step(optimizer)
        scaler.update()
        return True
    except Exception as e:
        return False
    finally:
        optimizer.zero_grad()


def train_traffic_controller(config: dict):
    """
    ä¼˜åŒ–çš„ä¸‰é˜¶æ®µè®­ç»ƒæµç¨‹
    - Phase 1: ä¸–ç•Œæ¨¡å‹é¢„è®­ç»ƒï¼ˆçŠ¶æ€é¢„æµ‹ï¼‰
    - Phase 2: ä¸–ç•Œæ¨¡å‹é£é™©é¢„æµ‹ï¼ˆå†²çªé¢„æµ‹ï¼‰
    - Phase 3: ç«¯åˆ°ç«¯å¾®è°ƒï¼ˆæ•´ä½“ä¼˜åŒ–ï¼‰
    """
    print("ğŸ”§ å¼€å§‹ä¼˜åŒ–ç‰ˆè®­ç»ƒäº¤é€šæ§åˆ¶å™¨...")
    print("=" * 60)

    # åˆå§‹åŒ–æ¨¡å‹å’Œä¼˜åŒ–å™¨
    model = TrafficController(config['model'])
    device = torch.device(config['model']['device'])
    model = model.to(device)
    
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=config['training']['learning_rate'],
        weight_decay=config['training'].get('weight_decay', 0.0001)
    )
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    total_epochs = (
        config['training']['phase1_epochs'] +
        config['training']['phase2_epochs'] +
        config['training']['phase3_epochs']
    )
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(
        optimizer, T_0=50, T_mult=2, eta_min=1e-6
    )
    
    # æŸå¤±å‡½æ•°å’Œè¾…åŠ©ç±»
    mse_loss = torch.nn.MSELoss()
    bce_loss = torch.nn.BCEWithLogitsLoss()
    curriculum = CurriculumScheduler(total_epochs)
    augmentation = DataAugmentation()
    
    # æ··åˆç²¾åº¦è®­ç»ƒ
    scaler = torch.amp.GradScaler('cuda', enabled=device.type == 'cuda')
    
    print(f"âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
    print(f"   - è®¾å¤‡: {device}")
    print(f"   - å­¦ä¹ ç‡: {config['training']['learning_rate']}")
    print(f"   - æ··åˆç²¾åº¦: {'å¯ç”¨' if device.type == 'cuda' else 'ç¦ç”¨'}")
    print("=" * 60)
    
    # ============ Phase 1 ============
    print("\nğŸ”„ é˜¶æ®µ1ï¼šä¸–ç•Œæ¨¡å‹é¢„è®­ç»ƒ...")
    model.world_model.set_phase(1)
    
    for epoch in range(config['training']['phase1_epochs']):
        difficulty = curriculum.get_difficulty(epoch)
        
        model.train()
        
        # ç”Ÿæˆè™šæ‹Ÿæ•°æ®
        dummy_node_features = torch.randn(64, config['model']['node_dim']).to(device)
        dummy_edge_index = torch.randint(0, 64, (2, 128)).to(device)
        dummy_edge_attr = torch.randn(128, config['model']['edge_dim']).to(device)
        dummy_node_features = augmentation.augment_features(dummy_node_features)
        
        from torch_geometric.data import Data
        graph_data = Data(
            x=dummy_node_features,
            edge_index=dummy_edge_index,
            edge_attr=dummy_edge_attr
        ).to(device)
        
        # å‰å‘å’Œåå‘
        with torch.amp.autocast('cuda', enabled=device.type == 'cuda'):
            gnn_out = model.risk_gnn(graph_data)
            pred_next = model.world_model(gnn_out)
            target_next = torch.randn_like(gnn_out).to(device)
            loss = mse_loss(pred_next, target_next)
        
        safe_backward_step(loss, optimizer, scaler, model, 1, epoch)
        scheduler.step()
        
        if epoch % 10 == 0:
            lr = optimizer.param_groups[0]['lr']
            print(f"   Epoch {epoch:3d} | Loss: {loss.item():.4f} | Difficulty: {difficulty:.2f} | LR: {lr:.2e}")
    
    print("âœ… é˜¶æ®µ1è®­ç»ƒå®Œæˆ!\n")
    
    # ============ Phase 2 ============
    print("ğŸ”„ é˜¶æ®µ2ï¼šä¸–ç•Œæ¨¡å‹é£é™©é¢„æµ‹è®­ç»ƒ...")
    model.world_model.set_phase(2)
    
    for epoch in range(config['training']['phase2_epochs']):
        difficulty = curriculum.get_difficulty(config['training']['phase1_epochs'] + epoch)
        
        model.train()
        
        # ç”Ÿæˆè™šæ‹Ÿæ•°æ®
        dummy_node_features = torch.randn(64, config['model']['node_dim']).to(device)
        dummy_edge_index = torch.randint(0, 64, (2, 128)).to(device)
        dummy_edge_attr = torch.randn(128, config['model']['edge_dim']).to(device)
        dummy_node_features = augmentation.augment_features(dummy_node_features)
        
        graph_data = Data(
            x=dummy_node_features,
            edge_index=dummy_edge_index,
            edge_attr=dummy_edge_attr
        ).to(device)
        
        # å‰å‘å’Œåå‘
        with torch.amp.autocast('cuda', enabled=device.type == 'cuda'):
            gnn_out = model.risk_gnn(graph_data)
            pred_future = model.world_model(gnn_out)
            target_future = torch.randn(64, 5, 257).to(device)
            
            # åˆ†ç¦»é¢„æµ‹
            pred_states = pred_future[..., :-1]
            pred_conflicts = torch.clamp(pred_future[..., -1], -10, 10)
            target_states = target_future[..., :-1]
            target_conflicts = torch.clamp(target_future[..., -1], -1, 1)
            
            # å¤šä»»åŠ¡æŸå¤±
            state_loss = mse_loss(pred_states, target_states)
            conflict_loss = bce_loss(pred_conflicts.unsqueeze(-1), target_conflicts.unsqueeze(-1).clamp(0, 1))
            loss = state_loss + 1.5 * conflict_loss
        
        safe_backward_step(loss, optimizer, scaler, model, 2, epoch)
        scheduler.step()
        
        if epoch % 20 == 0:
            lr = optimizer.param_groups[0]['lr']
            print(f"   Epoch {epoch:3d} | Loss: {loss.item():.4f} | Difficulty: {difficulty:.2f} | LR: {lr:.2e}")
    
    print("âœ… é˜¶æ®µ2è®­ç»ƒå®Œæˆ!\n")
    
    # ============ Phase 3 ============
    print("ğŸ”„ é˜¶æ®µ3ï¼šç«¯åˆ°ç«¯å¾®è°ƒ...")
    
    # è°ƒæ•´å­¦ä¹ ç‡
    for param_group in optimizer.param_groups:
        param_group['lr'] = 0.0001
    
    successful_batches = 0
    
    for epoch in range(config['training']['phase3_epochs']):
        difficulty = curriculum.get_difficulty(
            config['training']['phase1_epochs'] +
            config['training']['phase2_epochs'] +
            epoch
        )
        
        constraint_weight = min(1.0, epoch / 50)
        
        model.train()
        
        # ç”Ÿæˆè™šæ‹Ÿæ•°æ®
        batch_size = config['training']['batch_size']
        dummy_node_features = torch.randn(batch_size, config['model']['node_dim']).to(device)
        dummy_edge_index = torch.randint(0, batch_size, (2, batch_size * 2)).to(device)
        dummy_edge_attr = torch.randn(batch_size * 2, config['model']['edge_dim']).to(device)
        dummy_node_features = augmentation.augment_features(dummy_node_features)
        
        batch_data = {
            'node_features': dummy_node_features,
            'edge_indices': dummy_edge_index,
            'edge_features': dummy_edge_attr,
            'global_metrics': torch.randn(1, config['model']['global_dim']).to(device),
            'vehicle_ids': [f'veh_{i}' for i in range(batch_size)],
            'is_icv': torch.rand(batch_size) > (0.75 - 0.25 * difficulty),
            'vehicle_states': {
                'ids': [f'veh_{i}' for i in range(batch_size)],
                'data': {f'veh_{i}': {
                    'position': torch.randn(1).item(),
                    'speed': max(0, min(30, torch.randn(1).item())),
                    'acceleration': max(-8, min(4, torch.randn(1).item())),
                    'lane_id': f'edge_{i % 10}'
                } for i in range(batch_size)}
            }
        }
        
        # å‰å‘å’Œåå‘
        try:
            with torch.amp.autocast('cuda', enabled=device.type == 'cuda'):
                output = model(batch_data, epoch)
                
                if 'world_predictions' in output:
                    world_pred = torch.clamp(output['world_predictions'], -10, 10)
                    target = torch.clamp(torch.randn_like(world_pred), -10, 10)
                    loss = mse_loss(world_pred, target)
                else:
                    loss = mse_loss(dummy_node_features[:, :2], torch.randn(batch_size, 2).to(device))
            
            if safe_backward_step(loss, optimizer, scaler, model, 3, epoch):
                successful_batches += 1
        except:
            pass
        
        scheduler.step()
        
        if epoch % 20 == 0:
            lr = optimizer.param_groups[0]['lr']
            print(f"   Epoch {epoch:3d} | Loss: {loss.item():.4f} | Constraint: {constraint_weight:.2f} | "
                  f"Success: {successful_batches}/{epoch+1} | LR: {lr:.2e}")
    
    print(f"âœ… é˜¶æ®µ3è®­ç»ƒå®Œæˆ! (æˆåŠŸ: {successful_batches}/{config['training']['phase3_epochs']})\n")
    print("=" * 60)
    print("âœ… å®Œæ•´è®­ç»ƒæµç¨‹å®Œæˆ!")
    print("=" * 60)
    
    return model


def save_model(model, config, save_path):
    """ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹"""
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    
    torch.save({
        'model_state_dict': model.state_dict(),
        'config': config
    }, save_path)
    
    print(f"âœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {save_path}")


def main():
    # åŠ è½½é…ç½®
    with open('train_config.json', 'r') as f:
        config = json.load(f)
    
    print("\n" + "=" * 60)
    print("ğŸ“Š æ™ºèƒ½äº¤é€šæ§åˆ¶å™¨ - ä¼˜åŒ–ç‰ˆè®­ç»ƒ (ç¨³å®šç‰ˆ)")
    print("=" * 60)
    print("æ”¹è¿›ç‰¹æ€§:")
    print("  âœ“ æ–°ç‰ˆ torch.amp æ··åˆç²¾åº¦ API")
    print("  âœ“ NaN è‡ªåŠ¨æ£€æµ‹å’Œæ¢å¤")
    print("  âœ“ å®‰å…¨åå‘ä¼ æ’­")
    print("  âœ“ å­¦ä¹ ç‡åŠ¨æ€è°ƒæ•´")
    print("  âœ“ è¯¾ç¨‹å­¦ä¹ éš¾åº¦è°ƒæ•´")
    print("  âœ“ æ•°æ®å¢å¼º")
    print("=" * 60 + "\n")
    
    # è®­ç»ƒæ¨¡å‹
    trained_model = train_traffic_controller(config)
    
    # ä¿å­˜æ¨¡å‹
    save_path = config['training']['save_path']
    save_model(trained_model, config, save_path)
    
    print("\n" + "=" * 60)
    print("ğŸ‰ è®­ç»ƒå®Œæˆï¼")
    print("=" * 60 + "\n")


if __name__ == "__main__":
    main()

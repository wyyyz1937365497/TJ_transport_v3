# æ™ºèƒ½äº¤é€šååŒæ§åˆ¶ç³»ç»Ÿï¼šå®Œæ•´ç¥ç»ç½‘ç»œè®¾è®¡ä¸å®ç°


è¯·æ£€æŸ¥å½“å‰çš„ä»£ç å®ç°æ˜¯å¦å®Œæ•´çš„å®ç°äº†è¯¦ç»†è¦æ±‚ä¸­çš„å†…å®¹ï¼Œæ ¸å¿ƒç›®æ ‡æ˜¯åœ¨25%æ™ºèƒ½è½¦è¾†æ¸—é€ç‡çº¦æŸä¸‹ï¼Œé€šè¿‡â€œæŒ‰éœ€å¹²é¢„â€ç­–ç•¥ä¼˜åŒ–å…¨å±€äº¤é€šæ•ˆç‡ï¼ˆ
S
perf
S 
perf
â€‹
 ï¼‰åŒæ—¶æœ€å°åŒ–å¹²é¢„æˆæœ¬ï¼ˆ
P
int
P 
int
â€‹
 ï¼‰ï¼Œä»¥æœ€å¤§åŒ–æ€»è¯„åˆ† 
S
total
=
S
perf
Ã—
P
int
S 
total
â€‹
 =S 
perf
â€‹
 Ã—P 
int
â€‹
 ã€‚

è¯¥æ¶æ„ç›®å‰å·²æ¼”è¿›è‡³ v4.0 ç‰ˆæœ¬ï¼Œä¸»è¦åŒ…å«ä»¥ä¸‹å…³é”®ç»„ä»¶ï¼š

æ„ŸçŸ¥å±‚ï¼šé£é™©æ•æ„Ÿå¼‚æ„å›¾ç¥ç»ç½‘ç»œï¼ˆRisk-Sensitive GNNï¼‰ï¼Œåœ¨è¾¹ç‰¹å¾ä¸­åµŒå…¥ TTCï¼ˆç¢°æ’æ—¶é—´ï¼‰å’Œ THWï¼ˆè½¦å¤´æ—¶è·ï¼‰å€’æ•°ï¼Œå¹¶é‡‡ç”¨ Biased Attention æœºåˆ¶å¼ºåŒ–é«˜é£é™©äº¤äº’çš„æ³¨æ„åŠ›æƒé‡ã€‚
é¢„æµ‹å±‚ï¼šæ¸è¿›å¼ä¸–ç•Œæ¨¡å‹ï¼Œåˆ†ä¸¤é˜¶æ®µè®­ç»ƒï¼š
Phase 1ï¼šä»…é¢„æµ‹ä¸‹ä¸€æ—¶åˆ»è½¦è¾†çŠ¶æ€ï¼ˆä½ç½®ã€é€Ÿåº¦ï¼‰ï¼Œå­¦ä¹ åŸºç¡€åŠ¨åŠ›å­¦ï¼›
Phase 2ï¼šå†»ç»“ç‰¹å¾æå–å™¨ï¼Œè§£è€¦è¾“å‡ºä¸º 
z
flow
z 
flow
â€‹
 ï¼ˆæµæ¼”åŒ–ï¼‰ä¸ 
z
risk
z 
risk
â€‹
 ï¼ˆé£é™©æ¼”åŒ–ï¼‰ï¼Œè”åˆä¼˜åŒ–è½¨è¿¹ MSE ä¸å†²çªåˆ†ç±»æŸå¤±ã€‚
å†³ç­–å±‚ï¼šå½±å“åŠ›é©±åŠ¨çš„ Top-K ç¨€ç–æ§åˆ¶æœºåˆ¶ï¼ŒåŠ¨æ€è®¡ç®—æ¯è¾†è½¦çš„å½±å“åŠ›å¾—åˆ†
Score
i
=
Î±
â‹…
Importance
GNN
+
Î²
â‹…
Impact
Predicted
,
Score 
i
â€‹
 =Î±â‹…Importance 
GNN
â€‹
 +Î²â‹…Impact 
Predicted
â€‹
 ,
ä»…å¯¹ Top-Kï¼ˆå¦‚ K=5ï¼‰å…³é”®è½¦è¾†æ‰§è¡Œå¼ºåŒ–å­¦ä¹ æ§åˆ¶ï¼Œå…¶ä½™è½¦è¾†ä½¿ç”¨ IDM æ¨¡å‹è·Ÿé©°ã€‚

å®‰å…¨çº¦æŸæ¨¡å—ï¼šåŒæ¨¡æ€å®‰å…¨å±éšœ
Level 1ï¼šåŠ¨ä½œè£å‰ªï¼ˆåŠ é€Ÿåº¦é™å¹…ã€é€Ÿåº¦éè´Ÿï¼‰ï¼›
Level 2ï¼šTTC < 2.0s æ—¶å¼ºåˆ¶ç´§æ€¥åˆ¶åŠ¨ï¼Œå¹¶åœ¨è®­ç»ƒä¸­æ–½åŠ å·¨å¤§è´Ÿå¥–åŠ±ä»¥é¿å…è¿›å…¥é«˜å±çŠ¶æ€ã€‚
è®­ç»ƒç­–ç•¥ï¼š
é‡‡ç”¨äº‹ä»¶è§¦å‘ + å®šæ—¶å…œåº•çš„æ§åˆ¶å‘¨æœŸï¼ˆé»˜è®¤10ç§’ï¼Œé«˜å±äº‹ä»¶å¯ä¸­æ–­ï¼‰ï¼›
å¥–åŠ±å‡½æ•°ç›´æ¥åŸºäºä¸ SUMO åŸºå‡†åœºæ™¯çš„æ€§èƒ½å·®å€¼ï¼ˆå¦‚å¹³å‡é€Ÿåº¦æå‡ï¼‰ï¼›
æ”¯æŒå¤šé˜¶æ®µè®­ç»ƒï¼ˆPhase1/Phase2 + Policyï¼‰ï¼Œå¯é€šè¿‡å‘½ä»¤è¡Œå‚æ•°çµæ´»é…ç½®å„é˜¶æ®µ epoch æ•°ã€batch size å’Œå­¦ä¹ ç‡ã€‚
ä½ å·²åœ¨æœ¬åœ°æˆåŠŸè¿è¡Œè®­ç»ƒè„šæœ¬ï¼ˆå¦‚ train_s.py å’Œ train.pyï¼‰ï¼Œå¹¶è§‚å¯Ÿåˆ°æ¨¡å‹åœ¨ç¬¬17è½®è¾¾åˆ°å¹³å‡å¥–åŠ± 1136.34ï¼Œä¸”å®‰å…¨å¹²é¢„æ¬¡æ•°å’Œå—æ§è½¦è¾†æ•°ç¬¦åˆé¢„æœŸã€‚

å¦‚æœä½ éœ€è¦è°ƒæ•´æ¶æ„ç»†èŠ‚ã€è®­ç»ƒè°ƒåº¦æˆ–éƒ¨ç½²ç­–ç•¥ï¼Œæˆ‘å¯ä»¥ç»§ç»­ååŠ©ã€‚

æˆ‘ç°åœ¨ä½¿ç”¨Ray + RLlibï¼ˆåˆ†å¸ƒå¼ RL æ¡†æ¶ï¼‰ä»¥åŠSUMO-RLè¿™ä»½æŒ‡å—æ—¨åœ¨å¸®åŠ©ä½ å°†ç°æœ‰çš„ v4.0 æ¶æ„ï¼ˆGNN + ä¸–ç•Œæ¨¡å‹ + çº¦æŸRL + å®‰å…¨å±éšœï¼‰ä¸ Ray RLlibï¼ˆé«˜æ•ˆåˆ†å¸ƒå¼å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼‰æ·±åº¦ç»“åˆã€‚

æ ¸å¿ƒç›®æ ‡ï¼šåˆ©ç”¨ Ray RLlib çš„å¤šè¿›ç¨‹å¹¶è¡Œèƒ½åŠ›ï¼ŒåŒæ—¶è·‘å¤šä¸ª SUMO å®ä¾‹ï¼Œæˆå€æå‡è®­ç»ƒæ•°æ®ååé‡ï¼ŒåŒæ—¶ä¸¥æ ¼éµå®ˆæ¯”èµ›â€œä»…ä½¿ç”¨å®˜æ–¹ç¯å¢ƒã€æ— å¤–éƒ¨æ•°æ®â€çš„è§„å®šã€‚

æ™ºèƒ½äº¤é€šååŒæ§åˆ¶ Agent é«˜æ•ˆç¼–ç¨‹æŒ‡å— (åŸºäº Ray RLlib)
1. æ•´ä½“è®¾è®¡åŸåˆ™
æ¶æ„ä¸åŠ¨æ‘‡ï¼šä¿ç•™ v4.0 çš„æ ¸å¿ƒæ¨¡å—ï¼ˆRisk-Sensitive GNNã€Progressive World Modelã€Constrained RLã€Dual-mode Safety Shieldï¼‰ã€‚
æ¡†æ¶æ¢å¼•æ“ï¼šæŠ›å¼ƒæ‰‹å†™çš„å•è¿›ç¨‹ TrainingManagerï¼Œæ”¹ç”¨ Ray RLlib ä½œä¸ºè®­ç»ƒå¼•æ“ã€‚
ç¯å¢ƒæ ‡å‡†åŒ–ï¼šå°† SUMO äº¤äº’é€»è¾‘å°è£…ä¸ºæ ‡å‡†çš„ gym.Envï¼Œä½œä¸ºæ•°æ®ç”Ÿäº§è€…ã€‚
è®¡ç®—å¹¶è¡ŒåŒ–ï¼šåˆ©ç”¨ Ray çš„ RolloutWorker åœ¨å¤šæ ¸ CPU ä¸Šå¹¶è¡Œè·‘å¤šä¸ª SUMOï¼Œåˆ©ç”¨ GPU è¿›è¡Œæ‰¹é‡æ¨¡å‹æ›´æ–°ã€‚
2. æŠ€æœ¯æ ˆé€‰å‹
ç»„ä»¶	é€‰å‹	ç†ç”±
ä»¿çœŸæ ¸å¿ƒ	å®˜æ–¹ SUMO	æ¯”èµ›æŒ‡å®šï¼Œä¸å¯æ›´æ”¹ã€‚
è®­ç»ƒæ¡†æ¶	Ray RLlib	å·¥ä¸šçº§åˆ†å¸ƒå¼ RL æ¡†æ¶ï¼ŒåŸç”Ÿæ”¯æŒå¤šç¯å¢ƒå¹¶è¡Œã€å¼‚æ„èµ„æºè°ƒåº¦ï¼Œä¸”ä¸åŒ…å«ä»»ä½•äº¤é€šæ•°æ®ã€‚
ç¯å¢ƒæ¥å£	Gymnasium API	RLlib å’Œ SB3 çš„æ ‡å‡†æ¥å£ï¼Œä¾¿äºè¿ç§»ã€‚å»ºè®®åŸºäºæ­¤è‡ªå·±å°è£…ä¸€ä¸ª CustomSumoEnvã€‚
æ·±åº¦å­¦ä¹ 	PyTorch	ä½ ç°æœ‰ä»£ç å·²åŸºäº PyTorchï¼ŒRLlib å¯¹ PyTorch æ”¯æŒå®Œç¾ã€‚
3. ç¬¬ä¸€æ­¥ï¼šå°è£…æ ‡å‡†åŒ–ç¯å¢ƒ
æˆ‘ä»¬éœ€è¦å°†ä½  trainer.py ä¸­çš„ rollout_stage é€»è¾‘é‡å†™ä¸ºä¸€ä¸ªç±»ã€‚è¿™æ˜¯æœ€å…³é”®çš„ä¸€æ­¥ï¼Œå†³å®šäº†æ•°æ®ç”Ÿæˆçš„æ•ˆç‡ã€‚

å…³é”®ä¼˜åŒ–ç‚¹ï¼š
ä½¿ç”¨ TraCI è®¢é˜…ï¼šä¸è¦åœ¨å¾ªç¯é‡Œè°ƒç”¨ getSpeedã€‚åœ¨ reset æˆ– step å¼€å§‹æ—¶ä¸€æ¬¡æ€§è®¢é˜…æ‰€æœ‰è½¦è¾†å˜é‡ã€‚
æ‰¹é‡åŠ¨ä½œåº”ç”¨ï¼šæ¥æ”¶ä¸€ä¸ªåŒ…å«æ‰€æœ‰è½¦è¾†åŠ¨ä½œçš„å­—å…¸ï¼Œæ‰¹é‡åº”ç”¨ã€‚
é›†æˆå®‰å…¨å±‚ï¼šåœ¨ç¯å¢ƒå†…éƒ¨ step æ–¹æ³•ä¸­ï¼Œåœ¨å°†åŠ¨ä½œå‘ç»™ SUMO ä¹‹å‰ï¼Œå…ˆç»è¿‡ä½ çš„ Level 1 & Level 2 å®‰å…¨å±éšœã€‚


## ä¸€ã€æ•´ä½“æ¶æ„

```python
"""
å®Œæ•´çš„æ™ºèƒ½äº¤é€šååŒæ§åˆ¶ç³»ç»Ÿ
åŒ…å«ï¼šæ„ŸçŸ¥å±‚ã€é¢„æµ‹å±‚ã€å†³ç­–å±‚ã€å®‰å…¨å±‚
ä¸¥æ ¼éµå®ˆç«èµ›è§„åˆ™ï¼Œä»…æ§åˆ¶25%çš„æ™ºèƒ½è½¦è¾†
"""
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import traci
from typing import Dict, List, Tuple, Any, Optional
import os
import json
import time
from torch_geometric.nn import GATConv
from torch_geometric.data import Data

class TrafficController(nn.Module):
    """
    æ™ºèƒ½äº¤é€šååŒæ§åˆ¶ç¥ç»ç½‘ç»œ
    æ¶æ„ï¼šRisk-Sensitive GNN + Progressive World Model + Influence-Driven Controller + Dual-mode Safety Shield
    """
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__()
        self.config = config
        
        # 1. æ„ŸçŸ¥å±‚ï¼šé£é™©æ•æ„ŸGNN
        self.risk_gnn = RiskSensitiveGNN(
            node_dim=config.get('node_dim', 9),
            edge_dim=config.get('edge_dim', 4),
            hidden_dim=config.get('gnn_hidden_dim', 64),
            output_dim=config.get('gnn_output_dim', 256),
            num_layers=config.get('gnn_layers', 3),
            heads=config.get('gnn_heads', 4)
        )
        
        # 2. é¢„æµ‹å±‚ï¼šæ¸è¿›å¼ä¸–ç•Œæ¨¡å‹
        self.world_model = ProgressiveWorldModel(
            input_dim=config.get('gnn_output_dim', 256),
            hidden_dim=config.get('world_hidden_dim', 128),
            future_steps=config.get('future_steps', 5),
            num_phases=2
        )
        
        # 3. å†³ç­–å±‚ï¼šå½±å“åŠ›é©±åŠ¨æ§åˆ¶å™¨
        self.controller = InfluenceDrivenController(
            gnn_dim=config.get('gnn_output_dim', 256),
            world_dim=config.get('gnn_output_dim', 256),
            global_dim=config.get('global_dim', 16),
            hidden_dim=config.get('controller_hidden_dim', 128),
            action_dim=config.get('action_dim', 2),
            top_k=config.get('top_k', 5)
        )
        
        # 4. å®‰å…¨å±‚ï¼šåŒæ¨¡æ€å®‰å…¨å±éšœ
        self.safety_shield = DualModeSafetyShield(
            ttc_threshold=config.get('ttc_threshold', 2.0),
            thw_threshold=config.get('thw_threshold', 1.5),
            max_accel=config.get('max_accel', 2.0),
            max_decel=config.get('max_decel', -3.0),
            emergency_decel=config.get('emergency_decel', -5.0),
            max_lane_change_speed=config.get('max_lane_change_speed', 5.0)
        )
        
        # 5. çº¦æŸä¼˜åŒ–å‚æ•°
        self.register_buffer('lagrange_multiplier', torch.tensor(1.0))
        self.cost_limit = config.get('cost_limit', 0.1)
        self.lambda_lr = config.get('lambda_lr', 0.01)
        
        # 6. ç¼“å­˜æœºåˆ¶
        self.gnn_cache = {}
        self.cache_timeout = config.get('cache_timeout', 10)  # ç¼“å­˜10æ­¥
        
        print("âœ… äº¤é€šæ§åˆ¶ç¥ç»ç½‘ç»œåˆå§‹åŒ–å®Œæˆ!")
        print(f"   - GNNç»´åº¦: {config.get('gnn_output_dim', 256)}")
        print(f"   - é¢„æµ‹æ­¥é•¿: {config.get('future_steps', 5)}")
        print(f"   - æ§åˆ¶è½¦è¾†æ•°: {config.get('top_k', 5)}")
        
    def forward(self, batch: Dict[str, Any], step: int) -> Dict[str, Any]:
        """
        å‰å‘ä¼ æ’­ï¼Œç”Ÿæˆæ§åˆ¶æŒ‡ä»¤
        """
        # 1. æ„ŸçŸ¥å±‚ï¼šGNNç‰¹å¾æå–
        gnn_embedding = self._get_gnn_embedding(batch, step)
        
        # 2. é¢„æµ‹å±‚ï¼šæœªæ¥çŠ¶æ€é¢„æµ‹
        world_predictions = self.world_model(gnn_embedding)
        
        # 3. å†³ç­–å±‚ï¼šå½±å“åŠ›è®¡ç®—ä¸åŠ¨ä½œç”Ÿæˆ
        controller_output = self.controller(
            gnn_embedding=gnn_embedding,
            world_predictions=world_predictions,
            global_metrics=batch['global_metrics'],
            vehicle_ids=batch['vehicle_ids'],
            is_icv=batch['is_icv']
        )
        
        # 4. å®‰å…¨å±‚ï¼šåŠ¨ä½œå®‰å…¨åŒ–
        safe_actions = self.safety_shield(
            raw_actions=controller_output['raw_actions'],
            vehicle_states=batch['vehicle_states'],
            selected_vehicle_indices=controller_output['selected_indices']
        )
        
        # 5. ç»„åˆè¾“å‡º
        output = {
            'selected_vehicle_ids': controller_output['selected_vehicle_ids'],
            'safe_actions': safe_actions,
            'influence_scores': controller_output['influence_scores'],
            'level1_interventions': safe_actions['level1_interventions'],
            'level2_interventions': safe_actions['level2_interventions'],
            'gnn_embedding': gnn_embedding,
            'world_predictions': world_predictions
        }
        
        return output
    
    def _get_gnn_embedding(self, batch: Dict[str, Any], step: int) -> torch.Tensor:
        """å¸¦ç¼“å­˜çš„GNNæ¨ç†"""
        # ç”Ÿæˆç¼“å­˜é”®
        cache_key = str(hash(str(batch['vehicle_ids']) + str(batch['edge_indices'].shape)))
        
        # æ£€æŸ¥ç¼“å­˜
        if cache_key in self.gnn_cache and step - self.gnn_cache[cache_key]['step'] < self.cache_timeout:
            return self.gnn_cache[cache_key]['embedding']
        
        # æ„å»ºå›¾æ•°æ®
        graph_data = self._build_graph(batch)
        
        # GNNæ¨ç†
        with torch.no_grad():
            gnn_embedding = self.risk_gnn(graph_data)
        
        # æ›´æ–°ç¼“å­˜
        self.gnn_cache[cache_key] = {
            'embedding': gnn_embedding,
            'step': step
        }
        
        return gnn_embedding
    
    def _build_graph(self, batch: Dict[str, Any]) -> Data:
        """æ„å»ºå›¾ç¥ç»ç½‘ç»œè¾“å…¥"""
        # èŠ‚ç‚¹ç‰¹å¾
        node_features = batch['node_features']  # [N, 9]
        
        # è¾¹ç´¢å¼•
        edge_index = batch['edge_indices']  # [2, E]
        
        # è¾¹ç‰¹å¾
        edge_features = batch['edge_features']  # [E, 4]
        
        # åˆ›å»ºPyGæ•°æ®å¯¹è±¡
        graph = Data(
            x=node_features,
            edge_index=edge_index,
            edge_attr=edge_features
        )
        
        return graph
    
    def update_lagrange_multiplier(self, mean_cost: float):
        """æ›´æ–°æ‹‰æ ¼æœ—æ—¥ä¹˜å­"""
        if mean_cost > self.cost_limit:
            self.lagrange_multiplier *= (1 + self.lambda_lr)
        else:
            self.lagrange_multiplier *= (1 - self.lambda_lr)
        
        # é™åˆ¶èŒƒå›´
        self.lagrange_multiplier = torch.clamp(self.lagrange_multiplier, 0.1, 10.0)
        
        return self.lagrange_multiplier.item()
```

## äºŒã€æ„ŸçŸ¥å±‚ï¼šRisk-Sensitive GNN

```python
class RiskSensitiveGNN(nn.Module):
    """
    é£é™©æ•æ„Ÿå›¾ç¥ç»ç½‘ç»œ
    è¾“å…¥ï¼šè½¦è¾†èŠ‚ç‚¹ç‰¹å¾(9ç»´) + äº¤äº’è¾¹ç‰¹å¾(4ç»´)
    è¾“å‡ºï¼š256ç»´å…¨å±€åµŒå…¥
    """
    
    def __init__(self, node_dim: int = 9, edge_dim: int = 4, hidden_dim: int = 64, 
                 output_dim: int = 256, num_layers: int = 3, heads: int = 4):
        super().__init__()
        
        # 1. èŠ‚ç‚¹ç‰¹å¾ç¼–ç å™¨
        self.node_encoder = nn.Sequential(
            nn.Linear(node_dim, 32),
            nn.ReLU(),
            nn.Linear(32, hidden_dim),
            nn.LayerNorm(hidden_dim)
        )
        
        # 2. è¾¹ç‰¹å¾ç¼–ç å™¨
        self.edge_encoder = nn.Sequential(
            nn.Linear(edge_dim, 16),
            nn.ReLU(),
            nn.Linear(16, hidden_dim // 2),
            nn.LayerNorm(hidden_dim // 2)
        )
        
        # 3. é£é™©æ³¨æ„åŠ›æœºåˆ¶
        self.risk_attention = nn.Sequential(
            nn.Linear(hidden_dim + hidden_dim // 2, hidden_dim),
            nn.Tanh(),
            nn.Linear(hidden_dim, 1),
            nn.Sigmoid()
        )
        
        # 4. GNNå±‚
        self.gnn_layers = nn.ModuleList()
        for i in range(num_layers):
            self.gnn_layers.append(
                GATConv(
                    in_channels=hidden_dim if i > 0 else hidden_dim,
                    out_channels=hidden_dim,
                    heads=heads,
                    concat=False,
                    edge_dim=hidden_dim // 2
                )
            )
        
        # 5. è¾“å‡ºæŠ•å½±å±‚
        self.output_layer = nn.Sequential(
            nn.Linear(hidden_dim, 128),
            nn.ReLU(),
            nn.Linear(128, output_dim),
            nn.LayerNorm(output_dim)
        )
        
        # åˆå§‹åŒ–æƒé‡
        self._init_weights()
    
    def _init_weights(self):
        """æƒé‡åˆå§‹åŒ–"""
        for m in self.modules():
            if isinstance(m, (nn.Linear, nn.Conv1d)):
                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
    
    def forward(self, graph: Data) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­
        Args:
            graph: åŒ…å«x, edge_index, edge_attrçš„PyGæ•°æ®å¯¹è±¡
        Returns:
            global_embedding: [N, 256] å…¨å±€åµŒå…¥
        """
        # 1. ç¼–ç èŠ‚ç‚¹å’Œè¾¹ç‰¹å¾
        node_features = self.node_encoder(graph.x)  # [N, 64]
        edge_features = self.edge_encoder(graph.edge_attr)  # [E, 32]
        
        # 2. è®¡ç®—é£é™©æ³¨æ„åŠ›æƒé‡
        if edge_features.size(0) > 0:
            src_nodes = graph.edge_index[0]
            risk_input = torch.cat([
                node_features[src_nodes],
                edge_features
            ], dim=1)  # [E, 96]
            risk_weights = self.risk_attention(risk_input)  # [E, 1]
        else:
            risk_weights = None
        
        # 3. GNNä¼ æ’­
        x = node_features
        for layer in self.gnn_layers:
            x = layer(x, graph.edge_index, edge_attr=edge_features, attention_weights=risk_weights)
            x = F.relu(x)
        
        # 4. è¾“å‡ºæŠ•å½±
        global_embedding = self.output_layer(x)  # [N, 256]
        
        return global_embedding
```

## ä¸‰ã€é¢„æµ‹å±‚ï¼šProgressive World Model

```python
class ProgressiveWorldModel(nn.Module):
    """
    æ¸è¿›å¼ä¸–ç•Œæ¨¡å‹
    é˜¶æ®µ1ï¼šé¢„æµ‹ä¸‹ä¸€æ—¶åˆ»çŠ¶æ€
    é˜¶æ®µ2ï¼šé¢„æµ‹æœªæ¥5æ­¥çŠ¶æ€ + å†²çªæ¦‚ç‡
    """
    
    def __init__(self, input_dim: int = 256, hidden_dim: int = 128, 
                 future_steps: int = 5, num_phases: int = 2):
        super().__init__()
        
        self.future_steps = future_steps
        self.num_phases = num_phases
        self.current_phase = 1
        
        # 1. å…±äº«ç¼–ç å™¨
        self.shared_encoder = nn.Sequential(
            nn.Linear(input_dim, 192),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(192, hidden_dim),
            nn.LayerNorm(hidden_dim)
        )
        
        # 2. åŸºç¡€åŠ¨åŠ›å­¦åˆ†æ”¯ (Phase 1)
        self.dynamics_lstm = nn.LSTM(
            input_size=hidden_dim,
            hidden_size=hidden_dim,
            num_layers=2,
            batch_first=True,
            dropout=0.1
        )
        
        # 3. é£é™©æ¼”åŒ–åˆ†æ”¯ (Phase 2)
        self.risk_decoders = nn.ModuleList([
            nn.Sequential(
                nn.Linear(hidden_dim, 192),
                nn.ReLU(),
                nn.Dropout(0.1),
                nn.Linear(192, input_dim + 1)  # çŠ¶æ€ + å†²çªæ¦‚ç‡
            ) for _ in range(future_steps)
        ])
        
        # 4. è¾…åŠ©åˆ†ç±»å™¨
        self.conflict_classifier = nn.Sequential(
            nn.Linear(input_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 1),
            nn.Sigmoid()
        )
        
        # åˆå§‹åŒ–æƒé‡
        self._init_weights()
    
    def _init_weights(self):
        """æƒé‡åˆå§‹åŒ–"""
        for m in self.modules():
            if isinstance(m, (nn.Linear, nn.LSTM)):
                if hasattr(m, 'weight') and m.weight is not None:
                    nn.init.kaiming_normal_(m.weight, nonlinearity='relu')
                if hasattr(m, 'bias') and m.bias is not None:
                    nn.init.constant_(m.bias, 0)
    
    def set_phase(self, phase: int):
        """è®¾ç½®è®­ç»ƒé˜¶æ®µ"""
        self.current_phase = phase
        print(f"ğŸ”„ ä¸–ç•Œæ¨¡å‹åˆ‡æ¢åˆ°é˜¶æ®µ {phase}")
    
    def forward(self, gnn_embedding: torch.Tensor) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­
        Args:
            gnn_embedding: [N, 256] GNNè¾“å‡ºåµŒå…¥
        Returns:
            predictions: 
                Phase 1: [N, 256] ä¸‹ä¸€æ—¶åˆ»çŠ¶æ€
                Phase 2: [N, 5, 257] æœªæ¥5æ­¥çŠ¶æ€ + å†²çªæ¦‚ç‡
        """
        batch_size = gnn_embedding.size(0)
        
        # 1. å…±äº«ç¼–ç 
        encoded = self.shared_encoder(gnn_embedding)  # [N, 128]
        
        if self.current_phase == 1:
            # Phase 1: åŸºç¡€åŠ¨åŠ›å­¦é¢„æµ‹
            # é‡å¡‘ä¸ºLSTMè¾“å…¥æ ¼å¼ [N, 1, 128]
            lstm_input = encoded.unsqueeze(1)
            
            # LSTMé¢„æµ‹
            lstm_output, _ = self.dynamics_lstm(lstm_input)  # [N, 1, 128]
            
            # é¢„æµ‹ä¸‹ä¸€æ—¶åˆ»çŠ¶æ€
            next_state = self.risk_decoders[0](lstm_output.squeeze(1))[:, :-1]  # [N, 256]
            
            return next_state
        
        else:
            # Phase 2: é£é™©æ¼”åŒ–é¢„æµ‹
            predictions = []
            
            # ä¸ºæ¯ä¸ªæœªæ¥æ­¥ç”Ÿæˆé¢„æµ‹
            for t in range(self.future_steps):
                # ä½¿ç”¨ç›¸åŒçš„ç¼–ç ä½†æ·»åŠ æ—¶é—´æ­¥ä¿¡æ¯
                time_input = encoded + 0.1 * t * torch.ones_like(encoded)
                pred = self.risk_decoders[t](time_input)  # [N, 257]
                predictions.append(pred.unsqueeze(1))
            
            # åˆå¹¶é¢„æµ‹ [N, 5, 257]
            predictions = torch.cat(predictions, dim=1)
            
            return predictions
```

## å››ã€å†³ç­–å±‚ï¼šInfluence-Driven Controller

```python
class InfluenceDrivenController(nn.Module):
    """
    å½±å“åŠ›é©±åŠ¨æ§åˆ¶å™¨
    1. è®¡ç®—æ¯è¾†è½¦çš„å½±å“åŠ›å¾—åˆ†
    2. é€‰æ‹©Top-Kæœ€å…·å½±å“åŠ›çš„ICVè½¦è¾†
    3. ä¸ºé€‰ä¸­çš„è½¦è¾†ç”Ÿæˆæ§åˆ¶åŠ¨ä½œ
    """
    
    def __init__(self, gnn_dim: int = 256, world_dim: int = 256, global_dim: int = 16,
                 hidden_dim: int = 128, action_dim: int = 2, top_k: int = 5):
        super().__init__()
        
        self.top_k = top_k
        self.action_dim = action_dim
        
        # 1. å…¨å±€ä¸Šä¸‹æ–‡ç¼–ç å™¨
        self.global_encoder = nn.Sequential(
            nn.Linear(global_dim, 32),
            nn.ReLU(),
            nn.Linear(32, 64),
            nn.LayerNorm(64)
        )
        
        # 2. ç‰¹å¾èåˆå±‚
        self.fusion_layer = nn.Sequential(
            nn.Linear(gnn_dim + 64 + world_dim, 384),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(384, hidden_dim),
            nn.LayerNorm(hidden_dim)
        )
        
        # 3. å½±å“åŠ›è¯„åˆ†ç½‘ç»œ
        self.influence_scorer = nn.Sequential(
            nn.Linear(hidden_dim, 64),
            nn.ReLU(),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 1),
            nn.Sigmoid()
        )
        
        # 4. åŠ¨ä½œç”Ÿæˆç½‘ç»œ
        self.action_generator = nn.ModuleDict({
            'acceleration': nn.Sequential(
                nn.Linear(hidden_dim, 64),
                nn.ReLU(),
                nn.Linear(64, 32),
                nn.ReLU(),
                nn.Linear(32, 1),
                nn.Tanh()  # è¾“å‡ºèŒƒå›´[-1, 1]
            ),
            'lane_change': nn.Sequential(
                nn.Linear(hidden_dim, 32),
                nn.ReLU(),
                nn.Linear(32, 16),
                nn.ReLU(),
                nn.Linear(16, 1),
                nn.Sigmoid()  # è¾“å‡ºæ¦‚ç‡[0, 1]
            )
        })
        
        # 5. ä»·å€¼ç½‘ç»œ
        self.value_network = nn.Sequential(
            nn.Linear(hidden_dim, 64),
            nn.ReLU(),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 1)
        )
        
        # åˆå§‹åŒ–æƒé‡
        self._init_weights()
    
    def _init_weights(self):
        """æƒé‡åˆå§‹åŒ–"""
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_normal_(m.weight)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0.1)
    
    def forward(self, gnn_embedding: torch.Tensor, world_predictions: torch.Tensor,
                global_metrics: torch.Tensor, vehicle_ids: List[str], 
                is_icv: torch.Tensor) -> Dict[str, Any]:
        """
        å‰å‘ä¼ æ’­
        Args:
            gnn_embedding: [N, 256] GNNåµŒå…¥
            world_predictions: [N, 5, 257] ä¸–ç•Œæ¨¡å‹é¢„æµ‹
            global_metrics: [B, 16] å…¨å±€äº¤é€šæŒ‡æ ‡
            vehicle_ids: [N] è½¦è¾†IDåˆ—è¡¨
            is_icv: [N] æ˜¯å¦ä¸ºæ™ºèƒ½ç½‘è”è½¦
        Returns:
            åŒ…å«é€‰ä¸­è½¦è¾†IDã€æ§åˆ¶åŠ¨ä½œç­‰çš„å­—å…¸
        """
        batch_size = gnn_embedding.size(0)
        
        # 1. å¤„ç†å…¨å±€ç‰¹å¾
        global_features = self.global_encoder(global_metrics)  # [B, 64]
        
        # 2. èåˆç‰¹å¾
        # å–ä¸–ç•Œæ¨¡å‹çš„å¹³å‡é¢„æµ‹
        avg_world_pred = world_predictions.mean(dim=1) if world_predictions.dim() == 3 else world_predictions
        
        # é‡å¤å…¨å±€ç‰¹å¾ä»¥åŒ¹é…æ‰¹æ¬¡å¤§å°
        global_features_expanded = global_features.repeat(batch_size, 1)
        
        # èåˆ
        fused_input = torch.cat([
            gnn_embedding,
            global_features_expanded,
            avg_world_pred
        ], dim=1)  # [N, 256+64+256] = [N, 576]
        
        fused_features = self.fusion_layer(fused_input)  # [N, 128]
        
        # 3. è®¡ç®—ICVè½¦è¾†çš„å½±å“åŠ›å¾—åˆ†
        icv_mask = is_icv.bool()
        icv_indices = torch.where(icv_mask)[0]
        
        if len(icv_indices) == 0:
            return {
                'selected_vehicle_ids': [],
                'selected_indices': [],
                'raw_actions': torch.zeros(0, self.action_dim),
                'influence_scores': torch.zeros(0),
                'value_estimates': torch.zeros(0)
            }
        
        icv_features = fused_features[icv_mask]  # [N_icv, 128]
        influence_scores = self.influence_scorer(icv_features).squeeze(-1)  # [N_icv]
        
        # 4. é€‰æ‹©Top-Kè½¦è¾†
        k = min(self.top_k, len(icv_indices))
        top_k_scores, top_k_indices = torch.topk(influence_scores, k, largest=True, sorted=True)
        
        selected_indices = icv_indices[top_k_indices]  # [K]
        selected_vehicle_ids = [vehicle_ids[i] for i in selected_indices.cpu().numpy()]
        
        # 5. ä¸ºé€‰ä¸­è½¦è¾†ç”ŸæˆåŠ¨ä½œ
        selected_features = fused_features[selected_indices]  # [K, 128]
        
        # ç”ŸæˆåŠ é€Ÿåº¦åŠ¨ä½œ
        accel_actions = self.action_generator['acceleration'](selected_features)  # [K, 1]
        
        # ç”Ÿæˆæ¢é“æ¦‚ç‡
        lane_actions = self.action_generator['lane_change'](selected_features)  # [K, 1]
        
        # ç»„åˆåŠ¨ä½œ
        raw_actions = torch.cat([accel_actions, lane_actions], dim=1)  # [K, 2]
        
        # 6. ä»·å€¼ä¼°è®¡
        value_estimates = self.value_network(fused_features).squeeze(-1)  # [N]
        
        return {
            'selected_vehicle_ids': selected_vehicle_ids,
            'selected_indices': selected_indices.cpu().numpy().tolist(),
            'raw_actions': raw_actions,
            'influence_scores': influence_scores,
            'value_estimates': value_estimates,
            'top_k_scores': top_k_scores
        }
```

## äº”ã€å®‰å…¨å±‚ï¼šDual-mode Safety Shield

```python
class DualModeSafetyShield(nn.Module):
    """
    åŒæ¨¡æ€å®‰å…¨å±éšœ
    Level 1: åŠ¨ä½œè£å‰ªï¼ˆè½¯çº¦æŸï¼‰
    Level 2: ç´§æ€¥åˆ¶åŠ¨ï¼ˆç¡¬çº¦æŸï¼‰
    """
    
    def __init__(self, ttc_threshold: float = 2.0, thw_threshold: float = 1.5,
                 max_accel: float = 2.0, max_decel: float = -3.0,
                 emergency_decel: float = -5.0, max_lane_change_speed: float = 5.0):
        super().__init__()
        
        self.ttc_threshold = ttc_threshold
        self.thw_threshold = thw_threshold
        self.max_accel = max_accel
        self.max_decel = max_decel
        self.emergency_decel = emergency_decel
        self.max_lane_change_speed = max_lane_change_speed
        
        # å®‰å…¨å‚æ•°ï¼ˆå¯å­¦ä¹ ï¼‰
        self.register_parameter('learnable_max_accel', nn.Parameter(torch.tensor(max_accel)))
        self.register_parameter('learnable_max_decel', nn.Parameter(torch.tensor(max_decel)))
        self.register_parameter('learnable_emergency_decel', nn.Parameter(torch.tensor(emergency_decel)))
    
    def forward(self, raw_actions: torch.Tensor, vehicle_states: Dict[str, Any], 
                selected_vehicle_indices: List[int]) -> Dict[str, Any]:
        """
        å®‰å…¨å±éšœå‰å‘ä¼ æ’­
        Args:
            raw_actions: [K, 2] åŸå§‹æ§åˆ¶åŠ¨ä½œï¼ˆåŠ é€Ÿåº¦ï¼Œæ¢é“æ¦‚ç‡ï¼‰
            vehicle_states: è½¦è¾†çŠ¶æ€å­—å…¸
            selected_vehicle_indices: é€‰ä¸­è½¦è¾†ç´¢å¼•åˆ—è¡¨
        Returns:
            å®‰å…¨åŒ–åçš„åŠ¨ä½œå’Œå¹²é¢„ç»Ÿè®¡
        """
        if len(selected_vehicle_indices) == 0:
            return {
                'safe_actions': torch.zeros(0, 2),
                'level1_interventions': 0,
                'level2_interventions': 0
            }
        
        # Level 1: åŠ¨ä½œè£å‰ª
        level1_actions, level1_interventions = self._level1_clipping(
            raw_actions, vehicle_states, selected_vehicle_indices
        )
        
        # Level 2: ç´§æ€¥å®‰å…¨æ£€æŸ¥
        level2_actions, level2_interventions = self._level2_emergency_check(
            level1_actions, vehicle_states, selected_vehicle_indices
        )
        
        total_level1 = torch.sum(level1_interventions).item()
        total_level2 = torch.sum(level2_interventions).item()
        
        return {
            'safe_actions': level2_actions,
            'level1_interventions': total_level1,
            'level2_interventions': total_level2
        }
    
    def _level1_clipping(self, raw_actions: torch.Tensor, vehicle_states: Dict[str, Any], 
                        selected_indices: List[int]) -> Tuple[torch.Tensor, torch.Tensor]:
        """Level 1: åŸºç¡€åŠ¨ä½œè£å‰ª"""
        k = len(selected_indices)
        safe_actions = raw_actions.clone()
        intervention_mask = torch.zeros(k, dtype=torch.bool)
        
        for i, idx in enumerate(selected_indices):
            veh_id = vehicle_states['ids'][idx]
            
            if veh_id not in vehicle_states['data']:
                continue
            
            vehicle = vehicle_states['data'][veh_id]
            current_speed = vehicle['speed']
            
            # 1. åŠ é€Ÿåº¦è£å‰ª
            raw_accel = raw_actions[i, 0].item()
            
            # åŠ¨æ€è°ƒæ•´åŠ é€Ÿåº¦é™åˆ¶ï¼ˆåŸºäºé€Ÿåº¦ï¼‰
            dynamic_max_accel = self.max_accel * (1 - current_speed / 30.0)  # é«˜é€Ÿæ—¶å‡å°åŠ é€Ÿåº¦
            dynamic_max_decel = self.max_decel * (1 + current_speed / 30.0)  # é«˜é€Ÿæ—¶å¢å¤§å‡é€Ÿåº¦
            
            safe_accel = max(min(raw_accel, dynamic_max_accel), dynamic_max_decel)
            
            if abs(safe_accel - raw_accel) > 0.1:  # å¹²é¢„é˜ˆå€¼
                intervention_mask[i] = True
            
            # 2. æ¢é“é™åˆ¶
            raw_lane_change = raw_actions[i, 1].item()
            safe_lane_change = raw_lane_change
            
            # ä»…åœ¨ä½é€Ÿæ—¶å…è®¸æ¢é“
            if current_speed > self.max_lane_change_speed:
                safe_lane_change = 0.0
                if raw_lane_change > 0.5:
                    intervention_mask[i] = True
            
            # æ›´æ–°å®‰å…¨åŠ¨ä½œ
            safe_actions[i, 0] = safe_accel
            safe_actions[i, 1] = safe_lane_change
        
        return safe_actions, intervention_mask
    
    def _level2_emergency_check(self, actions: torch.Tensor, vehicle_states: Dict[str, Any], 
                               selected_indices: List[int]) -> Tuple[torch.Tensor, torch.Tensor]:
        """Level 2: ç´§æ€¥å®‰å…¨æ£€æŸ¥"""
        k = len(selected_indices)
        final_actions = actions.clone()
        emergency_mask = torch.zeros(k, dtype=torch.bool)
        
        for i, idx in enumerate(selected_indices):
            veh_id = vehicle_states['ids'][idx]
            
            if veh_id not in vehicle_states['data']:
                continue
            
            ego_vehicle = vehicle_states['data'][veh_id]
            leader_vehicle = self._find_leader(ego_vehicle, vehicle_states['data'])
            
            if leader_vehicle:
                # è®¡ç®—TTCå’ŒTHW
                ttc = self._calculate_ttc(ego_vehicle, leader_vehicle)
                thw = self._calculate_thw(ego_vehicle, leader_vehicle)
                
                # æ£€æŸ¥ç´§æ€¥æ¡ä»¶
                if ttc < self.ttc_threshold or thw < self.thw_threshold:
                    # ç´§æ€¥åˆ¶åŠ¨
                    final_actions[i, 0] = self.emergency_decel
                    final_actions[i, 1] = 0.0  # å–æ¶ˆæ¢é“
                    emergency_mask[i] = True
        
        return final_actions, emergency_mask
    
    def _find_leader(self, ego: Dict[str, Any], all_vehicles: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """æ‰¾åˆ°å‰è½¦"""
        min_distance = float('inf')
        leader = None
        
        for veh_id, vehicle in all_vehicles.items():
            if veh_id == ego['id']:
                continue
            
            # æ£€æŸ¥æ˜¯å¦åœ¨åŒä¸€è½¦é“
            if vehicle['lane_id'] != ego['lane_id']:
                continue
            
            # æ£€æŸ¥æ˜¯å¦åœ¨å‰æ–¹
            if vehicle['position'] <= ego['position']:
                continue
            
            distance = vehicle['position'] - ego['position']
            if distance < min_distance:
                min_distance = distance
                leader = vehicle
        
        return leader if min_distance < 100 else None  # 100ç±³å†…
    
    def _calculate_ttc(self, ego: Dict[str, Any], leader: Dict[str, Any]) -> float:
        """è®¡ç®—ç¢°æ’æ—¶é—´TTC"""
        relative_speed = ego['speed'] - leader['speed']
        distance = leader['position'] - ego['position']
        
        if relative_speed <= 0:
            return float('inf')  # ä¸ä¼šç¢°æ’
        
        ttc = distance / relative_speed
        return max(0.1, ttc)  # é˜²æ­¢é™¤é›¶
    
    def _calculate_thw(self, ego: Dict[str, Any], leader: Dict[str, Any]) -> float:
        """è®¡ç®—è½¦å¤´æ—¶è·THW"""
        distance = leader['position'] - ego['position']
        if ego['speed'] <= 0:
            return float('inf')
        
        thw = distance / ego['speed']
        return max(0.1, thw)  # é˜²æ­¢é™¤é›¶
```

## å…­ã€é›†æˆåˆ°SUMOç«èµ›æ¡†æ¶

```python
class NeuralTrafficController:
    """
    ç¥ç»äº¤é€šæ§åˆ¶å™¨ï¼Œé›†æˆåˆ°SUMOç«èµ›æ¡†æ¶
    """
    
    def __init__(self, config_path: str = None):
        # é»˜è®¤é…ç½®
        self.config = {
            'node_dim': 9,
            'edge_dim': 4,
            'gnn_hidden_dim': 64,
            'gnn_output_dim': 256,
            'gnn_layers': 3,
            'gnn_heads': 4,
            'world_hidden_dim': 128,
            'future_steps': 5,
            'controller_hidden_dim': 128,
            'global_dim': 16,
            'top_k': 5,
            'ttc_threshold': 2.0,
            'thw_threshold': 1.5,
            'max_accel': 2.0,
            'max_decel': -3.0,
            'emergency_decel': -5.0,
            'max_lane_change_speed': 5.0,
            'cost_limit': 0.1,
            'lambda_lr': 0.01,
            'cache_timeout': 10,
            'device': 'cuda' if torch.cuda.is_available() else 'cpu',
            'model_path': None
        }
        
        # åŠ è½½é…ç½®æ–‡ä»¶
        if config_path and os.path.exists(config_path):
            with open(config_path, 'r') as f:
                config_data = json.load(f)
                self.config.update(config_data)
        
        # åˆå§‹åŒ–ç¥ç»ç½‘ç»œ
        self.device = torch.device(self.config['device'])
        self.model = TrafficController(self.config).to(self.device)
        
        # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        if self.config.get('model_path') and os.path.exists(self.config['model_path']):
            try:
                checkpoint = torch.load(self.config['model_path'], map_location=self.device)
                self.model.load_state_dict(checkpoint['model_state_dict'])
                print(f"âœ… åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: {self.config['model_path']}")
            except Exception as e:
                print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.total_interventions = 0
        self.total_emergency_interventions = 0
        self.total_controlled_vehicles = 0
        
        print(f"ğŸš€ ç¥ç»äº¤é€šæ§åˆ¶å™¨åˆå§‹åŒ–å®Œæˆ! è®¾å¤‡: {self.device}")
    
    def build_model_input(self, vehicle_data: Dict[str, Any], step: int) -> Dict[str, Any]:
        """
        æ„å»ºæ¨¡å‹è¾“å…¥
        """
        # 1. æ”¶é›†è½¦è¾†ç‰¹å¾
        vehicle_ids = list(vehicle_data.keys())
        node_features = []
        is_icv_list = []
        
        for i, veh_id in enumerate(vehicle_ids):
            vehicle = vehicle_data[veh_id]
            
            # èŠ‚ç‚¹ç‰¹å¾: [ä½ç½®, é€Ÿåº¦, åŠ é€Ÿåº¦, è½¦é“, å‰©ä½™è·ç¦», å®Œæˆç‡, ç±»å‹, æ—¶é—´, æ­¥é•¿]
            features = [
                vehicle.get('position', 0.0),
                vehicle.get('speed', 0.0),
                vehicle.get('acceleration', 0.0),
                vehicle.get('lane_index', 0),
                vehicle.get('remaining_distance', 1000.0),
                vehicle.get('completion_rate', 0.0),
                1.0 if vehicle.get('is_icv', False) else 0.0,  # ICVæ ‡å¿—
                step * 0.1,  # æ—¶é—´(ç§’)
                0.1  # æ­¥é•¿
            ]
            
            node_features.append(features)
            is_icv_list.append(vehicle.get('is_icv', False))
        
        # 2. æ„å»ºäº¤äº’å›¾
        edge_indices = []
        edge_features = []
        
        # ç®€åŒ–ç‰ˆï¼šè¿æ¥ç›¸è¿‘è½¦è¾†
        for i, veh_id_i in enumerate(vehicle_ids):
            for j, veh_id_j in enumerate(vehicle_ids):
                if i == j:
                    continue
                
                # è®¡ç®—è·ç¦»
                pos_i = vehicle_data[veh_id_i].get('position', 0.0)
                pos_j = vehicle_data[veh_id_j].get('position', 0.0)
                speed_i = vehicle_data[veh_id_i].get('speed', 0.0)
                speed_j = vehicle_data[veh_id_j].get('speed', 0.0)
                
                distance = abs(pos_i - pos_j)
                if distance < 50:  # 50ç±³å†…
                    edge_indices.append([i, j])
                    
                    # è¾¹ç‰¹å¾: [ç›¸å¯¹è·ç¦», ç›¸å¯¹é€Ÿåº¦, TTC, THW]
                    rel_distance = distance
                    rel_speed = abs(speed_i - speed_j)
                    
                    # ä¼°ç®—TTCå’ŒTHW
                    ttc = rel_distance / max(rel_speed, 0.1) if rel_speed > 0 else 100
                    thw = rel_distance / max(speed_i, 0.1) if speed_i > 0 else 100
                    
                    edge_features.append([rel_distance, rel_speed, min(ttc, 10), min(thw, 10)])
        
        # 3. å…¨å±€äº¤é€šæŒ‡æ ‡
        global_metrics = self._calculate_global_metrics(vehicle_data, step)
        
        # 4. è½¬æ¢ä¸ºå¼ é‡
        batch = {
            'node_features': torch.tensor(node_features, dtype=torch.float32).to(self.device),
            'edge_indices': torch.tensor(edge_indices, dtype=torch.long).t().contiguous().to(self.device) if edge_indices else torch.zeros((2, 0), dtype=torch.long).to(self.device),
            'edge_features': torch.tensor(edge_features, dtype=torch.float32).to(self.device) if edge_features else torch.zeros((0, 4), dtype=torch.float32).to(self.device),
            'global_metrics': torch.tensor(global_metrics, dtype=torch.float32).unsqueeze(0).to(self.device),
            'vehicle_ids': vehicle_ids,
            'is_icv': torch.tensor(is_icv_list, dtype=torch.bool).to(self.device),
            'vehicle_states': {
                'ids': vehicle_ids,
                'data': vehicle_data
            }
        }
        
        return batch
    
    def _calculate_global_metrics(self, vehicle_data: Dict[str, Any], step: int) -> List[float]:
        """
        è®¡ç®—å…¨å±€äº¤é€šæŒ‡æ ‡
        """
        speeds = [v['speed'] for v in vehicle_data.values()]
        positions = [v['position'] for v in vehicle_data.values()]
        accelerations = [v['acceleration'] for v in vehicle_data.values()]
        
        avg_speed = np.mean(speeds) if speeds else 0.0
        speed_std = np.std(speeds) if len(speeds) > 1 else 0.0
        avg_accel = np.mean(np.abs(accelerations)) if accelerations else 0.0
        vehicle_count = len(vehicle_data)
        
        # 16ç»´å…¨å±€æŒ‡æ ‡
        metrics = [
            avg_speed, speed_std, avg_accel, vehicle_count,
            step * 0.1,  # å½“å‰æ—¶é—´
            min(positions) if positions else 0.0,  # æœ€å°ä½ç½®
            max(positions) if positions else 0.0,  # æœ€å¤§ä½ç½®
            np.mean(positions) if positions else 0.0,  # å¹³å‡ä½ç½®
            len([v for v in vehicle_data.values() if v.get('is_icv', False)]),  # ICVæ•°é‡
            vehicle_count - len([v for v in vehicle_data.values() if v.get('is_icv', False)]),  # éICVæ•°é‡
            np.sum([v['speed'] for v in vehicle_data.values() if v.get('is_icv', False)]) if vehicle_data else 0.0,  # ICVæ€»é€Ÿåº¦
            np.sum([v['speed'] for v in vehicle_data.values() if not v.get('is_icv', False)]) if vehicle_data else 0.0,  # éICVæ€»é€Ÿåº¦
            avg_speed * vehicle_count,  # æ€»æµé‡
            speed_std * vehicle_count,  # æ€»æ³¢åŠ¨
            avg_accel * vehicle_count,  # æ€»åŠ é€Ÿåº¦
            step % 100  # å‘¨æœŸæ€§ç‰¹å¾
        ]
        
        return metrics
    
    def apply_control(self, vehicle_data: Dict[str, Any], step: int) -> Dict[str, Any]:
        """
        åº”ç”¨æ§åˆ¶ç®—æ³•
        """
        # 1. æ„å»ºæ¨¡å‹è¾“å…¥
        batch = self.build_model_input(vehicle_data, step)
        
        # 2. æ¨¡å‹æ¨ç†
        with torch.no_grad():
            output = self.model(batch, step)
        
        # 3. åº”ç”¨å®‰å…¨åŠ¨ä½œ
        control_results = self._apply_safe_actions(output, vehicle_data)
        
        # 4. æ›´æ–°ç»Ÿè®¡
        self.total_interventions += output['level1_interventions'] + output['level2_interventions']
        self.total_emergency_interventions += output['level2_interventions']
        self.total_controlled_vehicles += len(output['selected_vehicle_ids'])
        
        # 5. è°ƒè¯•è¾“å‡º
        if step % 100 == 0:
            print(f"[Step {step}] æ§åˆ¶: {len(output['selected_vehicle_ids'])}è¾†, "
                  f"å¹²é¢„: {output['level1_interventions'] + output['level2_interventions']}, "
                  f"ç´§æ€¥: {output['level2_interventions']}")
        
        return control_results
    
    def _apply_safe_actions(self, output: Dict[str, Any], vehicle_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        åº”ç”¨å®‰å…¨åŠ¨ä½œåˆ°SUMO
        """
        results = {
            'controlled_vehicles': [],
            'actions_applied': [],
            'safety_interventions': output['level1_interventions'] + output['level2_interventions'],
            'emergency_interventions': output['level2_interventions']
        }
        
        for i, veh_id in enumerate(output['selected_vehicle_ids']):
            if veh_id not in vehicle_data:
                continue
            
            try:
                action = output['safe_actions'][i]
                accel_action = action[0].item() * 5.0  # [-1,1] -> [-5,5]
                lane_action = action[1].item() > 0.5  # æ¦‚ç‡è½¬å¸ƒå°”
                
                # åº”ç”¨åŠ é€Ÿåº¦æ§åˆ¶
                current_speed = traci.vehicle.getSpeed(veh_id)
                new_speed = max(0.0, current_speed + accel_action * 0.1)  # 0.1ç§’æ­¥é•¿
                
                traci.vehicle.setSpeedMode(veh_id, 0)  # å…³é—­SUMOè‡ªåŠ¨æ§åˆ¶
                traci.vehicle.setSpeed(veh_id, new_speed)
                
                # è®°å½•æ§åˆ¶ç»“æœ
                results['controlled_vehicles'].append(veh_id)
                results['actions_applied'].append({
                    'acceleration': accel_action,
                    'lane_change': lane_action,
                    'new_speed': new_speed
                })
                
            except traci.TraCIException as e:
                continue
            except Exception as e:
                continue
        
        return results
```

## ä¸ƒã€è®­ç»ƒè¾…åŠ©å‡½æ•°ï¼ˆå¯é€‰ï¼‰

```python
def train_traffic_controller(config: Dict[str, Any]) -> TrafficController:
    """
    è®­ç»ƒäº¤é€šæ§åˆ¶å™¨
    åŒ…å«ä¸‰é˜¶æ®µè®­ç»ƒæµç¨‹
    """
    print("ğŸ”§ å¼€å§‹è®­ç»ƒäº¤é€šæ§åˆ¶å™¨...")
    
    # 1. åˆå§‹åŒ–æ¨¡å‹
    model = TrafficController(config)
    
    # 2. é˜¶æ®µ1ï¼šä¸–ç•Œæ¨¡å‹é¢„è®­ç»ƒ
    print("ğŸ”„ é˜¶æ®µ1ï¼šä¸–ç•Œæ¨¡å‹é¢„è®­ç»ƒ...")
    model.world_model.set_phase(1)
    # ... è®­ç»ƒä»£ç 
    
    # 3. é˜¶æ®µ2ï¼šå®‰å…¨RLè®­ç»ƒ
    print("ğŸ”„ é˜¶æ®µ2ï¼šå®‰å…¨RLè®­ç»ƒ...")
    model.world_model.set_phase(2)
    # ... è®­ç»ƒä»£ç 
    
    # 4. é˜¶æ®µ3ï¼šçº¦æŸä¼˜åŒ–
    print("ğŸ”„ é˜¶æ®µ3ï¼šçº¦æŸä¼˜åŒ–...")
    # ... è®­ç»ƒä»£ç 
    
    print("âœ… è®­ç»ƒå®Œæˆ!")
    return model

def evaluate_controller(model: TrafficController, sumo_cfg: str, max_steps: int = 3600):
    """
    è¯„ä¼°æ§åˆ¶å™¨æ€§èƒ½
    """
    # åˆå§‹åŒ–SUMO
    sumo_binary = "sumo"
    sumo_cmd = [sumo_binary, "-c", sumo_cfg, "--no-warnings", "true"]
    traci.start(sumo_cmd)
    
    try:
        step = 0
        total_reward = 0
        
        while step < max_steps:
            traci.simulationStep()
            
            # æ”¶é›†è½¦è¾†æ•°æ®
            vehicle_data = collect_vehicle_data()
            
            # åº”ç”¨æ§åˆ¶
            control_results = model.apply_control(vehicle_data, step)
            
            # è®¡ç®—å¥–åŠ±
            reward = calculate_reward(vehicle_data, control_results)
            total_reward += reward
            
            step += 1
            
            if step % 100 == 0:
                print(f"Evaluation Step {step}/{max_steps}, Total Reward: {total_reward:.2f}")
        
        print(f"ğŸ“ˆ è¯„ä¼°å®Œæˆ! å¹³å‡å¥–åŠ±: {total_reward / max_steps:.2f}")
        
    finally:
        traci.close()
    
    return total_reward

def collect_vehicle_data() -> Dict[str, Any]:
    """
    æ”¶é›†è½¦è¾†æ•°æ®
    """
    vehicle_data = {}
    vehicle_ids = traci.vehicle.getIDList()
    
    for veh_id in vehicle_ids:
        try:
            # ç¡®å®šæ˜¯å¦ä¸ºICV (25%æ¦‚ç‡)
            is_icv = hash(veh_id) % 100 < 25
            
            vehicle_data[veh_id] = {
                'position': traci.vehicle.getLanePosition(veh_id),
                'speed': traci.vehicle.getSpeed(veh_id),
                'acceleration': traci.vehicle.getAcceleration(veh_id),
                'lane_index': traci.vehicle.getLaneIndex(veh_id),
                'remaining_distance': 1000.0,  # ç®€åŒ–
                'completion_rate': 0.5,  # ç®€åŒ–
                'is_icv': is_icv,
                'id': veh_id,
                'lane_id': traci.vehicle.getLaneID(veh_id)
            }
        except:
            continue
    
    return vehicle_data

def calculate_reward(vehicle_data: Dict[str, Any], control_results: Dict[str, Any]) -> float:
    """
    è®¡ç®—å¥–åŠ±
    """
    # ç®€åŒ–å¥–åŠ±å‡½æ•°
    avg_speed = np.mean([v['speed'] for v in vehicle_data.values()]) if vehicle_data else 0.0
    speed_std = np.std([v['speed'] for v in vehicle_data.values()]) if len(vehicle_data) > 1 else 0.0
    intervention_cost = control_results['safety_interventions'] * 0.1
    
    # å¥–åŠ± = é€Ÿåº¦å¥–åŠ± - ä¸ç¨³å®šæƒ©ç½š - å¹²é¢„æˆæœ¬
    reward = avg_speed * 0.1 - speed_std * 0.5 - intervention_cost
    
    return reward
```

## å…«ã€å®Œæ•´é›†æˆåˆ°main.py

```python
from neural_traffic_controller import NeuralTrafficController
import json

class SUMOCompetitionFramework:
    # ... å…¶ä»–ä»£ç ä¿æŒä¸å˜ ...
    
    def __init__(self, sumo_cfg_path):
        # ... åŸæœ‰åˆå§‹åŒ–ä»£ç  ...
        
        # åˆå§‹åŒ–ç¥ç»æ§åˆ¶å™¨
        self.neural_controller = None
        self.use_neural_control = True  # å¯ç”¨ç¥ç»æ§åˆ¶
        
        # åŠ è½½æ§åˆ¶å™¨é…ç½®
        controller_config = {
            'node_dim': 9,
            'edge_dim': 4,
            'gnn_hidden_dim': 64,
            'gnn_output_dim': 256,
            'gnn_layers': 3,
            'gnn_heads': 4,
            'world_hidden_dim': 128,
            'future_steps': 5,
            'controller_hidden_dim': 128,
            'global_dim': 16,
            'top_k': 5,
            'ttc_threshold': 2.0,
            'thw_threshold': 1.5,
            'max_accel': 2.0,
            'max_decel': -3.0,
            'emergency_decel': -5.0,
            'max_lane_change_speed': 5.0,
            'cost_limit': 0.1,
            'lambda_lr': 0.01,
            'cache_timeout': 10,
            'device': 'cpu',  # ä½¿ç”¨CPUä»¥ç¡®ä¿å…¼å®¹æ€§
            'model_path': None  # é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
        }
        
        try:
            self.neural_controller = NeuralTrafficController(config_path=None)
            print("âœ… ç¥ç»äº¤é€šæ§åˆ¶å™¨å·²åŠ è½½")
        except Exception as e:
            print(f"âŒ ç¥ç»æ§åˆ¶å™¨åŠ è½½å¤±è´¥: {e}")
            self.use_neural_control = False
    
    def apply_control_algorithm(self, step):
        """
        åº”ç”¨æ§åˆ¶ä¼˜åŒ–ç®—æ³•
        """
        # ============================================================
        # å‚èµ›è€…ä»£ç åŒºåŸŸå¼€å§‹
        # ============================================================
        
        # ä»…åœ¨ç‰¹å®šæ­¥æ•°æ‰§è¡Œæ§åˆ¶ä»¥é™ä½è®¡ç®—å¼€é”€
        if step % 5 != 0:
            return
        
        if self.use_neural_control and self.neural_controller:
            try:
                # æ”¶é›†å½“å‰è½¦è¾†æ•°æ®
                vehicle_data = self._collect_current_vehicle_data()
                
                if not vehicle_data:
                    return
                
                # åº”ç”¨ç¥ç»æ§åˆ¶
                control_results = self.neural_controller.apply_control(vehicle_data, step)
                
                # è®°å½•æ§åˆ¶ç»Ÿè®¡
                self._record_control_statistics(control_results, step)
                
            except Exception as e:
                print(f"âš ï¸  ç¥ç»æ§åˆ¶æ‰§è¡Œé”™è¯¯: {e}")
                # å›é€€åˆ°åŸºç¡€æ§åˆ¶
                self._fallback_control_algorithm(step)
        else:
            # å›é€€åˆ°åŸºç¡€æ§åˆ¶
            self._fallback_control_algorithm(step)
        
        # ============================================================
        # å‚èµ›è€…ä»£ç åŒºåŸŸç»“æŸ
        # ============================================================
    
    def _collect_current_vehicle_data(self) -> Dict[str, Any]:
        """æ”¶é›†å½“å‰è½¦è¾†æ•°æ®"""
        vehicle_data = {}
        vehicle_ids = traci.vehicle.getIDList()
        
        for veh_id in vehicle_ids:
            try:
                # ç¡®å®šæ˜¯å¦ä¸ºICV (25%æ¦‚ç‡)
                is_icv = hash(veh_id) % 100 < 25
                
                # è·å–è½¦è¾†ä½ç½®ï¼ˆç®€åŒ–ï¼‰
                try:
                    position = traci.vehicle.getLanePosition(veh_id)
                except:
                    position = 0.0
                
                vehicle_data[veh_id] = {
                    'position': position,
                    'speed': traci.vehicle.getSpeed(veh_id),
                    'acceleration': traci.vehicle.getAcceleration(veh_id),
                    'lane_index': traci.vehicle.getLaneIndex(veh_id),
                    'remaining_distance': 1000.0,  # ç®€åŒ–
                    'completion_rate': 0.5,  # ç®€åŒ–
                    'is_icv': is_icv,
                    'id': veh_id,
                    'lane_id': traci.vehicle.getLaneID(veh_id)
                }
            except Exception as e:
                continue
        
        return vehicle_data
    
    def _fallback_control_algorithm(self, step):
        """å›é€€æ§åˆ¶ç®—æ³•"""
        # ç®€å•çš„è‡ªé€‚åº”é€Ÿåº¦æ§åˆ¶
        vehicle_ids = traci.vehicle.getIDList()
        
        for veh_id in vehicle_ids:
            try:
                current_speed = traci.vehicle.getSpeed(veh_id)
                edge_id = traci.vehicle.getRoadID(veh_id)
                
                # ä»…æ§åˆ¶25%çš„è½¦è¾†ï¼ˆæ¨¡æ‹ŸICVï¼‰
                if hash(veh_id) % 4 != 0:  # 25%æ¦‚ç‡
                    continue
                
                # åŸºäºå‰æ–¹è½¦è¾†æ•°çš„é€Ÿåº¦æ§åˆ¶
                leader_count = 0
                try:
                    next_edge = traci.vehicle.getRoute(veh_id)[traci.vehicle.getRouteIndex(veh_id) + 1]
                    leader_count = traci.edge.getLastStepVehicleNumber(next_edge)
                except:
                    leader_count = 0
                
                # è°ƒæ•´é€Ÿåº¦
                if leader_count > 5:
                    target_speed = max(5.0, current_speed - 1.0)
                else:
                    target_speed = min(25.0, current_speed + 0.5)
                
                traci.vehicle.setSpeedMode(veh_id, 0)  # å…³é—­SUMOè‡ªåŠ¨æ§åˆ¶
                traci.vehicle.setSpeed(veh_id, target_speed)
                
            except Exception as e:
                continue
    
    def _record_control_statistics(self, control_results: Dict[str, Any], step: int):
        """è®°å½•æ§åˆ¶ç»Ÿè®¡"""
        if not hasattr(self, 'control_stats'):
            self.control_stats = {
                'total_interventions': 0,
                'total_emergency_interventions': 0,
                'total_controlled_vehicles': 0,
                'step_records': []
            }
        
        self.control_stats['total_interventions'] += control_results['safety_interventions']
        self.control_stats['total_emergency_interventions'] += control_results['emergency_interventions']
        self.control_stats['total_controlled_vehicles'] += len(control_results['controlled_vehicles'])
        
        # æ¯100æ­¥è®°å½•ä¸€æ¬¡
        if step % 100 == 0:
            record = {
                'step': step,
                'controlled_vehicles': len(control_results['controlled_vehicles']),
                'interventions': control_results['safety_interventions'],
                'emergency_interventions': control_results['emergency_interventions']
            }
            self.control_stats['step_records'].append(record)
```

## ä¹ã€æ¨¡å‹é…ç½®ä¸è®­ç»ƒè„šæœ¬

```python
# train_config.json
{
    "training": {
        "phase1_epochs": 50,
        "phase2_epochs": 200,
        "phase3_epochs": 100,
        "batch_size": 64,
        "learning_rate": 0.0003,
        "weight_decay": 0.0001
    },
    "model": {
        "node_dim": 9,
        "edge_dim": 4,
        "gnn_hidden_dim": 64,
        "gnn_output_dim": 256,
        "gnn_layers": 3,
        "gnn_heads": 4,
        "world_hidden_dim": 128,
        "future_steps": 5,
        "controller_hidden_dim": 128,
        "global_dim": 16,
        "top_k": 5
    },
    "safety": {
        "ttc_threshold": 2.0,
        "thw_threshold": 1.5,
        "max_accel": 2.0,
        "max_decel": -3.0,
        "emergency_decel": -5.0,
        "max_lane_change_speed": 5.0
    },
    "constraint": {
        "cost_limit": 0.1,
        "lambda_lr": 0.01,
        "alpha": 1.0,
        "beta": 5.0
    },
    "device": "cuda",
    "save_path": "models/traffic_controller_v1.pth"
}

# train.py
import torch
import json
from neural_traffic_controller import TrafficController, train_traffic_controller

def main():
    # åŠ è½½é…ç½®
    with open('train_config.json', 'r') as f:
        config = json.load(f)
    
    # è®­ç»ƒæ¨¡å‹
    model = train_traffic_controller(config['model'])
    
    # ä¿å­˜æ¨¡å‹
    torch.save({
        'model_state_dict': model.state_dict(),
        'config': config
    }, config['training']['save_path'])
    
    print(f"âœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {config['training']['save_path']}")

if __name__ == "__main__":
    main()
```

## æ€»ç»“

è¿™å¥—å®Œæ•´çš„ç¥ç»ç½‘ç»œè®¾è®¡ä¸ºæ™ºèƒ½äº¤é€šååŒæ§åˆ¶æä¾›äº†é«˜æ•ˆã€å®‰å…¨çš„è§£å†³æ–¹æ¡ˆï¼š

1. **é«˜æ•ˆæ„ŸçŸ¥**ï¼šRisk-Sensitive GNNç²¾ç¡®æ•æ‰äº¤é€šé£é™©å’Œå…³é”®äº¤äº’
2. **ç²¾å‡†é¢„æµ‹**ï¼šProgressive World Modelæä¾›5æ­¥å‰ç»é¢„æµ‹
3. **ç¨€ç–æ§åˆ¶**ï¼šä»…æ§åˆ¶5%æœ€å…·å½±å“åŠ›çš„ICVè½¦è¾†ï¼Œå¤§å¹…é™ä½å¹²é¢„æˆæœ¬
4. **å®‰å…¨ä¿éšœ**ï¼šåŒæ¨¡æ€å®‰å…¨å±éšœç¡®ä¿100%æŒ‡ä»¤å®‰å…¨
5. **çº¦æŸä¼˜åŒ–**ï¼šæ‹‰æ ¼æœ—æ—¥ä¹˜å­è‡ªåŠ¨å¹³è¡¡æ€§èƒ½ä¸æˆæœ¬

è¯¥è®¾è®¡ä¸¥æ ¼éµå®ˆç«èµ›è§„åˆ™ï¼Œä¸ä¿®æ”¹ODè·¯å¾„ï¼Œä»…æ§åˆ¶25%çš„æ™ºèƒ½è½¦è¾†ï¼Œåœ¨ä¿æŒä½å¹²é¢„æˆæœ¬çš„åŒæ—¶æœ€å¤§åŒ–äº¤é€šæ•ˆç‡ã€‚å®Œæ•´ä»£ç å¯ç›´æ¥é›†æˆåˆ°æä¾›çš„SUMOæ¡†æ¶ä¸­ï¼Œå¼€ç®±å³ç”¨ã€‚
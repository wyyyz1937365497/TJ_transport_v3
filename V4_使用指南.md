# v4.0 æ™ºèƒ½äº¤é€šååŒæ§åˆ¶ç³»ç»Ÿ - ä½¿ç”¨æŒ‡å—

## ğŸ“‹ ç›®å½•

1. [ç³»ç»Ÿæ¦‚è¿°](#ç³»ç»Ÿæ¦‚è¿°)
2. [æ¶æ„è®¾è®¡](#æ¶æ„è®¾è®¡)
3. [æ ¸å¿ƒç»„ä»¶](#æ ¸å¿ƒç»„ä»¶)
4. [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
5. [è¯¦ç»†é…ç½®](#è¯¦ç»†é…ç½®)
6. [è®­ç»ƒæŒ‡å—](#è®­ç»ƒæŒ‡å—)
7. [éƒ¨ç½²æŒ‡å—](#éƒ¨ç½²æŒ‡å—)
8. [API å‚è€ƒ](#api-å‚è€ƒ)
9. [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)
10. [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)

---

## ç³»ç»Ÿæ¦‚è¿°

v4.0 æ™ºèƒ½äº¤é€šååŒæ§åˆ¶ç³»ç»Ÿæ˜¯ä¸€ä¸ªåŸºäºæ·±åº¦å¼ºåŒ–å­¦ä¹ çš„äº¤é€šæµä¼˜åŒ–è§£å†³æ–¹æ¡ˆï¼Œé€šè¿‡"æŒ‰éœ€å¹²é¢„"ç­–ç•¥åœ¨ 25% æ™ºèƒ½è½¦è¾†æ¸—é€ç‡çº¦æŸä¸‹ä¼˜åŒ–å…¨å±€äº¤é€šæ•ˆç‡ã€‚

### æ ¸å¿ƒç›®æ ‡

- **æœ€å¤§åŒ–æ€§èƒ½å¾—åˆ† (S_perf)**ï¼šæå‡å¹³å‡é€Ÿåº¦ã€ååé‡å’Œ OD å®Œæˆç‡
- **æœ€å°åŒ–å¹²é¢„æˆæœ¬ (P_int)**ï¼šæ§åˆ¶å—æ§è½¦è¾†æ•°é‡å’Œå¹²é¢„é¢‘ç‡
- **æœ€å¤§åŒ–æ€»è¯„åˆ†**ï¼šS_total = S_perf Ã— P_int

### ä¸»è¦ç‰¹æ€§

- âœ… é£é™©æ•æ„Ÿå¼‚æ„å›¾ç¥ç»ç½‘ç»œï¼ˆRisk-Sensitive GNNï¼‰
- âœ… æ¸è¿›å¼ä¸–ç•Œæ¨¡å‹ï¼ˆProgressive World Modelï¼‰
- âœ… Top-K ç¨€ç–æ§åˆ¶æœºåˆ¶
- âœ… åŒæ¨¡æ€å®‰å…¨å±éšœï¼ˆDual-Mode Safety Shieldï¼‰
- âœ… äº‹ä»¶è§¦å‘æ§åˆ¶æœºåˆ¶
- âœ… Ray RLlib åˆ†å¸ƒå¼è®­ç»ƒæ”¯æŒ
- âœ… TraCI è®¢é˜…ä¼˜åŒ–

---

## æ¶æ„è®¾è®¡

### æ•°æ®æµå›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     SUMO ä»¿çœŸç¯å¢ƒ                              â”‚
â”‚  (è½¦è¾†çŠ¶æ€ã€ä½ç½®ã€é€Ÿåº¦ã€åŠ é€Ÿåº¦ã€ä¿¡å·ç¯çŠ¶æ€ç­‰)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Phase 2: æ„ŸçŸ¥å±‚ - Risk-Sensitive GNN            â”‚
â”‚  â€¢ æ„å»ºå¼‚æ„å›¾ï¼ˆèŠ‚ç‚¹ï¼šè½¦è¾†ï¼Œè¾¹ï¼šäº¤äº’å…³ç³»ï¼‰                       â”‚
â”‚  â€¢ è¾¹ç‰¹å¾ï¼šTTCï¼ˆç¢°æ’æ—¶é—´ï¼‰ã€THWï¼ˆè½¦å¤´æ—¶è·ï¼‰å€’æ•°                  â”‚
â”‚  â€¢ Biased Attention æœºåˆ¶å¼ºåŒ–é«˜é£é™©äº¤äº’                          â”‚
â”‚  â€¢ è¾“å‡ºï¼š256ç»´å…¨å±€åµŒå…¥ + é‡è¦æ€§åˆ†æ•°                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Phase 3: é¢„æµ‹å±‚ - Progressive World Model           â”‚
â”‚  â€¢ Phase 1: é¢„æµ‹ä¸‹ä¸€æ—¶åˆ»è½¦è¾†çŠ¶æ€ï¼ˆä½ç½®ã€é€Ÿåº¦ï¼‰                  â”‚
â”‚  â€¢ Phase 2: è§£è€¦è¾“å‡ºä¸º z_flowï¼ˆæµæ¼”åŒ–ï¼‰ä¸ z_riskï¼ˆé£é™©æ¼”åŒ–ï¼‰    â”‚
â”‚  â€¢ è”åˆä¼˜åŒ–è½¨è¿¹ MSE ä¸å†²çªåˆ†ç±»æŸå¤±                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Phase 4: å†³ç­–å±‚ - Influence-Driven Controller        â”‚
â”‚  â€¢ å½±å“åŠ›å¾—åˆ†è®¡ç®—ï¼šScore_i = Î±Â·Importance_GNN + Î²Â·Impact_Predicted â”‚
â”‚  â€¢ Top-K é€‰æ‹©ï¼ˆK=5ï¼‰å…³é”® ICV è½¦è¾†                            â”‚
â”‚  â€¢ å…¶ä½™è½¦è¾†ä½¿ç”¨ IDM æ¨¡å‹è·Ÿé©°                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Phase 5: å®‰å…¨çº¦æŸ - Dual-Mode Safety Shield          â”‚
â”‚  â€¢ Level 1: åŠ¨ä½œè£å‰ªï¼ˆåŠ é€Ÿåº¦é™å¹…ã€é€Ÿåº¦éè´Ÿï¼‰                    â”‚
â”‚  â€¢ Level 2: TTC < 2.0s æ—¶å¼ºåˆ¶ç´§æ€¥åˆ¶åŠ¨                         â”‚
â”‚  â€¢ è®­ç»ƒä¸­æ–½åŠ å·¨å¤§è´Ÿå¥–åŠ±é¿å…è¿›å…¥é«˜å±çŠ¶æ€                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Phase 6: äº‹ä»¶è§¦å‘ - Event-Triggered Controller       â”‚
â”‚  â€¢ é»˜è®¤ 10 ç§’æ§åˆ¶å‘¨æœŸ                                         â”‚
â”‚  â€¢ é«˜å±äº‹ä»¶å¯ä¸­æ–­ï¼ˆTTC < 1.5sã€æ‹¥å µæ¯”ä¾‹ > 60%ï¼‰               â”‚
â”‚  â€¢ æ”¯æŒå¤šç§äº‹ä»¶ç±»å‹ï¼ˆNORMALã€HIGH_RISKã€CONGESTIONã€EMERGENCYï¼‰ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Phase 7: åŠ¨ä½œåº”ç”¨ - SUMO TraCI                   â”‚
â”‚  â€¢ æ‰¹é‡åº”ç”¨å®‰å…¨åŠ¨ä½œåˆ° SUMO                                    â”‚
â”‚  â€¢ éå—æ§è½¦è¾†ä½¿ç”¨ IDM æ¨¡å‹                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### é›†æˆæ¶æ„

```python
# å®Œæ•´é›†æˆæµç¨‹
V4CompleteIntegration
â”œâ”€â”€ SUMORLEnvironmentOptimized (TraCI è®¢é˜…ä¼˜åŒ–)
â”œâ”€â”€ RiskSensitiveGNN (æ„ŸçŸ¥å±‚)
â”œâ”€â”€ ProgressiveWorldModel (é¢„æµ‹å±‚)
â”œâ”€â”€ InfluenceDrivenController (å†³ç­–å±‚)
â”œâ”€â”€ IDMController (é ICV è½¦è¾†æ§åˆ¶)
â”œâ”€â”€ DualModeSafetyShield (å®‰å…¨çº¦æŸ)
â”œâ”€â”€ SafetyReward (å®‰å…¨å¥–åŠ±)
â”œâ”€â”€ ActionClipper (åŠ¨ä½œè£å‰ª)
â””â”€â”€ EventTriggeredController (äº‹ä»¶è§¦å‘)
```

---

## æ ¸å¿ƒç»„ä»¶

### 1. Risk-Sensitive GNNï¼ˆæ„ŸçŸ¥å±‚ï¼‰

**æ–‡ä»¶**: [`risk_sensitive_gnn.py`](risk_sensitive_gnn.py)

**åŠŸèƒ½**:
- æ„å»ºäº¤é€šå¼‚æ„å›¾ï¼Œæ•æ‰è½¦è¾†é—´äº¤äº’å…³ç³»
- ä½¿ç”¨ Biased Attention æœºåˆ¶å¼ºåŒ–é«˜é£é™©äº¤äº’
- è¾“å‡ºè½¦è¾†é‡è¦æ€§åˆ†æ•°

**å…³é”®å‚æ•°**:
```python
node_feature_dim = 9      # èŠ‚ç‚¹ç‰¹å¾ç»´åº¦
edge_feature_dim = 4      # è¾¹ç‰¹å¾ç»´åº¦ï¼ˆTTCã€THW ç­‰ï¼‰
hidden_dim = 256          # éšè—å±‚ç»´åº¦
num_heads = 4             # æ³¨æ„åŠ›å¤´æ•°
num_layers = 2            # GNN å±‚æ•°
```

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from risk_sensitive_gnn import RiskSensitiveGNN

gnn = RiskSensitiveGNN(
    node_feature_dim=9,
    edge_feature_dim=4,
    hidden_dim=256,
    num_heads=4
)

# å‰å‘ä¼ æ’­
embeddings = gnn(node_features, edge_indices, edge_features)
```

### 2. Progressive World Modelï¼ˆé¢„æµ‹å±‚ï¼‰

**æ–‡ä»¶**: [`progressive_world_model.py`](progressive_world_model.py)

**åŠŸèƒ½**:
- ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥
- Phase 1: å­¦ä¹ åŸºç¡€åŠ¨åŠ›å­¦
- Phase 2: è§£è€¦æµæ¼”åŒ–ä¸é£é™©æ¼”åŒ–

**å…³é”®å‚æ•°**:
```python
state_dim = 9             # çŠ¶æ€ç»´åº¦
hidden_dim = 256          # éšè—å±‚ç»´åº¦
latent_dim = 64           # æ½œåœ¨ç»´åº¦
num_layers = 2            # LSTM å±‚æ•°
```

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from progressive_world_model import ProgressiveWorldModel

model = ProgressiveWorldModel(
    state_dim=9,
    hidden_dim=256,
    latent_dim=64
)

# è®¾ç½®è®­ç»ƒé˜¶æ®µ
model.set_phase(phase=2)

# å‰å‘ä¼ æ’­
predictions = model(state_tensor)
```

### 3. Influence-Driven Controllerï¼ˆå†³ç­–å±‚ï¼‰

**æ–‡ä»¶**: [`influence_controller.py`](influence_controller.py)

**åŠŸèƒ½**:
- è®¡ç®—æ¯è¾†è½¦çš„å½±å“åŠ›å¾—åˆ†
- Top-K é€‰æ‹©å…³é”®è½¦è¾†
- å¯¹éå—æ§è½¦è¾†åº”ç”¨ IDM æ¨¡å‹

**å…³é”®å‚æ•°**:
```python
state_dim = 9             # çŠ¶æ€ç»´åº¦
hidden_dim = 128          # éšè—å±‚ç»´åº¦
top_k = 5                 # Top-K é€‰æ‹©æ•°é‡
alpha = 1.0               # GNN é‡è¦æ€§æƒé‡
beta = 5.0                # é¢„æµ‹å½±å“åŠ›æƒé‡
```

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from influence_controller import InfluenceDrivenController

controller = InfluenceDrivenController(
    state_dim=9,
    hidden_dim=128,
    top_k=5
)

# å‰å‘ä¼ æ’­
control_output = controller(state_tensor, gnn_importance)
selected_ids = control_output['selected_vehicle_ids']
actions = control_output['actions']
```

### 4. Dual-Mode Safety Shieldï¼ˆå®‰å…¨çº¦æŸï¼‰

**æ–‡ä»¶**: [`safety_shield.py`](safety_shield.py)

**åŠŸèƒ½**:
- Level 1: åŠ¨ä½œè£å‰ª
- Level 2: ç´§æ€¥åˆ¶åŠ¨
- å®‰å…¨å¥–åŠ±è®¡ç®—

**å…³é”®å‚æ•°**:
```python
ttc_threshold = 2.0               # TTC é˜ˆå€¼ï¼ˆç§’ï¼‰
thw_threshold = 1.5               # THW é˜ˆå€¼ï¼ˆç§’ï¼‰
emergency_deceleration = -4.5      # ç´§æ€¥åˆ¶åŠ¨å‡é€Ÿåº¦
max_acceleration = 3.0             # æœ€å¤§åŠ é€Ÿåº¦
min_acceleration = -3.0            # æœ€å°åŠ é€Ÿåº¦
```

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from safety_shield import DualModeSafetyShield, SafetyReward, ActionClipper

safety_shield = DualModeSafetyShield(
    ttc_threshold=2.0,
    emergency_deceleration=-4.5
)

safety_reward = SafetyReward(
    emergency_penalty=-100.0,
    warning_penalty=-10.0
)

action_clipper = ActionClipper(
    max_acceleration=3.0,
    min_acceleration=-3.0
)

# æ£€æŸ¥ç´§æ€¥æ¡ä»¶
is_emergency, is_warning = safety_shield.check_emergency_conditions(
    veh_id, speed, road_id, lane_id
)

# è£å‰ªåŠ¨ä½œ
clipped_accel, is_clipped = action_clipper.clip_acceleration(
    accel_action, speed
)
```

### 5. Event-Triggered Controllerï¼ˆäº‹ä»¶è§¦å‘ï¼‰

**æ–‡ä»¶**: [`event_triggered_controller.py`](event_triggered_controller.py)

**åŠŸèƒ½**:
- äº‹ä»¶è§¦å‘æ§åˆ¶æœºåˆ¶
- æ”¯æŒå¤šç§äº‹ä»¶ç±»å‹
- å®šæ—¶å…œåº•æ§åˆ¶

**å…³é”®å‚æ•°**:
```python
control_interval = 10.0                     # æ§åˆ¶é—´éš”ï¼ˆç§’ï¼‰
emergency_ttc_threshold = 1.5              # ç´§æ€¥ TTC é˜ˆå€¼
high_risk_ttc_threshold = 2.0              # é«˜é£é™© TTC é˜ˆå€¼
congestion_speed_threshold = 5.0           # æ‹¥å µé€Ÿåº¦é˜ˆå€¼
congestion_ratio_threshold = 0.6            # æ‹¥å µæ¯”ä¾‹é˜ˆå€¼
```

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from event_triggered_controller import EventTriggeredController

event_controller = EventTriggeredController(
    control_interval=10.0,
    emergency_ttc_threshold=1.5
)

# æ£€æŸ¥æ˜¯å¦åº”è¯¥è§¦å‘æ§åˆ¶
should_control, event_type = event_controller.should_trigger_control(
    observation, safety_info, current_time
)
```

### 6. Ray RLlib Integrationï¼ˆåˆ†å¸ƒå¼è®­ç»ƒï¼‰

**æ–‡ä»¶**: [`ray_rllib_integration.py`](ray_rllib_integration.py)

**åŠŸèƒ½**:
- Ray RLlib åˆ†å¸ƒå¼è®­ç»ƒé›†æˆ
- å¤šè¿›ç¨‹å¹¶è¡Œ SUMO å®ä¾‹
- GPU æ‰¹é‡æ¨¡å‹æ›´æ–°

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from ray_rllib_integration import RayRLlibTrainer

trainer = RayRLlibTrainer(
    env_name="SUMORayEnvironment",
    num_workers=4,
    num_gpus=1
)

# è®­ç»ƒ
for epoch in range(100):
    result = trainer.train()
    print(f"Epoch {epoch}: reward={result['episode_reward_mean']}")
```

### 7. TraCI Subscription Optimizationï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰

**æ–‡ä»¶**: [`sumo_rl_env_optimized.py`](sumo_rl_env_optimized.py)

**åŠŸèƒ½**:
- TraCI è®¢é˜…ç®¡ç†
- æ‰¹é‡è·å–è½¦è¾†æ•°æ®
- ç¼“å­˜æœºåˆ¶

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from sumo_rl_env_optimized import SUMORLEnvironmentOptimized

env = SUMORLEnvironmentOptimized(
    sumo_cfg_path='ä»¿çœŸç¯å¢ƒ-åˆèµ›/sumo.sumocfg',
    use_subscription=True
)

observation = env.reset()
observation, reward, done, info = env.step({})
```

### 8. V4 Complete Integrationï¼ˆå®Œæ•´é›†æˆï¼‰

**æ–‡ä»¶**: [`v4_integration.py`](v4_integration.py)

**åŠŸèƒ½**:
- åè°ƒæ‰€æœ‰ç»„ä»¶ä¹‹é—´çš„æ•°æ®äº¤äº’
- å®ç°å®Œæ•´çš„ 7 é˜¶æ®µé›†æˆæµç¨‹
- æä¾›ç»Ÿä¸€çš„è®­ç»ƒå’Œæ¨ç†æ¥å£

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from v4_integration import V4CompleteIntegration

integration = V4CompleteIntegration(
    sumo_cfg_path='ä»¿çœŸç¯å¢ƒ-åˆèµ›/sumo.sumocfg',
    device='cuda',
    top_k=5,
    icv_penetration=0.25,
    control_interval=10.0
)

# é‡ç½®
observation = integration.reset()

# è¿è¡Œ
for step in range(1000):
    observation, reward, done, info = integration.step()
    
    if done:
        break

# è·å–ç»Ÿè®¡
stats = integration.get_statistics()
```

---

## å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

- Python 3.8+
- PyTorch 1.10+
- SUMO 1.24.0+
- Ray 2.0+ (å¯é€‰ï¼Œç”¨äºåˆ†å¸ƒå¼è®­ç»ƒ)
- CUDA 11.0+ (å¯é€‰ï¼Œç”¨äº GPU åŠ é€Ÿ)

### å®‰è£…ä¾èµ–

```bash
# å…‹éš†ä»“åº“
git clone <repository_url>
cd TJ_transport_v3

# å®‰è£…åŸºç¡€ä¾èµ–
pip install -r requirements.txt

# å®‰è£… SUMO
# ä» https://sumo.dlr.de/docs/Downloads.php ä¸‹è½½å¹¶å®‰è£…
# æˆ–ä½¿ç”¨åŒ…ç®¡ç†å™¨å®‰è£…
sudo apt-get install sumo sumo-tools

# å®‰è£… Ray (å¯é€‰ï¼Œç”¨äºåˆ†å¸ƒå¼è®­ç»ƒ)
pip install "ray[rllib]" torch torchvision
```

### åŸºç¡€ä½¿ç”¨

#### 1. è¿è¡Œå®Œæ•´é›†æˆç³»ç»Ÿ

```bash
python v4_integration.py
```

#### 2. è¿è¡Œ Ray RLlib è®­ç»ƒ

```bash
python ray_rllib_integration.py
```

#### 3. è¿è¡Œäº‹ä»¶è§¦å‘æ§åˆ¶å™¨

```bash
python event_triggered_controller.py
```

#### 4. è¿è¡Œ TraCI ä¼˜åŒ–ç¯å¢ƒ

```bash
python sumo_rl_env_optimized.py
```

### é…ç½®æ–‡ä»¶

åˆ›å»º `config.json`:

```json
{
  "sumo_cfg_path": "ä»¿çœŸç¯å¢ƒ-åˆèµ›/sumo.sumocfg",
  "device": "cuda",
  "gnn": {
    "hidden_dim": 256,
    "num_heads": 4,
    "num_layers": 2
  },
  "world_model": {
    "hidden_dim": 256,
    "latent_dim": 64,
    "num_layers": 2
  },
  "controller": {
    "top_k": 5,
    "alpha": 1.0,
    "beta": 5.0
  },
  "safety": {
    "ttc_threshold": 2.0,
    "thw_threshold": 1.5,
    "emergency_deceleration": -4.5
  },
  "event_trigger": {
    "control_interval": 10.0,
    "emergency_ttc_threshold": 1.5
  },
  "training": {
    "max_steps": 3600,
    "use_gui": false,
    "icv_penetration": 0.25
  }
}
```

---

## è¯¦ç»†é…ç½®

### GNN é…ç½®

```python
from risk_sensitive_gnn import RiskSensitiveGNN

gnn = RiskSensitiveGNN(
    node_feature_dim=9,        # èŠ‚ç‚¹ç‰¹å¾ç»´åº¦
    edge_feature_dim=4,        # è¾¹ç‰¹å¾ç»´åº¦
    hidden_dim=256,            # éšè—å±‚ç»´åº¦ï¼ˆæ¨èï¼š128-512ï¼‰
    num_heads=4,               # æ³¨æ„åŠ›å¤´æ•°ï¼ˆæ¨èï¼š4-8ï¼‰
    num_layers=2,              # GNN å±‚æ•°ï¼ˆæ¨èï¼š2-4ï¼‰
    dropout=0.1               # Dropout æ¯”ä¾‹
)
```

### ä¸–ç•Œæ¨¡å‹é…ç½®

```python
from progressive_world_model import ProgressiveWorldModel

model = ProgressiveWorldModel(
    state_dim=9,              # çŠ¶æ€ç»´åº¦
    hidden_dim=256,            # éšè—å±‚ç»´åº¦ï¼ˆæ¨èï¼š128-512ï¼‰
    latent_dim=64,             # æ½œåœ¨ç»´åº¦ï¼ˆæ¨èï¼š32-128ï¼‰
    num_layers=2,              # LSTM å±‚æ•°ï¼ˆæ¨èï¼š2-4ï¼‰
    device='cuda'              # è®¡ç®—è®¾å¤‡
)

# è®¾ç½®è®­ç»ƒé˜¶æ®µ
model.set_phase(phase=1)  # Phase 1: åŸºç¡€åŠ¨åŠ›å­¦
model.set_phase(phase=2)  # Phase 2: æµæ¼”åŒ– + é£é™©æ¼”åŒ–
```

### æ§åˆ¶å™¨é…ç½®

```python
from influence_controller import InfluenceDrivenController

controller = InfluenceDrivenController(
    state_dim=9,              # çŠ¶æ€ç»´åº¦
    hidden_dim=128,            # éšè—å±‚ç»´åº¦ï¼ˆæ¨èï¼š64-256ï¼‰
    top_k=5,                  # Top-K é€‰æ‹©æ•°é‡ï¼ˆæ¨èï¼š3-10ï¼‰
    device='cuda'              # è®¡ç®—è®¾å¤‡
)

# è°ƒæ•´æƒé‡
controller.alpha = 1.0   # GNN é‡è¦æ€§æƒé‡
controller.beta = 5.0    # é¢„æµ‹å½±å“åŠ›æƒé‡
```

### å®‰å…¨å±éšœé…ç½®

```python
from safety_shield import DualModeSafetyShield, SafetyReward, ActionClipper

safety_shield = DualModeSafetyShield(
    ttc_threshold=2.0,              # TTC é˜ˆå€¼ï¼ˆç§’ï¼‰
    thw_threshold=1.5,              # THW é˜ˆå€¼ï¼ˆç§’ï¼‰
    emergency_deceleration=-4.5,     # ç´§æ€¥åˆ¶åŠ¨å‡é€Ÿåº¦
    max_acceleration=3.0,            # æœ€å¤§åŠ é€Ÿåº¦
    min_acceleration=-3.0            # æœ€å°åŠ é€Ÿåº¦
)

safety_reward = SafetyReward(
    emergency_penalty=-100.0,  # ç´§æ€¥åˆ¶åŠ¨æƒ©ç½š
    warning_penalty=-10.0,     # è­¦å‘Šæƒ©ç½š
    safe_reward=1.0            # å®‰å…¨å¥–åŠ±
)

action_clipper = ActionClipper(
    max_acceleration=3.0,      # æœ€å¤§åŠ é€Ÿåº¦
    min_acceleration=-3.0,      # æœ€å°åŠ é€Ÿåº¦
    max_speed=30.0,            # æœ€å¤§é€Ÿåº¦
    min_speed=0.0              # æœ€å°é€Ÿåº¦
)
```

### äº‹ä»¶è§¦å‘é…ç½®

```python
from event_triggered_controller import EventTriggeredController

event_controller = EventTriggeredController(
    control_interval=10.0,                     # æ§åˆ¶é—´éš”ï¼ˆç§’ï¼‰
    emergency_ttc_threshold=1.5,              # ç´§æ€¥ TTC é˜ˆå€¼
    high_risk_ttc_threshold=2.0,              # é«˜é£é™© TTC é˜ˆå€¼
    congestion_speed_threshold=5.0,           # æ‹¥å µé€Ÿåº¦é˜ˆå€¼ï¼ˆm/sï¼‰
    congestion_ratio_threshold=0.6            # æ‹¥å µæ¯”ä¾‹é˜ˆå€¼
)
```

---

## è®­ç»ƒæŒ‡å—

### ä¸‰é˜¶æ®µè®­ç»ƒç­–ç•¥

#### Phase 1: åŸºç¡€åŠ¨åŠ›å­¦å­¦ä¹ ï¼ˆ50 epochsï¼‰

```python
from progressive_world_model import ProgressiveWorldModel

model = ProgressiveWorldModel(state_dim=9, hidden_dim=256)
model.set_phase(phase=1)

# è®­ç»ƒå¾ªç¯
for epoch in range(50):
    # å‰å‘ä¼ æ’­
    predictions = model(state_tensor)
    
    # è®¡ç®— MSE æŸå¤±
    loss = nn.MSELoss()(predictions['next_states'], next_states)
    
    # åå‘ä¼ æ’­
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
```

#### Phase 2: æµæ¼”åŒ–ä¸é£é™©æ¼”åŒ–ï¼ˆ200 epochsï¼‰

```python
model.set_phase(phase=2)

# å†»ç»“ç‰¹å¾æå–å™¨
for param in model.feature_extractor.parameters():
    param.requires_grad = False

# è®­ç»ƒå¾ªç¯
for epoch in range(200):
    # å‰å‘ä¼ æ’­
    predictions = model(state_tensor)
    
    # è®¡ç®—è”åˆæŸå¤±
    mse_loss = nn.MSELoss()(predictions['next_states'], next_states)
    bce_loss = nn.BCELoss()(predictions['conflict_probability'], conflict_labels)
    loss = mse_loss + 0.5 * bce_loss
    
    # åå‘ä¼ æ’­
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
```

#### Phase 3: ç­–ç•¥è®­ç»ƒï¼ˆ100 epochsï¼‰

```python
from v4_integration import V4CompleteIntegration

integration = V4CompleteIntegration(
    sumo_cfg_path='ä»¿çœŸç¯å¢ƒ-åˆèµ›/sumo.sumocfg',
    device='cuda'
)

# è®­ç»ƒå¾ªç¯
for epoch in range(100):
    observation = integration.reset()
    episode_reward = 0.0
    
    for step in range(3600):
        observation, reward, done, info = integration.step()
        episode_reward += reward
        
        if done:
            break
    
    print(f"Epoch {epoch}: reward={episode_reward:.2f}")
```

### Ray RLlib åˆ†å¸ƒå¼è®­ç»ƒ

```python
from ray_rllib_integration import RayRLlibTrainer

trainer = RayRLlibTrainer(
    env_name="SUMORayEnvironment",
    num_workers=4,          # å·¥ä½œè¿›ç¨‹æ•°
    num_gpus=1,            # GPU æ•°é‡
    train_batch_size=4000,   # è®­ç»ƒæ‰¹æ¬¡å¤§å°
    gamma=0.99,             # æŠ˜æ‰£å› å­
    lr=3e-4                # å­¦ä¹ ç‡
)

# è®­ç»ƒ
for epoch in range(100):
    result = trainer.train()
    print(f"Epoch {epoch}: reward={result['episode_reward_mean']}")
    
    # ä¿å­˜æ£€æŸ¥ç‚¹
    if epoch % 10 == 0:
        trainer.save(f"checkpoint_{epoch}")
```

### è¶…å‚æ•°è°ƒä¼˜

#### æ¨èè¶…å‚æ•°èŒƒå›´

| å‚æ•° | æ¨èèŒƒå›´ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|---------|--------|------|
| gnn_hidden_dim | 128-512 | 256 | GNN éšè—å±‚ç»´åº¦ |
| gnn_num_heads | 4-8 | 4 | æ³¨æ„åŠ›å¤´æ•° |
| world_model_hidden_dim | 128-512 | 256 | ä¸–ç•Œæ¨¡å‹éšè—å±‚ç»´åº¦ |
| world_model_latent_dim | 32-128 | 64 | æ½œåœ¨ç»´åº¦ |
| controller_hidden_dim | 64-256 | 128 | æ§åˆ¶å™¨éšè—å±‚ç»´åº¦ |
| top_k | 3-10 | 5 | Top-K é€‰æ‹©æ•°é‡ |
| alpha | 0.5-2.0 | 1.0 | GNN é‡è¦æ€§æƒé‡ |
| beta | 1.0-10.0 | 5.0 | é¢„æµ‹å½±å“åŠ›æƒé‡ |
| control_interval | 5.0-20.0 | 10.0 | æ§åˆ¶é—´éš”ï¼ˆç§’ï¼‰ |
| ttc_threshold | 1.5-3.0 | 2.0 | TTC é˜ˆå€¼ï¼ˆç§’ï¼‰ |

---

## éƒ¨ç½²æŒ‡å—

### æ¨ç†æ¨¡å¼

```python
from v4_integration import V4CompleteIntegration

# åˆ›å»ºé›†æˆç³»ç»Ÿ
integration = V4CompleteIntegration(
    sumo_cfg_path='ä»¿çœŸç¯å¢ƒ-åˆèµ›/sumo.sumocfg',
    device='cuda'
)

# åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
integration.load_checkpoint('checkpoint_best.pth')

# é‡ç½®ç³»ç»Ÿ
observation = integration.reset()

# è¿è¡Œæ¨ç†
for step in range(3600):
    observation, reward, done, info = integration.step()
    
    if done:
        break

# è·å–ç»Ÿè®¡
stats = integration.get_statistics()
print(f"Total reward: {stats['total_reward']:.2f}")
```

### ä¿å­˜å’ŒåŠ è½½æ¨¡å‹

```python
# ä¿å­˜æ£€æŸ¥ç‚¹
integration.save_checkpoint('checkpoint_epoch_50.pth')

# åŠ è½½æ£€æŸ¥ç‚¹
integration.load_checkpoint('checkpoint_epoch_50.pth')
```

### æ€§èƒ½ç›‘æ§

```python
import time

start_time = time.time()

for step in range(1000):
    observation, reward, done, info = integration.step()
    
    # æ‰“å°æ€§èƒ½æŒ‡æ ‡
    if step % 100 == 0:
        print(f"Step {step}:")
        print(f"  Reward: {reward:.4f}")
        print(f"  Processing time: {info['processing_time']:.4f}s")
        print(f"  Safety interventions: {info['safety_interventions']}")
        print(f"  Control updates: {info['control_updates']}")

total_time = time.time() - start_time
print(f"Average time per step: {total_time / 1000:.4f}s")
```

---

## API å‚è€ƒ

### V4CompleteIntegration

#### åˆå§‹åŒ–

```python
V4CompleteIntegration(
    sumo_cfg_path: str,
    device: str = 'cuda',
    gnn_hidden_dim: int = 256,
    gnn_num_heads: int = 4,
    world_model_hidden_dim: int = 256,
    top_k: int = 5,
    icv_penetration: float = 0.25,
    control_interval: float = 10.0,
    use_gui: bool = False,
    max_steps: int = 3600
)
```

#### æ–¹æ³•

##### reset()

é‡ç½®é›†æˆç³»ç»Ÿã€‚

**è¿”å›å€¼**: `Dict[str, Any]` - åˆå§‹è§‚æµ‹

##### step()

æ‰§è¡Œä¸€æ­¥å®Œæ•´çš„é›†æˆæµç¨‹ã€‚

**è¿”å›å€¼**: `Tuple[Dict[str, Any], float, bool, Dict[str, Any]]`
- `observation`: è§‚æµ‹
- `reward`: å¥–åŠ±
- `done`: æ˜¯å¦ç»“æŸ
- `info`: é¢å¤–ä¿¡æ¯

##### get_statistics()

è·å–ç»Ÿè®¡ä¿¡æ¯ã€‚

**è¿”å›å€¼**: `Dict[str, Any]` - ç»Ÿè®¡ä¿¡æ¯å­—å…¸

##### save_checkpoint(path: str)

ä¿å­˜æ£€æŸ¥ç‚¹ã€‚

##### load_checkpoint(path: str)

åŠ è½½æ£€æŸ¥ç‚¹ã€‚

##### close()

å…³é—­é›†æˆç³»ç»Ÿã€‚

### SUMORLEnvironmentOptimized

#### åˆå§‹åŒ–

```python
SUMORLEnvironmentOptimized(
    sumo_cfg_path: str,
    use_gui: bool = False,
    max_steps: int = 3600,
    seed: Optional[int] = None,
    use_subscription: bool = True
)
```

#### æ–¹æ³•

##### reset()

é‡ç½®ç¯å¢ƒã€‚

**è¿”å›å€¼**: `Dict[str, Any]` - åˆå§‹è§‚æµ‹

##### step(action: Dict[str, Any])

æ‰§è¡Œä¸€æ­¥ä»¿çœŸã€‚

**è¿”å›å€¼**: `Tuple[Dict[str, Any], float, bool, Dict[str, Any]]`

##### close()

å…³é—­ç¯å¢ƒã€‚

##### get_performance_stats()

è·å–æ€§èƒ½ç»Ÿè®¡ã€‚

**è¿”å›å€¼**: `Dict[str, Any]` - æ€§èƒ½ç»Ÿè®¡

---

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. SUMO å¯åŠ¨å¤±è´¥

**é”™è¯¯ä¿¡æ¯**: `TraCIException: Could not start SUMO`

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥ SUMO æ˜¯å¦æ­£ç¡®å®‰è£…
sumo --version

# è®¾ç½® SUMO_HOME ç¯å¢ƒå˜é‡
export SUMO_HOME=/usr/share/sumo
export PATH=$PATH:$SUMO_HOME/bin

# æ£€æŸ¥é…ç½®æ–‡ä»¶è·¯å¾„
python -c "import os; print(os.path.exists('ä»¿çœŸç¯å¢ƒ-åˆèµ›/sumo.sumocfg'))"
```

#### 2. CUDA å†…å­˜ä¸è¶³

**é”™è¯¯ä¿¡æ¯**: `RuntimeError: CUDA out of memory`

**è§£å†³æ–¹æ¡ˆ**:
```python
# å‡å°æ‰¹æ¬¡å¤§å°
batch_size = 64  # ä» 256 å‡å°åˆ° 64

# å‡å°éšè—å±‚ç»´åº¦
hidden_dim = 128  # ä» 256 å‡å°åˆ° 128

# ä½¿ç”¨ CPU
device = 'cpu'
```

#### 3. TraCI è®¢é˜…å¤±è´¥

**é”™è¯¯ä¿¡æ¯**: `TraCIException: Object is not subscribed`

**è§£å†³æ–¹æ¡ˆ**:
```python
# ç¡®ä¿åœ¨è·å–æ•°æ®å‰è®¢é˜…è½¦è¾†
subscription_manager.subscribe_vehicle(veh_id)

# æˆ–è€…ç¦ç”¨è®¢é˜…ä¼˜åŒ–
env = SUMORLEnvironmentOptimized(
    sumo_cfg_path='...',
    use_subscription=False
)
```

#### 4. è®­ç»ƒä¸æ”¶æ•›

**è§£å†³æ–¹æ¡ˆ**:
```python
# è°ƒæ•´å­¦ä¹ ç‡
lr = 1e-4  # ä» 3e-4 é™ä½åˆ° 1e-4

# å¢åŠ è®­ç»ƒè½®æ•°
epochs = 300  # ä» 100 å¢åŠ åˆ° 300

# è°ƒæ•´å¥–åŠ±å‡½æ•°
reward = speed * 0.2 - speed_std * 0.3  # å¢åŠ é€Ÿåº¦æƒé‡

# ä½¿ç”¨æ¢¯åº¦è£å‰ª
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
```

### è°ƒè¯•æŠ€å·§

#### å¯ç”¨è¯¦ç»†æ—¥å¿—

```python
import logging

logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

logger.debug("Debug message")
logger.info("Info message")
logger.warning("Warning message")
logger.error("Error message")
```

#### å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹

```python
import matplotlib.pyplot as plt

# ç»˜åˆ¶å¥–åŠ±æ›²çº¿
plt.plot(rewards)
plt.xlabel('Episode')
plt.ylabel('Reward')
plt.title('Training Progress')
plt.show()
```

#### æ€§èƒ½åˆ†æ

```python
import cProfile
import pstats

profiler = cProfile.Profile()
profiler.enable()

# è¿è¡Œä»£ç 
integration.step()

profiler.disable()
stats = pstats.Stats(profiler)
stats.sort_stats('cumtime')
stats.print_stats(10)
```

---

## æ€§èƒ½ä¼˜åŒ–

### TraCI è®¢é˜…ä¼˜åŒ–

ä½¿ç”¨ TraCI è®¢é˜…æœºåˆ¶å¯ä»¥æ˜¾è‘—æå‡æ€§èƒ½ï¼š

```python
# å¯ç”¨è®¢é˜…ä¼˜åŒ–
env = SUMORLEnvironmentOptimized(
    sumo_cfg_path='...',
    use_subscription=True
)

# æ€§èƒ½å¯¹æ¯”
# ä¸ä½¿ç”¨è®¢é˜…: ~100ms/step
# ä½¿ç”¨è®¢é˜…: ~10ms/step
# åŠ é€Ÿæ¯”: 10x
```

### GPU åŠ é€Ÿ

ä½¿ç”¨ GPU å¯ä»¥åŠ é€Ÿç¥ç»ç½‘ç»œè®¡ç®—ï¼š

```python
# ä½¿ç”¨ GPU
device = 'cuda' if torch.cuda.is_available() else 'cpu'

# æ‰¹é‡è®¡ç®—
with torch.no_grad():
    embeddings = gnn(node_features, edge_indices, edge_features)
```

### åˆ†å¸ƒå¼è®­ç»ƒ

ä½¿ç”¨ Ray RLlib å¯ä»¥å¹¶è¡Œè¿è¡Œå¤šä¸ª SUMO å®ä¾‹ï¼š

```python
trainer = RayRLlibTrainer(
    env_name="SUMORayEnvironment",
    num_workers=8,  # 8 ä¸ªå¹¶è¡Œå·¥ä½œè¿›ç¨‹
    num_gpus=2      # 2 ä¸ª GPU
)

# åŠ é€Ÿæ¯”: ~8x
```

### ç¼“å­˜ä¼˜åŒ–

ä½¿ç”¨ GNN ç¼“å­˜å¯ä»¥å‡å°‘é‡å¤è®¡ç®—ï¼š

```python
# ç¼“å­˜è¶…æ—¶æ—¶é—´
gnn_cache_timeout = 10  # æ­¥æ•°

# ç¼“å­˜å‘½ä¸­ç‡
cache_hits = 85%  # 85% çš„è¯·æ±‚å‘½ä¸­ç¼“å­˜
```

---

## é™„å½•

### æ–‡ä»¶ç»“æ„

```
TJ_transport_v3/
â”œâ”€â”€ risk_sensitive_gnn.py          # æ„ŸçŸ¥å±‚ - Risk-Sensitive GNN
â”œâ”€â”€ progressive_world_model.py     # é¢„æµ‹å±‚ - Progressive World Model
â”œâ”€â”€ influence_controller.py        # å†³ç­–å±‚ - Influence-Driven Controller
â”œâ”€â”€ safety_shield.py              # å®‰å…¨çº¦æŸ - Dual-Mode Safety Shield
â”œâ”€â”€ event_triggered_controller.py  # äº‹ä»¶è§¦å‘æœºåˆ¶
â”œâ”€â”€ ray_rllib_integration.py      # Ray RLlib é›†æˆ
â”œâ”€â”€ sumo_rl_env_optimized.py     # TraCI è®¢é˜…ä¼˜åŒ–ç¯å¢ƒ
â”œâ”€â”€ v4_integration.py            # v4.0 å®Œæ•´é›†æˆä¸»ç±»
â”œâ”€â”€ train.py                     # è®­ç»ƒè„šæœ¬
â”œâ”€â”€ train_sumo_rl.py            # SUMO RL è®­ç»ƒ
â”œâ”€â”€ config.json                 # é…ç½®æ–‡ä»¶
â”œâ”€â”€ requirements.txt            # ä¾èµ–åˆ—è¡¨
â”œâ”€â”€ V4_ä½¿ç”¨æŒ‡å—.md             # æœ¬æ–‡æ¡£
â””â”€â”€ ä»¿çœŸç¯å¢ƒ-åˆèµ›/
    â”œâ”€â”€ main.py                 # SUMO ç«èµ›æ¡†æ¶
    â”œâ”€â”€ net.xml                 # è·¯ç½‘é…ç½®
    â”œâ”€â”€ routes.xml              # è·¯å¾„é…ç½®
    â”œâ”€â”€ sumo.sumocfg           # SUMO é…ç½®
    â””â”€â”€ readme.md              # æ¡†æ¶è¯´æ˜
```

### ä¾èµ–ç‰ˆæœ¬

```
torch>=1.10.0
numpy>=1.21.0
pandas>=1.3.0
traci>=1.24.0
ray[rllib]>=2.0.0
gymnasium>=0.26.0
matplotlib>=3.4.0
```

### å¼•ç”¨

å¦‚æœæ‚¨åœ¨ç ”ç©¶ä¸­ä½¿ç”¨äº†æœ¬ç³»ç»Ÿï¼Œè¯·å¼•ç”¨ï¼š

```bibtex
@software{tj_transport_v4,
  title={v4.0 Intelligent Traffic Cooperative Control System},
  author={Your Name},
  year={2025},
  url={https://github.com/yourusername/TJ_transport_v3}
}
```

---

## è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»ï¼š

- GitHub Issues: [https://github.com/yourusername/TJ_transport_v3/issues](https://github.com/yourusername/TJ_transport_v3/issues)
- Email: your.email@example.com

---

**ç¥æ‚¨ä½¿ç”¨æ„‰å¿«ï¼** ğŸš¦ğŸš—ğŸ†

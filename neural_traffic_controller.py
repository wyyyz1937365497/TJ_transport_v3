import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import traci
from typing import Dict, List, Tuple, Any, Optional
import os
import json
import time
from torch_geometric.nn import GATConv
from torch_geometric.data import Data


class RiskSensitiveGNN(nn.Module):
    """
    é£é™©æ•æ„Ÿå›¾ç¥ç»ç½‘ç»œ
    è¾“å…¥ï¼šè½¦è¾†èŠ‚ç‚¹ç‰¹å¾(9ç»´) + äº¤äº’è¾¹ç‰¹å¾(4ç»´)
    è¾“å‡ºï¼š256ç»´å…¨å±€åµŒå…¥
    """

    def __init__(self, node_dim: int = 9, edge_dim: int = 4, hidden_dim: int = 64,
                 output_dim: int = 256, num_layers: int = 3, heads: int = 4):
        super().__init__()

        # 1. èŠ‚ç‚¹ç‰¹å¾ç¼–ç å™¨
        self.node_encoder = nn.Sequential(
            nn.Linear(node_dim, 32),
            nn.ReLU(),
            nn.Linear(32, hidden_dim),
            nn.LayerNorm(hidden_dim)
        )

        # 2. è¾¹ç‰¹å¾ç¼–ç å™¨
        self.edge_encoder = nn.Sequential(
            nn.Linear(edge_dim, 16),
            nn.ReLU(),
            nn.Linear(16, hidden_dim // 2),
            nn.LayerNorm(hidden_dim // 2)
        )

        # 3. é£é™©æ³¨æ„åŠ›æœºåˆ¶
        self.risk_attention = nn.Sequential(
            nn.Linear(hidden_dim + hidden_dim // 2, hidden_dim),
            nn.Tanh(),
            nn.Linear(hidden_dim, 1),
            nn.Sigmoid()
        )

        # 4. GNNå±‚ - æ”¹è¿›ç‰ˆï¼ˆå¸¦æ®‹å·®è¿æ¥å’Œå±‚å½’ä¸€åŒ–ï¼‰
        self.gnn_layers = nn.ModuleList()
        self.norm_layers = nn.ModuleList()
        
        for i in range(num_layers):
            self.gnn_layers.append(
                GATConv(
                    in_channels=hidden_dim,
                    out_channels=hidden_dim,
                    heads=heads,
                    concat=False,
                    edge_dim=hidden_dim // 2,
                    dropout=0.1
                )
            )
            self.norm_layers.append(nn.LayerNorm(hidden_dim))

        # 5. è¾“å‡ºæŠ•å½±å±‚
        self.output_layer = nn.Sequential(
            nn.Linear(hidden_dim, 128),
            nn.ReLU(),
            nn.Linear(128, output_dim),
            nn.LayerNorm(output_dim)
        )

        # åˆå§‹åŒ–æƒé‡
        self._init_weights()

    def _init_weights(self):
        """æƒé‡åˆå§‹åŒ–"""
        for m in self.modules():
            if isinstance(m, (nn.Linear, nn.Conv1d)):
                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)

    def forward(self, graph: Data) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­
        Args:
            graph: åŒ…å«x, edge_index, edge_attrçš„PyGæ•°æ®å¯¹è±¡
        Returns:
            global_embedding: [N, 256] å…¨å±€åµŒå…¥
        """
        # 1. ç¼–ç èŠ‚ç‚¹å’Œè¾¹ç‰¹å¾
        node_features = self.node_encoder(graph.x)  # [N, 64]
        edge_features = self.edge_encoder(graph.edge_attr)  # [E, 32]

        # 2. è®¡ç®—é£é™©æ³¨æ„åŠ›æƒé‡
        if edge_features.size(0) > 0:
            src_nodes = graph.edge_index[0]
            risk_input = torch.cat([
                node_features[src_nodes],
                edge_features
            ], dim=1)  # [E, 96]
            risk_weights = self.risk_attention(risk_input)  # [E, 1]
        else:
            risk_weights = None

        # 3. GNNä¼ æ’­ - æ”¹è¿›ç‰ˆï¼ˆæ®‹å·®è¿æ¥ï¼‰
        x = node_features
        for i, (layer, norm) in enumerate(zip(self.gnn_layers, self.norm_layers)):
            residual = x
            x = layer(x, graph.edge_index, edge_attr=edge_features)
            x = F.relu(x)
            x = norm(x + residual)  # æ®‹å·®è¿æ¥ + å±‚å½’ä¸€åŒ–

        # 4. è¾“å‡ºæŠ•å½±
        global_embedding = self.output_layer(x)  # [N, 256]

        return global_embedding


class ProgressiveWorldModel(nn.Module):
    """
    æ¸è¿›å¼ä¸–ç•Œæ¨¡å‹
    é˜¶æ®µ1ï¼šé¢„æµ‹ä¸‹ä¸€æ—¶åˆ»çŠ¶æ€
    é˜¶æ®µ2ï¼šé¢„æµ‹æœªæ¥5æ­¥çŠ¶æ€ + å†²çªæ¦‚ç‡
    """

    def __init__(self, input_dim: int = 256, hidden_dim: int = 128,
                 future_steps: int = 5, num_phases: int = 2):
        super().__init__()

        self.future_steps = future_steps
        self.num_phases = num_phases
        self.current_phase = 1

        # 1. å…±äº«ç¼–ç å™¨
        self.shared_encoder = nn.Sequential(
            nn.Linear(input_dim, 192),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(192, hidden_dim),
            nn.LayerNorm(hidden_dim)
        )

        # 2. åŸºç¡€åŠ¨åŠ›å­¦åˆ†æ”¯ (Phase 1)
        self.dynamics_lstm = nn.LSTM(
            input_size=hidden_dim,
            hidden_size=hidden_dim,
            num_layers=2,
            batch_first=True,
            dropout=0.1
        )

        # 3. é£é™©æ¼”åŒ–åˆ†æ”¯ (Phase 2)
        self.risk_decoders = nn.ModuleList([
            nn.Sequential(
                nn.Linear(hidden_dim, 192),
                nn.ReLU(),
                nn.Dropout(0.1),
                nn.Linear(192, input_dim + 1)  # çŠ¶æ€ + å†²çªæ¦‚ç‡
            ) for _ in range(future_steps)
        ])

        # 4. è¾…åŠ©åˆ†ç±»å™¨
        self.conflict_classifier = nn.Sequential(
            nn.Linear(input_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 1),
            nn.Sigmoid()
        )

        # åˆå§‹åŒ–æƒé‡
        self._init_weights()

    def _init_weights(self):
        """æƒé‡åˆå§‹åŒ–"""
        for m in self.modules():
            if isinstance(m, (nn.Linear, nn.LSTM)):
                if hasattr(m, 'weight') and m.weight is not None and isinstance(m.weight, torch.Tensor):
                    nn.init.kaiming_normal_(m.weight, nonlinearity='relu')
                if hasattr(m, 'bias') and m.bias is not None and isinstance(m.bias, torch.Tensor):
                    nn.init.constant_(m.bias, 0)

    def set_phase(self, phase: int):
        """è®¾ç½®è®­ç»ƒé˜¶æ®µ"""
        self.current_phase = phase
        print(f"ğŸ”„ ä¸–ç•Œæ¨¡å‹åˆ‡æ¢åˆ°é˜¶æ®µ {phase}")

    def forward(self, gnn_embedding: torch.Tensor) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­
        Args:
            gnn_embedding: [N, 256] GNNè¾“å‡ºåµŒå…¥
        Returns:
            predictions: 
                Phase 1: [N, 256] ä¸‹ä¸€æ—¶åˆ»çŠ¶æ€
                Phase 2: [N, 5, 257] æœªæ¥5æ­¥çŠ¶æ€ + å†²çªæ¦‚ç‡
        """
        batch_size = gnn_embedding.size(0)

        # 1. å…±äº«ç¼–ç 
        encoded = self.shared_encoder(gnn_embedding)  # [N, 128]

        if self.current_phase == 1:
            # Phase 1: åŸºç¡€åŠ¨åŠ›å­¦é¢„æµ‹
            # é‡å¡‘ä¸ºLSTMè¾“å…¥æ ¼å¼ [N, 1, 128]
            lstm_input = encoded.unsqueeze(1)

            # LSTMé¢„æµ‹
            lstm_output, _ = self.dynamics_lstm(lstm_input)  # [N, 1, 128]

            # é¢„æµ‹ä¸‹ä¸€æ—¶åˆ»çŠ¶æ€
            next_state = self.risk_decoders[0](lstm_output.squeeze(1))[:, :-1]  # [N, 256]

            return next_state

        else:
            # Phase 2: é£é™©æ¼”åŒ–é¢„æµ‹
            predictions = []

            # ä¸ºæ¯ä¸ªæœªæ¥æ­¥ç”Ÿæˆé¢„æµ‹
            for t in range(self.future_steps):
                # ä½¿ç”¨ç›¸åŒçš„ç¼–ç ä½†æ·»åŠ æ—¶é—´æ­¥ä¿¡æ¯
                time_input = encoded + 0.1 * t * torch.ones_like(encoded)
                pred = self.risk_decoders[t](time_input)  # [N, 257]
                predictions.append(pred.unsqueeze(1))

            # åˆå¹¶é¢„æµ‹ [N, 5, 257]
            predictions = torch.cat(predictions, dim=1)

            return predictions


class InfluenceDrivenController(nn.Module):
    """
    å½±å“åŠ›é©±åŠ¨æ§åˆ¶å™¨
    1. è®¡ç®—æ¯è¾†è½¦çš„å½±å“åŠ›å¾—åˆ†
    2. é€‰æ‹©Top-Kæœ€å…·å½±å“åŠ›çš„ICVè½¦è¾†
    3. ä¸ºé€‰ä¸­çš„è½¦è¾†ç”Ÿæˆæ§åˆ¶åŠ¨ä½œ
    """

    def __init__(self, gnn_dim: int = 256, world_dim: int = 256, global_dim: int = 16,
                 hidden_dim: int = 128, action_dim: int = 2, top_k: int = 5):
        super().__init__()

        self.top_k = top_k
        self.action_dim = action_dim

        # 1. å…¨å±€ä¸Šä¸‹æ–‡ç¼–ç å™¨
        self.global_encoder = nn.Sequential(
            nn.Linear(global_dim, 32),
            nn.ReLU(),
            nn.Linear(32, 64),
            nn.LayerNorm(64)
        )

        # 2. ç‰¹å¾èåˆå±‚
        self.fusion_layer = nn.Sequential(
            nn.Linear(gnn_dim + 64 + 257, 384),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(384, hidden_dim),
            nn.LayerNorm(hidden_dim)
        )

        # 3. å½±å“åŠ›è¯„åˆ†ç½‘ç»œ
        self.influence_scorer = nn.Sequential(
            nn.Linear(hidden_dim, 64),
            nn.ReLU(),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 1),
            nn.Sigmoid()
        )

        # 4. åŠ¨ä½œç”Ÿæˆç½‘ç»œ
        self.action_generator = nn.ModuleDict({
            'acceleration': nn.Sequential(
                nn.Linear(hidden_dim, 64),
                nn.ReLU(),
                nn.Linear(64, 32),
                nn.ReLU(),
                nn.Linear(32, 1),
                nn.Tanh()  # è¾“å‡ºèŒƒå›´[-1, 1]
            ),
            'lane_change': nn.Sequential(
                nn.Linear(hidden_dim, 32),
                nn.ReLU(),
                nn.Linear(32, 16),
                nn.ReLU(),
                nn.Linear(16, 1),
                nn.Sigmoid()  # è¾“å‡ºæ¦‚ç‡[0, 1]
            )
        })

        # 5. ä»·å€¼ç½‘ç»œ
        self.value_network = nn.Sequential(
            nn.Linear(hidden_dim, 64),
            nn.ReLU(),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 1)
        )

        # åˆå§‹åŒ–æƒé‡
        self._init_weights()

    def _init_weights(self):
        """æƒé‡åˆå§‹åŒ–"""
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_normal_(m.weight)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0.1)

    def forward(self, gnn_embedding: torch.Tensor, world_predictions: torch.Tensor,
                global_metrics: torch.Tensor, vehicle_ids: List[str],
                is_icv: torch.Tensor) -> Dict[str, Any]:
        """
        å‰å‘ä¼ æ’­
        Args:
            gnn_embedding: [N, 256] GNNåµŒå…¥
            world_predictions: [N, 5, 257] ä¸–ç•Œæ¨¡å‹é¢„æµ‹
            global_metrics: [B, 16] å…¨å±€äº¤é€šæŒ‡æ ‡
            vehicle_ids: [N] è½¦è¾†IDåˆ—è¡¨
            is_icv: [N] æ˜¯å¦ä¸ºæ™ºèƒ½ç½‘è”è½¦
        Returns:
            åŒ…å«é€‰ä¸­è½¦è¾†IDã€æ§åˆ¶åŠ¨ä½œç­‰çš„å­—å…¸
        """
        batch_size = gnn_embedding.size(0)

        # 1. å¤„ç†å…¨å±€ç‰¹å¾
        global_features = self.global_encoder(global_metrics)  # [B, 64]

        # 2. èåˆç‰¹å¾
        # å¤„ç†world_predictionsçš„ä¸åŒç»´åº¦
        if world_predictions.dim() == 3:
            # Phase 2: [N, 5, 257] -> å–å¹³å‡å¾—åˆ° [N, 257]
            avg_world_pred = world_predictions.mean(dim=1)
        elif world_predictions.dim() == 2:
            # Phase 1: [N, 256] -> éœ€è¦paddingåˆ°257ç»´
            avg_world_pred = torch.cat([
                world_predictions,
                torch.zeros(batch_size, 1, device=world_predictions.device)
            ], dim=1)
        else:
            avg_world_pred = world_predictions

        # é‡å¤å…¨å±€ç‰¹å¾ä»¥åŒ¹é…æ‰¹æ¬¡å¤§å°
        global_features_expanded = global_features.repeat(batch_size, 1)

        # èåˆ
        fused_input = torch.cat([
            gnn_embedding,
            global_features_expanded,
            avg_world_pred
        ], dim=1)  # [N, 256+64+257] = [N, 577]

        fused_features = self.fusion_layer(fused_input)  # [N, 128]

        # 3. è®¡ç®—ICVè½¦è¾†çš„å½±å“åŠ›å¾—åˆ†
        icv_mask = is_icv.bool()
        icv_indices = torch.where(icv_mask)[0]

        if len(icv_indices) == 0:
            return {
                'selected_vehicle_ids': [],
                'selected_indices': [],
                'raw_actions': torch.zeros(0, self.action_dim),
                'influence_scores': torch.zeros(0),
                'value_estimates': torch.zeros(0)
            }

        icv_features = fused_features[icv_mask]  # [N_icv, 128]
        influence_scores = self.influence_scorer(icv_features).squeeze(-1)  # [N_icv]

        # 4. é€‰æ‹©Top-Kè½¦è¾†
        k = min(self.top_k, len(icv_indices))
        top_k_scores, top_k_indices = torch.topk(influence_scores, k, largest=True, sorted=True)

        selected_indices = icv_indices[top_k_indices.cpu()]  # [K]
        selected_vehicle_ids = [vehicle_ids[i] for i in selected_indices.cpu().numpy()]

        # 5. ä¸ºé€‰ä¸­è½¦è¾†ç”ŸæˆåŠ¨ä½œ
        selected_features = fused_features[selected_indices]  # [K, 128]

        # ç”ŸæˆåŠ é€Ÿåº¦åŠ¨ä½œ
        accel_actions = self.action_generator['acceleration'](selected_features)  # [K, 1]

        # ç”Ÿæˆæ¢é“æ¦‚ç‡
        lane_actions = self.action_generator['lane_change'](selected_features)  # [K, 1]

        # ç»„åˆåŠ¨ä½œ
        raw_actions = torch.cat([accel_actions, lane_actions], dim=1)  # [K, 2]

        # 6. ä»·å€¼ä¼°è®¡
        value_estimates = self.value_network(fused_features).squeeze(-1)  # [N]

        return {
            'selected_vehicle_ids': selected_vehicle_ids,
            'selected_indices': selected_indices.cpu().numpy().tolist(),
            'raw_actions': raw_actions,
            'influence_scores': influence_scores,
            'value_estimates': value_estimates,
            'top_k_scores': top_k_scores
        }


class DualModeSafetyShield(nn.Module):
    """
    åŒæ¨¡æ€å®‰å…¨å±éšœ
    Level 1: åŠ¨ä½œè£å‰ªï¼ˆè½¯çº¦æŸï¼‰
    Level 2: ç´§æ€¥åˆ¶åŠ¨ï¼ˆç¡¬çº¦æŸï¼‰
    """

    def __init__(self, ttc_threshold: float = 2.0, thw_threshold: float = 1.5,
                 max_accel: float = 2.0, max_decel: float = -3.0,
                 emergency_decel: float = -5.0, max_lane_change_speed: float = 5.0):
        super().__init__()

        self.ttc_threshold = ttc_threshold
        self.thw_threshold = thw_threshold
        self.max_accel = max_accel
        self.max_decel = max_decel
        self.emergency_decel = emergency_decel
        self.max_lane_change_speed = max_lane_change_speed

        # å®‰å…¨å‚æ•°ï¼ˆå¯å­¦ä¹ ï¼‰
        self.register_parameter('learnable_max_accel', nn.Parameter(torch.tensor(max_accel)))
        self.register_parameter('learnable_max_decel', nn.Parameter(torch.tensor(max_decel)))
        self.register_parameter('learnable_emergency_decel', nn.Parameter(torch.tensor(emergency_decel)))

    def forward(self, raw_actions: torch.Tensor, vehicle_states: Dict[str, Any],
                selected_vehicle_indices: List[int]) -> Dict[str, Any]:
        """
        å®‰å…¨å±éšœå‰å‘ä¼ æ’­
        Args:
            raw_actions: [K, 2] åŸå§‹æ§åˆ¶åŠ¨ä½œï¼ˆåŠ é€Ÿåº¦ï¼Œæ¢é“æ¦‚ç‡ï¼‰
            vehicle_states: è½¦è¾†çŠ¶æ€å­—å…¸
            selected_vehicle_indices: é€‰ä¸­è½¦è¾†ç´¢å¼•åˆ—è¡¨
        Returns:
            å®‰å…¨åŒ–åçš„åŠ¨ä½œå’Œå¹²é¢„ç»Ÿè®¡
        """
        if len(selected_vehicle_indices) == 0:
            return {
                'safe_actions': torch.zeros(0, 2),
                'level1_interventions': 0,
                'level2_interventions': 0
            }

        # Level 1: åŠ¨ä½œè£å‰ª
        level1_actions, level1_interventions = self._level1_clipping(
            raw_actions, vehicle_states, selected_vehicle_indices
        )

        # Level 2: ç´§æ€¥å®‰å…¨æ£€æŸ¥
        level2_actions, level2_interventions = self._level2_emergency_check(
            level1_actions, vehicle_states, selected_vehicle_indices
        )

        total_level1 = torch.sum(level1_interventions).item()
        total_level2 = torch.sum(level2_interventions).item()

        return {
            'safe_actions': level2_actions,
            'level1_interventions': total_level1,
            'level2_interventions': total_level2
        }

    def _level1_clipping(self, raw_actions: torch.Tensor, vehicle_states: Dict[str, Any],
                         selected_indices: List[int]) -> Tuple[torch.Tensor, torch.Tensor]:
        """Level 1: åŸºç¡€åŠ¨ä½œè£å‰ª"""
        k = len(selected_indices)
        safe_actions = raw_actions.clone()
        intervention_mask = torch.zeros(k, dtype=torch.bool)

        for i, idx in enumerate(selected_indices):
            veh_id = vehicle_states['ids'][idx]

            if veh_id not in vehicle_states['data']:
                continue

            vehicle = vehicle_states['data'][veh_id]
            current_speed = vehicle['speed']

            # 1. åŠ é€Ÿåº¦è£å‰ª
            raw_accel = raw_actions[i, 0].item()

            # åŠ¨æ€è°ƒæ•´åŠ é€Ÿåº¦é™åˆ¶ï¼ˆåŸºäºé€Ÿåº¦ï¼‰
            dynamic_max_accel = self.max_accel * (1 - current_speed / 30.0)  # é«˜é€Ÿæ—¶å‡å°åŠ é€Ÿåº¦
            dynamic_max_decel = self.max_decel * (1 + current_speed / 30.0)  # é«˜é€Ÿæ—¶å¢å¤§å‡é€Ÿåº¦

            safe_accel = max(min(raw_accel, dynamic_max_accel), dynamic_max_decel)

            if abs(safe_accel - raw_accel) > 0.1:  # å¹²é¢„é˜ˆå€¼
                intervention_mask[i] = True

            # 2. æ¢é“é™åˆ¶
            raw_lane_change = raw_actions[i, 1].item()
            safe_lane_change = raw_lane_change

            # ä»…åœ¨ä½é€Ÿæ—¶å…è®¸æ¢é“
            if current_speed > self.max_lane_change_speed:
                safe_lane_change = 0.0
                if raw_lane_change > 0.5:
                    intervention_mask[i] = True

            # æ›´æ–°å®‰å…¨åŠ¨ä½œ
            safe_actions[i, 0] = safe_accel
            safe_actions[i, 1] = safe_lane_change

        return safe_actions, intervention_mask

    def _level2_emergency_check(self, actions: torch.Tensor, vehicle_states: Dict[str, Any],
                                selected_indices: List[int]) -> Tuple[torch.Tensor, torch.Tensor]:
        """Level 2: ç´§æ€¥å®‰å…¨æ£€æŸ¥"""
        k = len(selected_indices)
        final_actions = actions.clone()
        emergency_mask = torch.zeros(k, dtype=torch.bool)

        for i, idx in enumerate(selected_indices):
            veh_id = vehicle_states['ids'][idx]

            if veh_id not in vehicle_states['data']:
                continue

            ego_vehicle = vehicle_states['data'][veh_id]
            leader_vehicle = self._find_leader(veh_id, ego_vehicle, vehicle_states['data'])

            if leader_vehicle:
                # è®¡ç®—TTCå’ŒTHW
                ttc = self._calculate_ttc(ego_vehicle, leader_vehicle)
                thw = self._calculate_thw(ego_vehicle, leader_vehicle)

                # æ£€æŸ¥ç´§æ€¥æ¡ä»¶
                if ttc < self.ttc_threshold or thw < self.thw_threshold:
                    # ç´§æ€¥åˆ¶åŠ¨
                    final_actions[i, 0] = self.emergency_decel
                    final_actions[i, 1] = 0.0  # å–æ¶ˆæ¢é“
                    emergency_mask[i] = True

        return final_actions, emergency_mask

    def _find_leader(self, ego_id: str, ego: Dict[str, Any], all_vehicles: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """æ‰¾åˆ°å‰è½¦"""
        min_distance = float('inf')
        leader = None

        for veh_id, vehicle in all_vehicles.items():
            if veh_id == ego_id:
                continue

            # æ£€æŸ¥æ˜¯å¦åœ¨åŒä¸€è½¦é“
            if vehicle['lane_id'] != ego['lane_id']:
                continue

            # æ£€æŸ¥æ˜¯å¦åœ¨å‰æ–¹
            if vehicle['position'] <= ego['position']:
                continue

            distance = vehicle['position'] - ego['position']
            if distance < min_distance:
                min_distance = distance
                leader = vehicle

        return leader if min_distance < 100 else None  # 100ç±³å†…

    def _calculate_ttc(self, ego: Dict[str, Any], leader: Dict[str, Any]) -> float:
        """è®¡ç®—ç¢°æ’æ—¶é—´TTC"""
        relative_speed = ego['speed'] - leader['speed']
        distance = leader['position'] - ego['position']

        if relative_speed <= 0:
            return float('inf')  # ä¸ä¼šç¢°æ’

        ttc = distance / relative_speed
        return max(0.1, ttc)  # é˜²æ­¢é™¤é›¶

    def _calculate_thw(self, ego: Dict[str, Any], leader: Dict[str, Any]) -> float:
        """è®¡ç®—è½¦å¤´æ—¶è·THW"""
        distance = leader['position'] - ego['position']
        if ego['speed'] <= 0:
            return float('inf')

        thw = distance / ego['speed']
        return max(0.1, thw)  # é˜²æ­¢é™¤é›¶


class TrafficController(nn.Module):
    """
    æ™ºèƒ½äº¤é€šååŒæ§åˆ¶ç¥ç»ç½‘ç»œ
    æ¶æ„ï¼šRisk-Sensitive GNN + Progressive World Model + Influence-Driven Controller + Dual-mode Safety Shield
    """

    def __init__(self, config: Dict[str, Any]):
        super().__init__()
        self.config = config

        # 1. æ„ŸçŸ¥å±‚ï¼šé£é™©æ•æ„ŸGNN
        self.risk_gnn = RiskSensitiveGNN(
            node_dim=config.get('node_dim', 9),
            edge_dim=config.get('edge_dim', 4),
            hidden_dim=config.get('gnn_hidden_dim', 64),
            output_dim=config.get('gnn_output_dim', 256),
            num_layers=config.get('gnn_layers', 3),
            heads=config.get('gnn_heads', 4)
        )

        # 2. é¢„æµ‹å±‚ï¼šæ¸è¿›å¼ä¸–ç•Œæ¨¡å‹
        self.world_model = ProgressiveWorldModel(
            input_dim=config.get('gnn_output_dim', 256),
            hidden_dim=config.get('world_hidden_dim', 128),
            future_steps=config.get('future_steps', 5),
            num_phases=2
        )

        # 3. å†³ç­–å±‚ï¼šå½±å“åŠ›é©±åŠ¨æ§åˆ¶å™¨
        self.controller = InfluenceDrivenController(
            gnn_dim=config.get('gnn_output_dim', 256),
            world_dim=config.get('gnn_output_dim', 256),
            global_dim=config.get('global_dim', 16),
            hidden_dim=config.get('controller_hidden_dim', 128),
            action_dim=config.get('action_dim', 2),
            top_k=config.get('top_k', 5)
        )

        # 4. å®‰å…¨å±‚ï¼šåŒæ¨¡æ€å®‰å…¨å±éšœ
        self.safety_shield = DualModeSafetyShield(
            ttc_threshold=config.get('ttc_threshold', 2.0),
            thw_threshold=config.get('thw_threshold', 1.5),
            max_accel=config.get('max_accel', 2.0),
            max_decel=config.get('max_decel', -3.0),
            emergency_decel=config.get('emergency_decel', -5.0),
            max_lane_change_speed=config.get('max_lane_change_speed', 5.0)
        )

        # 5. çº¦æŸä¼˜åŒ–å‚æ•°
        self.register_buffer('lagrange_multiplier', torch.tensor(1.0))
        self.cost_limit = config.get('cost_limit', 0.1)
        self.lambda_lr = config.get('lambda_lr', 0.01)

        # 6. ç¼“å­˜æœºåˆ¶
        self.gnn_cache = {}
        self.cache_timeout = config.get('cache_timeout', 10)  # ç¼“å­˜10æ­¥

        print("âœ… äº¤é€šæ§åˆ¶ç¥ç»ç½‘ç»œåˆå§‹åŒ–å®Œæˆ!")
        print(f"   - GNNç»´åº¦: {config.get('gnn_output_dim', 256)}")
        print(f"   - é¢„æµ‹æ­¥é•¿: {config.get('future_steps', 5)}")
        print(f"   - æ§åˆ¶è½¦è¾†æ•°: {config.get('top_k', 5)}")

    def forward(self, batch: Dict[str, Any], step: int) -> Dict[str, Any]:
        """
        å‰å‘ä¼ æ’­ï¼Œç”Ÿæˆæ§åˆ¶æŒ‡ä»¤
        """
        # 1. æ„ŸçŸ¥å±‚ï¼šGNNç‰¹å¾æå–
        gnn_embedding = self._get_gnn_embedding(batch, step)

        # 2. é¢„æµ‹å±‚ï¼šæœªæ¥çŠ¶æ€é¢„æµ‹
        world_predictions = self.world_model(gnn_embedding)

        # 3. å†³ç­–å±‚ï¼šå½±å“åŠ›è®¡ç®—ä¸åŠ¨ä½œç”Ÿæˆ
        controller_output = self.controller(
            gnn_embedding=gnn_embedding,
            world_predictions=world_predictions,
            global_metrics=batch['global_metrics'],
            vehicle_ids=batch['vehicle_ids'],
            is_icv=batch['is_icv']
        )

        # 4. å®‰å…¨å±‚ï¼šåŠ¨ä½œå®‰å…¨åŒ–
        safe_actions = self.safety_shield(
            raw_actions=controller_output['raw_actions'],
            vehicle_states=batch['vehicle_states'],
            selected_vehicle_indices=controller_output['selected_indices']
        )

        # 5. ç»„åˆè¾“å‡º
        output = {
            'selected_vehicle_ids': controller_output['selected_vehicle_ids'],
            'safe_actions': safe_actions,
            'influence_scores': controller_output['influence_scores'],
            'level1_interventions': safe_actions['level1_interventions'],
            'level2_interventions': safe_actions['level2_interventions'],
            'gnn_embedding': gnn_embedding,
            'world_predictions': world_predictions
        }

        return output

    def _get_gnn_embedding(self, batch: Dict[str, Any], step: int) -> torch.Tensor:
        """å¸¦ç¼“å­˜çš„GNNæ¨ç†"""
        # ç”Ÿæˆç¼“å­˜é”®
        cache_key = str(hash(str(batch['vehicle_ids']) + str(batch['edge_indices'].shape)))

        # æ£€æŸ¥ç¼“å­˜
        if cache_key in self.gnn_cache and step - self.gnn_cache[cache_key]['step'] < self.cache_timeout:
            return self.gnn_cache[cache_key]['embedding']

        # æ„å»ºå›¾æ•°æ®
        graph_data = self._build_graph(batch)

        # GNNæ¨ç†
        with torch.no_grad():
            gnn_embedding = self.risk_gnn(graph_data)

        # æ›´æ–°ç¼“å­˜
        self.gnn_cache[cache_key] = {
            'embedding': gnn_embedding,
            'step': step
        }

        return gnn_embedding

    def _build_graph(self, batch: Dict[str, Any]) -> Data:
        """æ„å»ºå›¾ç¥ç»ç½‘ç»œè¾“å…¥"""
        # èŠ‚ç‚¹ç‰¹å¾
        node_features = batch['node_features']  # [N, 9]

        # è¾¹ç´¢å¼•
        edge_index = batch['edge_indices']  # [2, E]

        # è¾¹ç‰¹å¾
        edge_features = batch['edge_features']  # [E, 4]

        # åˆ›å»ºPyGæ•°æ®å¯¹è±¡
        graph = Data(
            x=node_features,
            edge_index=edge_index,
            edge_attr=edge_features
        )

        return graph

    def update_lagrange_multiplier(self, mean_cost: float):
        """æ›´æ–°æ‹‰æ ¼æœ—æ—¥ä¹˜å­"""
        if mean_cost > self.cost_limit:
            self.lagrange_multiplier *= (1 + self.lambda_lr)
        else:
            self.lagrange_multiplier *= (1 - self.lambda_lr)

        # é™åˆ¶èŒƒå›´
        self.lagrange_multiplier = torch.clamp(self.lagrange_multiplier, 0.1, 10.0)

        return self.lagrange_multiplier.item()


class NeuralTrafficController:
    """
    ç¥ç»äº¤é€šæ§åˆ¶å™¨ï¼Œé›†æˆåˆ°SUMOç«èµ›æ¡†æ¶
    """

    def __init__(self, config_path: str = None):
        # é»˜è®¤é…ç½®
        self.config = {
            'node_dim': 9,
            'edge_dim': 4,
            'gnn_hidden_dim': 64,
            'gnn_output_dim': 256,
            'gnn_layers': 3,
            'gnn_heads': 4,
            'world_hidden_dim': 128,
            'future_steps': 5,
            'controller_hidden_dim': 128,
            'global_dim': 16,
            'top_k': 5,
            'ttc_threshold': 2.0,
            'thw_threshold': 1.5,
            'max_accel': 2.0,
            'max_decel': -3.0,
            'emergency_decel': -5.0,
            'max_lane_change_speed': 5.0,
            'cost_limit': 0.1,
            'lambda_lr': 0.01,
            'cache_timeout': 10,
            'device': 'cuda' if torch.cuda.is_available() else 'cpu',
            'model_path': None
        }

        # åŠ è½½é…ç½®æ–‡ä»¶
        if config_path and os.path.exists(config_path):
            with open(config_path, 'r') as f:
                config_data = json.load(f)
                self.config.update(config_data)

        # åˆå§‹åŒ–ç¥ç»ç½‘ç»œ
        self.device = torch.device(self.config['device'])
        self.model = TrafficController(self.config).to(self.device)

        # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        if self.config.get('model_path') and os.path.exists(self.config['model_path']):
            try:
                checkpoint = torch.load(self.config['model_path'], map_location=self.device)
                self.model.load_state_dict(checkpoint['model_state_dict'])
                print(f"âœ… åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: {self.config['model_path']}")
            except Exception as e:
                print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")

        # ç»Ÿè®¡ä¿¡æ¯
        self.total_interventions = 0
        self.total_emergency_interventions = 0
        self.total_controlled_vehicles = 0

        print(f"ğŸš€ ç¥ç»äº¤é€šæ§åˆ¶å™¨åˆå§‹åŒ–å®Œæˆ! è®¾å¤‡: {self.device}")

    def build_model_input(self, vehicle_data: Dict[str, Any], step: int) -> Dict[str, Any]:
        """
        æ„å»ºæ¨¡å‹è¾“å…¥
        """
        # 1. æ”¶é›†è½¦è¾†ç‰¹å¾
        vehicle_ids = list(vehicle_data.keys())
        node_features = []
        is_icv_list = []

        for i, veh_id in enumerate(vehicle_ids):
            vehicle = vehicle_data[veh_id]

            # èŠ‚ç‚¹ç‰¹å¾: [ä½ç½®, é€Ÿåº¦, åŠ é€Ÿåº¦, è½¦é“, å‰©ä½™è·ç¦», å®Œæˆç‡, ç±»å‹, æ—¶é—´, æ­¥é•¿]
            position = vehicle.get('position', 0.0)
            speed = vehicle.get('speed', 0.0)
            acceleration = vehicle.get('acceleration', 0.0)
            lane_index = vehicle.get('lane_index', 0)
            remaining_distance = vehicle.get('remaining_distance', 1000.0)
            completion_rate = vehicle.get('completion_rate', 0.0)
            is_icv = 1.0 if vehicle.get('is_icv', False) else 0.0  # ICVæ ‡å¿—
            current_time = step * 0.1  # æ—¶é—´(ç§’)
            time_step = 0.1  # æ­¥é•¿

            features = [
                position,
                speed,
                acceleration,
                lane_index,
                remaining_distance,
                completion_rate,
                is_icv,
                current_time,
                time_step
            ]

            node_features.append(features)
            is_icv_list.append(vehicle.get('is_icv', False))

        # 2. æ„å»ºäº¤äº’å›¾
        edge_indices = []
        edge_features = []

        # è¿æ¥ç›¸è¿‘è½¦è¾†ï¼Œè€ƒè™‘å®é™…çš„è½¦è¾†ä½ç½®å’Œè½¦é“
        for i, veh_id_i in enumerate(vehicle_ids):
            for j, veh_id_j in enumerate(vehicle_ids):
                if i == j:
                    continue

                # è·å–è½¦è¾†ä¿¡æ¯
                vehicle_i = vehicle_data[veh_id_i]
                vehicle_j = vehicle_data[veh_id_j]
                
                # è·å–è½¦è¾†ä½ç½®å’Œé€Ÿåº¦
                pos_i = vehicle_i.get('position', 0.0)
                pos_j = vehicle_j.get('position', 0.0)
                speed_i = vehicle_i.get('speed', 0.0)
                speed_j = vehicle_j.get('speed', 0.0)
                
                # è·å–è½¦é“ä¿¡æ¯
                lane_i = vehicle_i.get('lane_id', '')
                lane_j = vehicle_j.get('lane_id', '')

                # è®¡ç®—è·ç¦»
                distance = abs(pos_i - pos_j)
                
                # åªæœ‰åœ¨åŒä¸€æ¡è½¦é“ä¸Šæˆ–è·ç¦»å¾ˆè¿‘çš„æƒ…å†µä¸‹æ‰å»ºç«‹è¿æ¥
                if lane_i == lane_j or distance < 50:  # 50ç±³å†…æˆ–åŒè½¦é“
                    edge_indices.append([i, j])

                    # è¾¹ç‰¹å¾: [ç›¸å¯¹è·ç¦», ç›¸å¯¹é€Ÿåº¦, TTC, THW]
                    rel_distance = distance
                    rel_speed = abs(speed_i - speed_j)

                    # è®¡ç®—TTC (Time To Collision) å’Œ THW (Time Headway)
                    # TTC = distance / closing_speed (å¦‚æœæ¥è¿‘çš„è¯)
                    closing_speed = abs(speed_i - speed_j)
                    if speed_i > speed_j and closing_speed > 0.1:
                        # è½¦è¾†iåœ¨è¿½è½¦è¾†jçš„æƒ…å†µ
                        ttc = rel_distance / closing_speed if closing_speed > 0 else float('inf')
                    else:
                        # ä¸ä¼šè¿½å°¾
                        ttc = float('inf')

                    # THW = distance / speed_of_rear_vehicle (å¯¹äºåè½¦è€Œè¨€)
                    rear_speed = min(speed_i, speed_j)
                    thw = rel_distance / rear_speed if rear_speed > 0 else float('inf')

                    edge_features.append([
                        rel_distance,
                        rel_speed,
                        min(ttc, 100.0),  # é™åˆ¶TTCæœ€å¤§å€¼
                        min(thw, 100.0)   # é™åˆ¶THWæœ€å¤§å€¼
                    ])

        # 3. å…¨å±€äº¤é€šæŒ‡æ ‡
        global_metrics = self._calculate_global_metrics(vehicle_data, step)

        # 4. è½¬æ¢ä¸ºå¼ é‡
        batch = {
            'node_features': torch.tensor(node_features, dtype=torch.float32).to(self.device),
            'edge_indices': torch.tensor(edge_indices, dtype=torch.long).t().contiguous().to(self.device) if edge_indices else torch.zeros((2, 0), dtype=torch.long).to(self.device),
            'edge_features': torch.tensor(edge_features, dtype=torch.float32).to(self.device) if edge_features else torch.zeros((0, 4), dtype=torch.float32).to(self.device),
            'global_metrics': torch.tensor(global_metrics, dtype=torch.float32).unsqueeze(0).to(self.device),
            'vehicle_ids': vehicle_ids,
            'is_icv': torch.tensor(is_icv_list, dtype=torch.bool).to(self.device),
            'vehicle_states': {
                'ids': vehicle_ids,
                'data': vehicle_data
            }
        }

        return batch

    def _calculate_global_metrics(self, vehicle_data: Dict[str, Any], step: int) -> List[float]:
        """
        è®¡ç®—å…¨å±€äº¤é€šæŒ‡æ ‡
        """
        speeds = [v['speed'] for v in vehicle_data.values()]
        positions = [v['position'] for v in vehicle_data.values()]
        accelerations = [v['acceleration'] for v in vehicle_data.values()]

        avg_speed = np.mean(speeds) if speeds else 0.0
        speed_std = np.std(speeds) if len(speeds) > 1 else 0.0
        avg_accel = np.mean(np.abs(accelerations)) if accelerations else 0.0
        vehicle_count = len(vehicle_data)

        # 16ç»´å…¨å±€æŒ‡æ ‡
        metrics = [
            avg_speed, speed_std, avg_accel, vehicle_count,
            step * 0.1,  # å½“å‰æ—¶é—´
            min(positions) if positions else 0.0,  # æœ€å°ä½ç½®
            max(positions) if positions else 0.0,  # æœ€å¤§ä½ç½®
            np.mean(positions) if positions else 0.0,  # å¹³å‡ä½ç½®
            len([v for v in vehicle_data.values() if v.get('is_icv', False)]),  # ICVæ•°é‡
            vehicle_count - len([v for v in vehicle_data.values() if v.get('is_icv', False)]),  # éICVæ•°é‡
            np.sum([v['speed'] for v in vehicle_data.values() if v.get('is_icv', False)]) if vehicle_data else 0.0,  # ICVæ€»é€Ÿåº¦
            np.sum([v['speed'] for v in vehicle_data.values() if not v.get('is_icv', False)]) if vehicle_data else 0.0,  # éICVæ€»é€Ÿåº¦
            avg_speed * vehicle_count,  # æ€»æµé‡
            speed_std * vehicle_count,  # æ€»æ³¢åŠ¨
            avg_accel * vehicle_count,  # æ€»åŠ é€Ÿåº¦
            step % 100  # å‘¨æœŸæ€§ç‰¹å¾
        ]

        return metrics

    def apply_control(self, vehicle_data: Dict[str, Any], step: int) -> Dict[str, Any]:
        """
        åº”ç”¨æ§åˆ¶ç®—æ³•
        """
        # 1. æ„å»ºæ¨¡å‹è¾“å…¥
        batch = self.build_model_input(vehicle_data, step)

        # 2. æ¨¡å‹æ¨ç†
        with torch.no_grad():
            output = self.model(batch, step)

        # 3. åº”ç”¨å®‰å…¨åŠ¨ä½œ
        control_results = self._apply_safe_actions(output, vehicle_data)

        # 4. æ›´æ–°ç»Ÿè®¡
        self.total_interventions += output['level1_interventions'] + output['level2_interventions']
        self.total_emergency_interventions += output['level2_interventions']
        self.total_controlled_vehicles += len(output['selected_vehicle_ids'])

        # 5. è°ƒè¯•è¾“å‡º
        if step % 100 == 0:
            print(f"[Step {step}] æ§åˆ¶: {len(output['selected_vehicle_ids'])}è¾†, "
                  f"å¹²é¢„: {output['level1_interventions'] + output['level2_interventions']}, "
                  f"ç´§æ€¥: {output['level2_interventions']}")

        return control_results

    def _apply_safe_actions(self, output: Dict[str, Any], vehicle_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        åº”ç”¨å®‰å…¨åŠ¨ä½œåˆ°SUMO
        """
        results = {
            'controlled_vehicles': [],
            'actions_applied': [],
            'safety_interventions': output['level1_interventions'] + output['level2_interventions'],
            'emergency_interventions': output['level2_interventions']
        }

        for i, veh_id in enumerate(output['selected_vehicle_ids']):
            if veh_id not in vehicle_data:
                continue

            try:
                action = output['safe_actions']['safe_actions'][i]
                accel_action = action[0].item() * 5.0  # [-1,1] -> [-5,5]
                lane_action = action[1].item() > 0.5  # æ¦‚ç‡è½¬å¸ƒå°”

                # åº”ç”¨åŠ é€Ÿåº¦æ§åˆ¶
                current_speed = traci.vehicle.getSpeed(veh_id)
                new_speed = max(0.0, current_speed + accel_action * 0.1)  # 0.1ç§’æ­¥é•¿

                traci.vehicle.setSpeedMode(veh_id, 0)  # å…³é—­SUMOè‡ªåŠ¨æ§åˆ¶
                traci.vehicle.setSpeed(veh_id, new_speed)

                # è®°å½•æ§åˆ¶ç»“æœ
                results['controlled_vehicles'].append(veh_id)
                results['actions_applied'].append({
                    'acceleration': accel_action,
                    'lane_change': lane_action,
                    'new_speed': new_speed
                })

            except traci.TraCIException as e:
                continue
            except Exception as e:
                continue

        return results
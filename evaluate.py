"""
è¯„ä¼°è„šæœ¬
è¯„ä¼°æ§åˆ¶å™¨æ€§èƒ½
"""

import torch
import numpy as np
from typing import Dict, List, Tuple, Any
import json
import os
from tqdm import tqdm

from sumo_integration import create_sumo_controller


class Evaluator:
    """
    è¯„ä¼°å™¨
    """
    
    def __init__(self, model_path: str, config_path: str = None):
        # åˆ›å»ºæ§åˆ¶å™¨
        self.controller = create_sumo_controller(config_path)
        
        # åŠ è½½æ¨¡å‹
        if model_path and os.path.exists(model_path):
            checkpoint = torch.load(model_path, map_location=self.controller.device)
            self.controller.model.load_state_dict(checkpoint['model_state_dict'])
            print(f"âœ… åŠ è½½æ¨¡å‹: {model_path}")
        
        # è¯„ä¼°æŒ‡æ ‡
        self.metrics = {
            'total_steps': 0,
            'total_reward': 0.0,
            'avg_speed': 0.0,
            'speed_std': 0.0,
            'throughput': 0.0,
            'intervention_count': 0,
            'emergency_count': 0,
            'controlled_vehicles': 0
        }
    
    def evaluate(self, num_episodes: int = 10, max_steps: int = 3600) -> Dict[str, Any]:
        """
        è¯„ä¼°æ§åˆ¶å™¨
        """
        print(f"ğŸ” å¼€å§‹è¯„ä¼° ({num_episodes} episodes, {max_steps} steps each)...")
        
        for episode in range(num_episodes):
            episode_reward = self._run_episode(max_steps)
            
            print(f"Episode {episode+1}/{num_episodes}, Reward: {episode_reward:.2f}")
        
        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        avg_metrics = {
            'avg_reward': self.metrics['total_reward'] / num_episodes,
            'avg_speed': self.metrics['avg_speed'] / num_episodes,
            'speed_std': self.metrics['speed_std'] / num_episodes,
            'throughput': self.metrics['throughput'] / num_episodes,
            'avg_interventions': self.metrics['intervention_count'] / num_episodes,
            'avg_emergency': self.metrics['emergency_count'] / num_episodes,
            'avg_controlled': self.metrics['controlled_vehicles'] / num_episodes
        }
        
        print("\nğŸ“Š è¯„ä¼°ç»“æœ:")
        for key, value in avg_metrics.items():
            print(f"  {key}: {value:.4f}")
        
        return avg_metrics
    
    def _run_episode(self, max_steps: int) -> float:
        """
        è¿è¡Œä¸€ä¸ªepisode
        """
        # é‡ç½®æ§åˆ¶å™¨ç»Ÿè®¡
        self.controller.reset_statistics()
        
        # æ¨¡æ‹ŸSUMOç¯å¢ƒ
        total_reward = 0.0
        speeds = []
        
        for step in range(max_steps):
            # ç”Ÿæˆæ¨¡æ‹Ÿè½¦è¾†æ•°æ®
            vehicle_data = self._generate_vehicle_data(step)
            
            # åº”ç”¨æ§åˆ¶
            control_results = self.controller.apply_control(vehicle_data, step)
            
            # è®¡ç®—å¥–åŠ±
            reward = self._calculate_reward(vehicle_data, control_results)
            total_reward += reward
            
            # è®°å½•é€Ÿåº¦
            speeds.extend([v['speed'] for v in vehicle_data.values()])
            
            # æ¯100æ­¥è¾“å‡º
            if step % 100 == 0:
                print(f"  Step {step}/{max_steps}, Reward: {reward:.2f}")
        
        # æ›´æ–°æŒ‡æ ‡
        self.metrics['total_steps'] += max_steps
        self.metrics['total_reward'] += total_reward
        self.metrics['avg_speed'] += np.mean(speeds)
        self.metrics['speed_std'] += np.std(speeds)
        self.metrics['throughput'] += len(speeds) / max_steps
        
        stats = self.controller.get_statistics()
        self.metrics['intervention_count'] += stats['total_interventions']
        self.metrics['emergency_count'] += stats['total_emergency_interventions']
        self.metrics['controlled_vehicles'] += stats['total_controlled_vehicles']
        
        return total_reward
    
    def _generate_vehicle_data(self, step: int) -> Dict[str, Any]:
        """
        ç”Ÿæˆæ¨¡æ‹Ÿè½¦è¾†æ•°æ®
        æ³¨æ„ï¼šåœ¨å®é™…è¯„ä¼°ä¸­ï¼Œåº”è¯¥ä½¿ç”¨çœŸå®çš„SUMOç¯å¢ƒæ•°æ®
        æ­¤æ–¹æ³•ä»…ç”¨äºæ¼”ç¤ºï¼Œç”Ÿäº§ç¯å¢ƒåº”ä»SUMOè·å–çœŸå®æ•°æ®
        """
        import warnings
        warnings.warn(
            "ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œè¯„ä¼°ã€‚åœ¨å®é™…ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œ"
            "åº”è¯¥ä½¿ç”¨çœŸå®çš„SUMOä»¿çœŸæ•°æ®ã€‚",
            RuntimeWarning
        )
        
        vehicle_data = {}
        
        # åŸºäºç‰©ç†è§„å¾‹ç”Ÿæˆæ›´çœŸå®çš„è½¦è¾†æ•°æ®
        num_vehicles = int(10 + 10 * np.sin(step * 0.01))
        
        for i in range(num_vehicles):
            veh_id = f"veh_{step}_{i}"
            
            # åŸºäºè½¦é“å’Œä½ç½®ç”Ÿæˆæ›´åˆç†çš„æ•°æ®
            lane_index = np.random.randint(0, 3)
            position = np.random.uniform(0, 1000) + lane_index * 50  # ä¸åŒè½¦é“åç§»
            
            # é€Ÿåº¦åŸºäºä½ç½®ï¼ˆæ¥è¿‘ç»ˆç‚¹å¯èƒ½å‡é€Ÿï¼‰
            base_speed = 15.0
            speed = base_speed + np.random.normal(0, 3.0)
            speed = max(5.0, min(30.0, speed))  # é™åˆ¶åœ¨åˆç†èŒƒå›´
            
            # åŠ é€Ÿåº¦åŸºäºé€Ÿåº¦å˜åŒ–
            acceleration = np.random.normal(0, 0.5)
            acceleration = max(-3.0, min(2.0, acceleration))
            
            # å‰©ä½™è·ç¦»å’Œå®Œæˆç‡
            remaining_distance = max(0.0, 1000.0 - position)
            completion_rate = position / 1000.0
            
            vehicle_data[veh_id] = {
                'position': position,
                'speed': speed,
                'acceleration': acceleration,
                'lane_index': lane_index,
                'remaining_distance': remaining_distance,
                'completion_rate': completion_rate,
                'is_icv': np.random.random() < 0.25,  # 25% ICV
                'id': veh_id,
                'lane_id': f"lane_{lane_index}"
            }
        
        return vehicle_data
    
    def _calculate_reward(self, vehicle_data: Dict[str, Any],
                        control_results: Dict[str, Any]) -> float:
        """
        è®¡ç®—å¥–åŠ± - åŸºäºçœŸå®äº¤é€šæŒ‡æ ‡
        è€ƒè™‘ï¼šæµé‡æ•ˆç‡ã€å®‰å…¨ã€ç¨³å®šæ€§ã€æ§åˆ¶æˆæœ¬
        """
        if not vehicle_data:
            return 0.0
        
        speeds = [v['speed'] for v in vehicle_data.values()]
        accelerations = [v.get('acceleration', 0.0) for v in vehicle_data.values()]
        
        # 1. æµé‡æ•ˆç‡å¥–åŠ±
        avg_speed = np.mean(speeds) if speeds else 0.0
        flow_efficiency = avg_speed / 30.0  # å½’ä¸€åŒ–åˆ°[0,1]
        
        # 2. ç¨³å®šæ€§æƒ©ç½š
        speed_std = np.std(speeds) if len(speeds) > 1 else 0.0
        accel_std = np.std(accelerations) if len(accelerations) > 1 else 0.0
        stability_penalty = (speed_std / 10.0 + accel_std / 5.0) * 0.5
        
        # 3. å®‰å…¨è¯„ä¼°
        safety_penalty = 0.0
        for vehicle in vehicle_data.values():
            speed = vehicle.get('speed', 0.0)
            accel = vehicle.get('acceleration', 0.0)
            
            # æ£€æŸ¥å±é™©é©¾é©¶è¡Œä¸º
            if speed > 35.0:  # è¶…é€Ÿ
                safety_penalty += (speed - 35.0) * 0.1
            if accel < -4.0:  # æ€¥åˆ¹è½¦
                safety_penalty += (-accel - 4.0) * 0.2
            if accel > 3.0:  # æ€¥åŠ é€Ÿ
                safety_penalty += (accel - 3.0) * 0.1
        
        # 4. æ§åˆ¶æˆæœ¬
        intervention_cost = control_results.get('safety_interventions', 0) * 0.05
        emergency_cost = control_results.get('emergency_interventions', 0) * 0.5
        
        # 5. ç»¼åˆå¥–åŠ±
        reward = (
            flow_efficiency * 10.0           # æµé‡æ•ˆç‡æƒé‡
            - stability_penalty * 2.0         # ç¨³å®šæ€§æƒ©ç½šæƒé‡
            - safety_penalty * 5.0            # å®‰å…¨æƒ©ç½šæƒé‡
            - intervention_cost                # æ§åˆ¶æˆæœ¬
            - emergency_cost                   # ç´§æ€¥å¹²é¢„æˆæœ¬
        )
        
        return reward
    
    def save_results(self, results: Dict[str, Any], save_path: str):
        """ä¿å­˜è¯„ä¼°ç»“æœ"""
        with open(save_path, 'w') as f:
            json.dump(results, f, indent=2)
        print(f"âœ… è¯„ä¼°ç»“æœå·²ä¿å­˜åˆ°: {save_path}")


def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®
    model_path = 'models/traffic_controller_v1.pth'
    config_path = None
    num_episodes = 10
    max_steps = 3600
    results_path = 'results/evaluation_results.json'
    
    # åˆ›å»ºç»“æœç›®å½•
    os.makedirs('results', exist_ok=True)
    
    # åˆ›å»ºè¯„ä¼°å™¨
    evaluator = Evaluator(model_path, config_path)
    
    # è¯„ä¼°
    results = evaluator.evaluate(num_episodes=num_episodes, max_steps=max_steps)
    
    # ä¿å­˜ç»“æœ
    evaluator.save_results(results, results_path)
    
    print("\nğŸ‰ è¯„ä¼°å®Œæˆ!")


if __name__ == "__main__":
    main()
